{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T14:33:30.095593Z",
     "start_time": "2021-02-16T14:33:27.267961Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import calendar\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# from utils_model import * # expand later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T14:33:30.205535Z",
     "start_time": "2021-02-16T14:33:30.102548Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "data['gender'] = data['gender'].astype('str')\n",
    "data_test['gender'] = data_test['gender'].astype('str')\n",
    "\n",
    "data['Achievement_above_100%_during3quartal'] = data['Achievement_above_100%_during3quartal'].astype(str)\n",
    "data_test['Achievement_above_100%_during3quartal'] = data_test['Achievement_above_100%_during3quartal'].astype(str)\n",
    "\n",
    "\n",
    "data = data.rename(columns={'annual leave':'annual_leave'})\n",
    "data_test = data_test.rename(columns={'annual leave':'annual_leave'})\n",
    "\n",
    "data = data.rename(columns={'Last_achievement_%':'Last_achievement'})\n",
    "data_test = data_test.rename(columns={'Last_achievement_%':'Last_achievement'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:51:32.232641Z",
     "start_time": "2021-02-14T06:51:32.222612Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T14:33:30.220535Z",
     "start_time": "2021-02-16T14:33:30.207540Z"
    }
   },
   "outputs": [],
   "source": [
    "# get test data (for final evaluation)\n",
    "X = data.drop(columns=['Best Performance'])\n",
    "y = data['Best Performance']\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T14:33:30.236537Z",
     "start_time": "2021-02-16T14:33:30.222539Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(X_train),len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T14:33:43.288984Z",
     "start_time": "2021-02-16T14:33:43.272980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 7, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = list(X.select_dtypes(exclude=['object']))\n",
    "cat_cols = list(X.select_dtypes(include=['object']))\n",
    "features = list(X.columns)\n",
    "len(num_cols),len(cat_cols),len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T14:33:49.147976Z",
     "start_time": "2021-02-16T14:33:49.128950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boosting_type',\n",
       " 'num_leaves',\n",
       " 'max_depth',\n",
       " 'learning_rate',\n",
       " 'n_estimators',\n",
       " 'subsample_for_bin',\n",
       " 'objective',\n",
       " 'class_weight',\n",
       " 'min_split_gain',\n",
       " 'min_child_weight',\n",
       " 'min_child_samples',\n",
       " 'subsample',\n",
       " 'subsample_freq',\n",
       " 'colsample_bytree',\n",
       " 'reg_alpha',\n",
       " 'reg_lambda',\n",
       " 'random_state',\n",
       " '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = '''boosting_type='gbdt',\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample_for_bin=200000,\n",
    "    objective=None,\n",
    "    class_weight=None,\n",
    "    min_split_gain=0.0,\n",
    "    min_child_weight=0.001,\n",
    "    min_child_samples=20,\n",
    "    subsample=1.0,\n",
    "    subsample_freq=0,\n",
    "    colsample_bytree=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=None\n",
    "    '''\n",
    "# [x.strip() for x in a.split(',\\n')]\n",
    "[x.split('=')[0].strip() for x in a.split('\\n')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T14:33:51.315985Z",
     "start_time": "2021-02-16T14:33:51.264956Z"
    }
   },
   "outputs": [],
   "source": [
    "class Feature_Engineering:\n",
    "    def __init__(self,parameters):\n",
    "        self.parameters = parameters\n",
    "        self.target = parameters['target']\n",
    "    \n",
    "    @staticmethod  \n",
    "    def check_col(col):\n",
    "        if len(col.split(' '))>1:\n",
    "            col2 = '_'.join(col.split(' '))\n",
    "        else:\n",
    "            col2 = col\n",
    "        return col2\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_bin(data,col,n_bin,mode='cut'):\n",
    "        while True:\n",
    "            try:\n",
    "                if mode=='cut':\n",
    "                    _,bin_dummy = pd.cut(data[col],n_bin,retbins=True)\n",
    "                else:\n",
    "                    _,bin_dummy = pd.qcut(data[col],n_bin,retbins=True)\n",
    "            except:\n",
    "                n_bin -= 1\n",
    "                continue\n",
    "            break\n",
    "        return bin_dummy\n",
    "        \n",
    "    def fit(self,data_ori):\n",
    "        target = self.target\n",
    "        data = data_ori.copy()\n",
    "        for param in self.parameters['bin_numer_qcut']:\n",
    "            col = param[0]\n",
    "            n_bin = param[1]\n",
    "            bin_dummy = self.get_bin(data,col,n_bin,mode='qcut')\n",
    "            bin_dummy[0] = bin_dummy[0]-0.001\n",
    "            bin_dummy[-1] = np.inf\n",
    "            setattr(self,f'{col}_bin_numer_qcut',bin_dummy)\n",
    "        for param in self.parameters['bin_numer_cut']:\n",
    "            col = param[0]\n",
    "            n_bin = param[1]\n",
    "            bin_dummy = self.get_bin(data,col,n_bin,mode='cut')\n",
    "            bin_dummy[0] = bin_dummy[0]-0.001\n",
    "            bin_dummy[-1] = np.inf\n",
    "            setattr(self,f'{col}_bin_numer_cut',bin_dummy)\n",
    "            \n",
    "            \n",
    "        for param in self.parameters['bin_add_categ_numer_bin_qcut']:\n",
    "            col = param[1]\n",
    "            n_bin = param[2]\n",
    "            bin_dummy = self.get_bin(data,col,n_bin,mode='qcut')\n",
    "            bin_dummy[0] = bin_dummy[0]-0.001\n",
    "            bin_dummy[-1] = np.inf\n",
    "            setattr(self,f'{col}_bin_qcut_add_categ',bin_dummy)\n",
    "        \n",
    "        for param in self.parameters['bin_target_encoding_cut']:\n",
    "            col = param[0]\n",
    "            n_bin = param[1]\n",
    "            bin_dummy = self.get_bin(data,col,n_bin,mode='cut')\n",
    "            bin_dummy[0] = bin_dummy[0]-0.001\n",
    "            bin_dummy[-1] = np.inf\n",
    "            setattr(self,f'{col}_bin_cut',bin_dummy)\n",
    "            \n",
    "            data[f'{col}_bin_target_encoding_cut'] = pd.cut(data[col],bins=bin_dummy)\n",
    "            data_dummy = data.groupby([f'{col}_bin_target_encoding_cut'])[target].mean().reset_index(drop=False)\n",
    "            setattr(self,f'{col}_bin_target_encoding_cut',data_dummy)\n",
    "            \n",
    "        for param in self.parameters['bin_target_encoding_qcut']:\n",
    "            col = param[0]\n",
    "            n_bin = param[1]\n",
    "            bin_dummy = self.get_bin(data,col,n_bin,mode='qcut')\n",
    "            bin_dummy[0] = bin_dummy[0]-0.001\n",
    "            bin_dummy[-1] = np.inf\n",
    "            setattr(self,f'{col}_bin_qcut',bin_dummy)\n",
    "            \n",
    "            data[f'{col}_bin_target_encoding_qcut'] = pd.cut(data[col],bins=bin_dummy)\n",
    "            data_dummy = data.groupby([f'{col}_bin_target_encoding_qcut'])[target].mean().reset_index(drop=False)\n",
    "            setattr(self,f'{col}_bin_target_encoding_qcut',data_dummy)\n",
    "           \n",
    "        for param in self.parameters['bin_target_encoding_custom_bin']:\n",
    "            col = param[0]\n",
    "            bins = param[1]\n",
    "            setattr(self,f'{col}_bin_custom_bin',bins)\n",
    "            \n",
    "            data[f'{col}_bin_target_encoding_custom_bin'] = pd.cut(data[col],bins=bins)\n",
    "            data_dummy = data.groupby([f'{col}_bin_target_encoding_custom_bin'])[target].mean().reset_index(drop=False)\n",
    "            setattr(self,f'{col}_bin_target_encoding_custom_bin',data_dummy)\n",
    "        \n",
    "        for param in self.parameters['categorical_mean_encoding']:\n",
    "            col = param\n",
    "            data[f'{col}_categorical_mean_encoding'] = data[col].copy().values\n",
    "            data_dummy = data.groupby([f'{col}_categorical_mean_encoding'])[target].mean().reset_index(drop=False)\n",
    "            setattr(self,f'{col}_categorical_mean_encoding',data_dummy)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fit = True\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def transform(self,X,mode='train'):\n",
    "        data = X.copy()\n",
    "        target = self.target\n",
    "        if mode!='train':\n",
    "            target_encode = self.target\n",
    "        else:\n",
    "            target_encode = self.target +\"_y\"\n",
    "            \n",
    "        if self.fit==False:\n",
    "            raise Exception(\"Fit to train data first\")\n",
    "        \n",
    "        for param in self.parameters['bin_numer_qcut']:\n",
    "            col = param[0]\n",
    "            bin_dummy = eval(f'self.{col}_bin_numer_qcut')\n",
    "            data[f'{col}_bin_numer_qcut'] = pd.cut(data[col],bins=bin_dummy).astype(str).values\n",
    "        for param in self.parameters['bin_numer_cut']:\n",
    "            col = param[0]\n",
    "            bin_dummy = eval(f'self.{col}_bin_numer_cut')\n",
    "            data[f'{col}_bin_numer_cut'] = pd.cut(data[col],bins=bin_dummy).astype(str).values\n",
    "            \n",
    "        for cols in self.parameters['bin_add_categ_numer_bin_qcut']:\n",
    "            col_add = cols[0] + '_' + cols[1]\n",
    "            bin_dummy = eval(f'self.{cols[1]}_bin_qcut_add_categ')\n",
    "            data[f'{col_add}_bin_add_categ_numer_bin_qcut'] = pd.cut(data[cols[1]],bins=bin_dummy).values\n",
    "            data[f'{col_add}_bin_add_categ_numer_bin_qcut'] = (data[cols[0]].astype(str)+'_' + data[f'{col_add}_bin_add_categ_numer_bin_qcut'].astype(str)).values\n",
    "        \n",
    "        for param in self.parameters['bin_target_encoding_cut']:\n",
    "            col = param[0]\n",
    "            bin_dummy = eval(f'self.{col}_bin_cut')\n",
    "            data_dummy = eval(f'self.{col}_bin_target_encoding_cut')\n",
    "            data[f'{col}_bin_target_encoding_cut'] = pd.cut(data[col],bins=bin_dummy).values\n",
    "            data[f'{col}_bin_target_encoding_cut'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_bin_target_encoding_cut'])[f'{target_encode}'].values\n",
    "        \n",
    "        for param in self.parameters['bin_target_encoding_qcut']:\n",
    "            col = param[0]\n",
    "            bin_dummy = eval(f'self.{col}_bin_qcut')\n",
    "            data_dummy = eval(f'self.{col}_bin_target_encoding_qcut')\n",
    "            data[f'{col}_bin_target_encoding_qcut'] = pd.cut(data[col],bins=bin_dummy).values\n",
    "            data[f'{col}_bin_target_encoding_qcut'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_bin_target_encoding_qcut'])[f'{target_encode}'].values\n",
    "        \n",
    "        for param in self.parameters['bin_target_encoding_custom_bin']:\n",
    "            col = param[0]\n",
    "            bin_dummy = eval(f'self.{col}_bin_custom_bin')\n",
    "            data_dummy = eval(f'self.{col}_bin_target_encoding_custom_bin')\n",
    "            data[f'{col}_bin_target_encoding_custom_bin'] = pd.cut(data[col],bins=bin_dummy).values\n",
    "            data[f'{col}_bin_target_encoding_custom_bin'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_bin_target_encoding_custom_bin'])[f'{target_encode}'].values\n",
    "        \n",
    "        for param in self.parameters['categorical_mean_encoding']:\n",
    "            col = param\n",
    "            data_dummy = eval(f'self.{col}_categorical_mean_encoding')\n",
    "            data[f'{col}_categorical_mean_encoding'] = data[col].copy().values\n",
    "            data[f'{col}_categorical_mean_encoding'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_categorical_mean_encoding'])[f'{target_encode}'].values\n",
    "        \n",
    "        \n",
    "        for cols in self.parameters['multiply']:\n",
    "            data[cols[0] + 'x' +cols[1]] = (data[cols[0]] * data[cols[1]]).values\n",
    "        for cols in self.parameters['add']:\n",
    "            data[cols[0] + '+' +cols[1]] = (data[cols[0]] + data[cols[1]]).values\n",
    "        for cols in self.parameters['add_str']:\n",
    "            data[cols[0] + '+' +cols[1]] = (data[cols[0]].astype(str)+'_' + data[cols[1]].astype(str)).values\n",
    "            \n",
    "        for cols in self.parameters['substract']:\n",
    "            data[cols[0] + '-' +cols[1]] = (data[cols[0]] - data[cols[1]]).values\n",
    "        for cols in self.parameters['divide']:\n",
    "            data[cols[0] + '/' +cols[1]] = (data[cols[0]] / np.where(data[cols[1]]==0,0.0001,data[cols[1]])).values\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T14:34:05.749435Z",
     "start_time": "2021-02-16T14:34:05.032738Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_skf = {'train':[],'val':[]}\n",
    "skf = StratifiedKFold(n_splits=2,random_state = 3,shuffle = True)\n",
    "parameters = {'multiply':[['GPA','number_of_dependences']],\n",
    "              'add':[['annual_leave','sick_leaves'],['assign_of_otherposition','branch_rotation']],\n",
    "              'add_str':[['Education_level','job_level']],\n",
    "              'substract':[],'divide':[],\n",
    "              'bin_numer_qcut':[],\n",
    "              'bin_numer_cut':[['GPA',30]],\n",
    "              'bin_add_categ_numer_bin_qcut':[['job_level','GPA',5],['Education_level','GPA',5]],\n",
    "            'bin_target_encoding_cut':[],\n",
    "             'bin_target_encoding_qcut':[['year_graduated',5],['GPA',5],['annual_leave',5]],\n",
    "             'bin_target_encoding_custom_bin':[],\n",
    "              'categorical_mean_encoding':['job_level','person_level','Employee_type','Education_level'],\n",
    "             'target':'Best Performance'}\n",
    "\n",
    "\n",
    "for train_index,val_index in skf.split(X,y):\n",
    "    add_fe = Feature_Engineering(parameters)\n",
    "    add_fe.fit(data.iloc[train_index,:])\n",
    "    data_skf['train'].append([add_fe.transform(X.iloc[train_index,:],mode='val'),y.iloc[train_index]])\n",
    "    data_skf['val'].append([add_fe.transform(X.iloc[val_index,:],mode='val'),y.iloc[val_index]])\n",
    "\n",
    "num_cols_fe = list(data_skf['train'][0][0].select_dtypes(exclude='object').columns)\n",
    "cat_cols_fe = list(data_skf['train'][0][0].select_dtypes(include='object').columns)\n",
    "len(num_cols_fe),len(cat_cols_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T14:36:14.999717Z",
     "start_time": "2021-02-16T14:34:23.514070Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | n_esti... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5466  \u001b[0m | \u001b[0m 57.14   \u001b[0m | \u001b[0m 228.8   \u001b[0m | \u001b[0m 70.21   \u001b[0m | \u001b[0m 0.02724 \u001b[0m | \u001b[0m 0.02118 \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.5486  \u001b[0m | \u001b[95m 66.36   \u001b[0m | \u001b[95m 159.4   \u001b[0m | \u001b[95m 91.88   \u001b[0m | \u001b[95m 0.04818 \u001b[0m | \u001b[95m 0.01917 \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5475  \u001b[0m | \u001b[0m 69.46   \u001b[0m | \u001b[0m 158.9   \u001b[0m | \u001b[0m 91.43   \u001b[0m | \u001b[0m 0.01489 \u001b[0m | \u001b[0m 0.01442 \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5451  \u001b[0m | \u001b[0m 69.15   \u001b[0m | \u001b[0m 105.8   \u001b[0m | \u001b[0m 80.83   \u001b[0m | \u001b[0m 0.02445 \u001b[0m | \u001b[0m 0.0194  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5478  \u001b[0m | \u001b[0m 64.45   \u001b[0m | \u001b[0m 164.3   \u001b[0m | \u001b[0m 93.63   \u001b[0m | \u001b[0m 0.03876 \u001b[0m | \u001b[0m 0.004643\u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.5497  \u001b[0m | \u001b[95m 61.39   \u001b[0m | \u001b[95m 153.5   \u001b[0m | \u001b[95m 91.73   \u001b[0m | \u001b[95m 0.03375 \u001b[0m | \u001b[95m 0.0499  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5467  \u001b[0m | \u001b[0m 60.68   \u001b[0m | \u001b[0m 152.0   \u001b[0m | \u001b[0m 85.52   \u001b[0m | \u001b[0m 0.00122 \u001b[0m | \u001b[0m 0.04384 \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5434  \u001b[0m | \u001b[0m 59.79   \u001b[0m | \u001b[0m 151.7   \u001b[0m | \u001b[0m 94.78   \u001b[0m | \u001b[0m 0.0259  \u001b[0m | \u001b[0m 0.03079 \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5493  \u001b[0m | \u001b[0m 65.38   \u001b[0m | \u001b[0m 163.4   \u001b[0m | \u001b[0m 92.69   \u001b[0m | \u001b[0m 0.03367 \u001b[0m | \u001b[0m 0.01145 \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5456  \u001b[0m | \u001b[0m 67.37   \u001b[0m | \u001b[0m 163.1   \u001b[0m | \u001b[0m 90.59   \u001b[0m | \u001b[0m 0.0138  \u001b[0m | \u001b[0m 0.001714\u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5475  \u001b[0m | \u001b[0m 60.21   \u001b[0m | \u001b[0m 150.7   \u001b[0m | \u001b[0m 90.64   \u001b[0m | \u001b[0m 0.01089 \u001b[0m | \u001b[0m 0.02142 \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.5517  \u001b[0m | \u001b[95m 65.85   \u001b[0m | \u001b[95m 165.1   \u001b[0m | \u001b[95m 93.33   \u001b[0m | \u001b[95m 0.003121\u001b[0m | \u001b[95m 0.02807 \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5487  \u001b[0m | \u001b[0m 66.12   \u001b[0m | \u001b[0m 165.1   \u001b[0m | \u001b[0m 94.14   \u001b[0m | \u001b[0m 0.0104  \u001b[0m | \u001b[0m 0.001773\u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.543   \u001b[0m | \u001b[0m 60.54   \u001b[0m | \u001b[0m 153.2   \u001b[0m | \u001b[0m 92.12   \u001b[0m | \u001b[0m 0.02236 \u001b[0m | \u001b[0m 0.01754 \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5469  \u001b[0m | \u001b[0m 56.31   \u001b[0m | \u001b[0m 265.6   \u001b[0m | \u001b[0m 49.13   \u001b[0m | \u001b[0m 0.02696 \u001b[0m | \u001b[0m 0.01729 \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5448  \u001b[0m | \u001b[0m 13.6    \u001b[0m | \u001b[0m 200.8   \u001b[0m | \u001b[0m 79.72   \u001b[0m | \u001b[0m 0.04757 \u001b[0m | \u001b[0m 0.03423 \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.5515  \u001b[0m | \u001b[0m 65.95   \u001b[0m | \u001b[0m 166.2   \u001b[0m | \u001b[0m 92.19   \u001b[0m | \u001b[0m 0.03291 \u001b[0m | \u001b[0m 0.04549 \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.5516  \u001b[0m | \u001b[0m 28.14   \u001b[0m | \u001b[0m 248.9   \u001b[0m | \u001b[0m 86.34   \u001b[0m | \u001b[0m 0.008996\u001b[0m | \u001b[0m 0.009258\u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5416  \u001b[0m | \u001b[0m 28.76   \u001b[0m | \u001b[0m 250.7   \u001b[0m | \u001b[0m 85.03   \u001b[0m | \u001b[0m 0.0208  \u001b[0m | \u001b[0m 0.03334 \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5448  \u001b[0m | \u001b[0m 66.24   \u001b[0m | \u001b[0m 159.7   \u001b[0m | \u001b[0m 93.37   \u001b[0m | \u001b[0m 0.04819 \u001b[0m | \u001b[0m 0.04839 \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5475  \u001b[0m | \u001b[0m 63.31   \u001b[0m | \u001b[0m 164.1   \u001b[0m | \u001b[0m 92.89   \u001b[0m | \u001b[0m 0.0479  \u001b[0m | \u001b[0m 0.02644 \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.5459  \u001b[0m | \u001b[0m 21.83   \u001b[0m | \u001b[0m 161.5   \u001b[0m | \u001b[0m 45.69   \u001b[0m | \u001b[0m 0.01535 \u001b[0m | \u001b[0m 0.005233\u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.5487  \u001b[0m | \u001b[0m 26.17   \u001b[0m | \u001b[0m 249.9   \u001b[0m | \u001b[0m 85.36   \u001b[0m | \u001b[0m 0.03302 \u001b[0m | \u001b[0m 0.03046 \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.5475  \u001b[0m | \u001b[0m 25.16   \u001b[0m | \u001b[0m 232.3   \u001b[0m | \u001b[0m 92.64   \u001b[0m | \u001b[0m 0.02698 \u001b[0m | \u001b[0m 0.02979 \u001b[0m |\n",
      "| \u001b[95m 25      \u001b[0m | \u001b[95m 0.554   \u001b[0m | \u001b[95m 5.346   \u001b[0m | \u001b[95m 168.8   \u001b[0m | \u001b[95m 72.08   \u001b[0m | \u001b[95m 0.008901\u001b[0m | \u001b[95m 0.02273 \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.5524  \u001b[0m | \u001b[0m 61.5    \u001b[0m | \u001b[0m 68.84   \u001b[0m | \u001b[0m 46.28   \u001b[0m | \u001b[0m 0.004467\u001b[0m | \u001b[0m 0.0101  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.5492  \u001b[0m | \u001b[0m 59.71   \u001b[0m | \u001b[0m 70.04   \u001b[0m | \u001b[0m 45.54   \u001b[0m | \u001b[0m 0.03637 \u001b[0m | \u001b[0m 0.04976 \u001b[0m |\n",
      "| \u001b[95m 28      \u001b[0m | \u001b[95m 0.5553  \u001b[0m | \u001b[95m 64.85   \u001b[0m | \u001b[95m 164.9   \u001b[0m | \u001b[95m 92.99   \u001b[0m | \u001b[95m 0.02922 \u001b[0m | \u001b[95m 0.04348 \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.5517  \u001b[0m | \u001b[0m 64.46   \u001b[0m | \u001b[0m 68.0    \u001b[0m | \u001b[0m 46.57   \u001b[0m | \u001b[0m 0.03129 \u001b[0m | \u001b[0m 0.03694 \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.5497  \u001b[0m | \u001b[0m 62.59   \u001b[0m | \u001b[0m 70.39   \u001b[0m | \u001b[0m 47.09   \u001b[0m | \u001b[0m 0.04206 \u001b[0m | \u001b[0m 0.03809 \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.5467  \u001b[0m | \u001b[0m 80.47   \u001b[0m | \u001b[0m 262.0   \u001b[0m | \u001b[0m 72.45   \u001b[0m | \u001b[0m 0.02904 \u001b[0m | \u001b[0m 0.0111  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.5443  \u001b[0m | \u001b[0m 60.87   \u001b[0m | \u001b[0m 68.77   \u001b[0m | \u001b[0m 46.6    \u001b[0m | \u001b[0m 0.01535 \u001b[0m | \u001b[0m 0.02438 \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.5466  \u001b[0m | \u001b[0m 87.4    \u001b[0m | \u001b[0m 67.41   \u001b[0m | \u001b[0m 74.61   \u001b[0m | \u001b[0m 0.02473 \u001b[0m | \u001b[0m 0.004383\u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.5534  \u001b[0m | \u001b[0m 85.04   \u001b[0m | \u001b[0m 128.9   \u001b[0m | \u001b[0m 54.03   \u001b[0m | \u001b[0m 0.01504 \u001b[0m | \u001b[0m 0.02119 \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.5469  \u001b[0m | \u001b[0m 69.95   \u001b[0m | \u001b[0m 283.2   \u001b[0m | \u001b[0m 92.06   \u001b[0m | \u001b[0m 0.04715 \u001b[0m | \u001b[0m 0.00756 \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.5483  \u001b[0m | \u001b[0m 81.04   \u001b[0m | \u001b[0m 167.6   \u001b[0m | \u001b[0m 89.47   \u001b[0m | \u001b[0m 0.02952 \u001b[0m | \u001b[0m 0.005757\u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.5483  \u001b[0m | \u001b[0m 29.72   \u001b[0m | \u001b[0m 241.8   \u001b[0m | \u001b[0m 66.61   \u001b[0m | \u001b[0m 0.01922 \u001b[0m | \u001b[0m 0.005486\u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.5454  \u001b[0m | \u001b[0m 32.26   \u001b[0m | \u001b[0m 249.9   \u001b[0m | \u001b[0m 48.95   \u001b[0m | \u001b[0m 0.03787 \u001b[0m | \u001b[0m 0.03714 \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.5494  \u001b[0m | \u001b[0m 98.05   \u001b[0m | \u001b[0m 179.3   \u001b[0m | \u001b[0m 54.49   \u001b[0m | \u001b[0m 0.006414\u001b[0m | \u001b[0m 0.02904 \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.5479  \u001b[0m | \u001b[0m 40.15   \u001b[0m | \u001b[0m 180.2   \u001b[0m | \u001b[0m 69.51   \u001b[0m | \u001b[0m 0.0184  \u001b[0m | \u001b[0m 0.02897 \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.5492  \u001b[0m | \u001b[0m 37.64   \u001b[0m | \u001b[0m 90.89   \u001b[0m | \u001b[0m 58.33   \u001b[0m | \u001b[0m 0.02228 \u001b[0m | \u001b[0m 0.01428 \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.5541  \u001b[0m | \u001b[0m 46.45   \u001b[0m | \u001b[0m 53.97   \u001b[0m | \u001b[0m 83.88   \u001b[0m | \u001b[0m 0.00664 \u001b[0m | \u001b[0m 0.03882 \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.5428  \u001b[0m | \u001b[0m 72.61   \u001b[0m | \u001b[0m 220.3   \u001b[0m | \u001b[0m 38.16   \u001b[0m | \u001b[0m 0.04811 \u001b[0m | \u001b[0m 0.01195 \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.5538  \u001b[0m | \u001b[0m 84.87   \u001b[0m | \u001b[0m 81.2    \u001b[0m | \u001b[0m 65.62   \u001b[0m | \u001b[0m 0.02453 \u001b[0m | \u001b[0m 0.02063 \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.5552  \u001b[0m | \u001b[0m 54.14   \u001b[0m | \u001b[0m 77.85   \u001b[0m | \u001b[0m 67.5    \u001b[0m | \u001b[0m 0.01833 \u001b[0m | \u001b[0m 0.03096 \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.5452  \u001b[0m | \u001b[0m 43.13   \u001b[0m | \u001b[0m 228.3   \u001b[0m | \u001b[0m 46.89   \u001b[0m | \u001b[0m 0.03406 \u001b[0m | \u001b[0m 0.04531 \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.545   \u001b[0m | \u001b[0m 37.8    \u001b[0m | \u001b[0m 119.3   \u001b[0m | \u001b[0m 62.99   \u001b[0m | \u001b[0m 0.01192 \u001b[0m | \u001b[0m 0.03295 \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.5455  \u001b[0m | \u001b[0m 83.49   \u001b[0m | \u001b[0m 172.0   \u001b[0m | \u001b[0m 80.11   \u001b[0m | \u001b[0m 0.02095 \u001b[0m | \u001b[0m 0.01817 \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.5459  \u001b[0m | \u001b[0m 10.22   \u001b[0m | \u001b[0m 129.9   \u001b[0m | \u001b[0m 92.09   \u001b[0m | \u001b[0m 0.04869 \u001b[0m | \u001b[0m 0.02234 \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.5439  \u001b[0m | \u001b[0m 58.93   \u001b[0m | \u001b[0m 144.4   \u001b[0m | \u001b[0m 81.86   \u001b[0m | \u001b[0m 0.024   \u001b[0m | \u001b[0m 0.0281  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.542   \u001b[0m | \u001b[0m 24.15   \u001b[0m | \u001b[0m 241.6   \u001b[0m | \u001b[0m 41.85   \u001b[0m | \u001b[0m 0.04828 \u001b[0m | \u001b[0m 0.03796 \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.5489  \u001b[0m | \u001b[0m 14.75   \u001b[0m | \u001b[0m 246.3   \u001b[0m | \u001b[0m 36.73   \u001b[0m | \u001b[0m 0.04309 \u001b[0m | \u001b[0m 0.01097 \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.5531  \u001b[0m | \u001b[0m 5.1     \u001b[0m | \u001b[0m 112.4   \u001b[0m | \u001b[0m 99.55   \u001b[0m | \u001b[0m 0.000574\u001b[0m | \u001b[0m 0.02335 \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.5473  \u001b[0m | \u001b[0m 14.64   \u001b[0m | \u001b[0m 57.06   \u001b[0m | \u001b[0m 45.65   \u001b[0m | \u001b[0m 0.0299  \u001b[0m | \u001b[0m 0.0155  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.5445  \u001b[0m | \u001b[0m 99.7    \u001b[0m | \u001b[0m 162.4   \u001b[0m | \u001b[0m 26.04   \u001b[0m | \u001b[0m 0.02034 \u001b[0m | \u001b[0m 0.04056 \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.5518  \u001b[0m | \u001b[0m 26.15   \u001b[0m | \u001b[0m 128.5   \u001b[0m | \u001b[0m 59.4    \u001b[0m | \u001b[0m 0.01487 \u001b[0m | \u001b[0m 0.03325 \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.5408  \u001b[0m | \u001b[0m 30.18   \u001b[0m | \u001b[0m 278.6   \u001b[0m | \u001b[0m 74.53   \u001b[0m | \u001b[0m 0.04014 \u001b[0m | \u001b[0m 0.01933 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.5482  \u001b[0m | \u001b[0m 78.67   \u001b[0m | \u001b[0m 216.3   \u001b[0m | \u001b[0m 96.3    \u001b[0m | \u001b[0m 0.01304 \u001b[0m | \u001b[0m 0.03063 \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.5511  \u001b[0m | \u001b[0m 74.62   \u001b[0m | \u001b[0m 138.6   \u001b[0m | \u001b[0m 42.67   \u001b[0m | \u001b[0m 0.0249  \u001b[0m | \u001b[0m 0.02317 \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.5455  \u001b[0m | \u001b[0m 27.67   \u001b[0m | \u001b[0m 202.6   \u001b[0m | \u001b[0m 43.5    \u001b[0m | \u001b[0m 0.009518\u001b[0m | \u001b[0m 0.03645 \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.5476  \u001b[0m | \u001b[0m 25.59   \u001b[0m | \u001b[0m 244.0   \u001b[0m | \u001b[0m 99.6    \u001b[0m | \u001b[0m 0.01085 \u001b[0m | \u001b[0m 0.02173 \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.5488  \u001b[0m | \u001b[0m 22.98   \u001b[0m | \u001b[0m 81.21   \u001b[0m | \u001b[0m 47.78   \u001b[0m | \u001b[0m 0.01837 \u001b[0m | \u001b[0m 0.0465  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.5526  \u001b[0m | \u001b[0m 37.51   \u001b[0m | \u001b[0m 71.04   \u001b[0m | \u001b[0m 82.11   \u001b[0m | \u001b[0m 0.009463\u001b[0m | \u001b[0m 0.02728 \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.5521  \u001b[0m | \u001b[0m 65.44   \u001b[0m | \u001b[0m 62.93   \u001b[0m | \u001b[0m 94.63   \u001b[0m | \u001b[0m 0.01357 \u001b[0m | \u001b[0m 0.04303 \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.5474  \u001b[0m | \u001b[0m 28.98   \u001b[0m | \u001b[0m 97.48   \u001b[0m | \u001b[0m 79.83   \u001b[0m | \u001b[0m 0.000395\u001b[0m | \u001b[0m 0.03771 \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.5509  \u001b[0m | \u001b[0m 15.07   \u001b[0m | \u001b[0m 96.63   \u001b[0m | \u001b[0m 80.95   \u001b[0m | \u001b[0m 0.000172\u001b[0m | \u001b[0m 0.04404 \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.5474  \u001b[0m | \u001b[0m 66.05   \u001b[0m | \u001b[0m 209.1   \u001b[0m | \u001b[0m 91.85   \u001b[0m | \u001b[0m 0.001075\u001b[0m | \u001b[0m 0.0276  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.5524  \u001b[0m | \u001b[0m 16.14   \u001b[0m | \u001b[0m 264.8   \u001b[0m | \u001b[0m 81.22   \u001b[0m | \u001b[0m 0.000943\u001b[0m | \u001b[0m 0.04781 \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.5495  \u001b[0m | \u001b[0m 27.74   \u001b[0m | \u001b[0m 196.5   \u001b[0m | \u001b[0m 88.11   \u001b[0m | \u001b[0m 0.0254  \u001b[0m | \u001b[0m 0.0318  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.542   \u001b[0m | \u001b[0m 7.85    \u001b[0m | \u001b[0m 215.0   \u001b[0m | \u001b[0m 53.53   \u001b[0m | \u001b[0m 0.007122\u001b[0m | \u001b[0m 0.0444  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.547   \u001b[0m | \u001b[0m 65.56   \u001b[0m | \u001b[0m 109.7   \u001b[0m | \u001b[0m 92.11   \u001b[0m | \u001b[0m 0.03747 \u001b[0m | \u001b[0m 0.03514 \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.5532  \u001b[0m | \u001b[0m 63.9    \u001b[0m | \u001b[0m 86.86   \u001b[0m | \u001b[0m 36.05   \u001b[0m | \u001b[0m 0.01316 \u001b[0m | \u001b[0m 0.04648 \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.5494  \u001b[0m | \u001b[0m 73.5    \u001b[0m | \u001b[0m 99.93   \u001b[0m | \u001b[0m 98.29   \u001b[0m | \u001b[0m 0.04133 \u001b[0m | \u001b[0m 0.02595 \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.5437  \u001b[0m | \u001b[0m 29.87   \u001b[0m | \u001b[0m 264.9   \u001b[0m | \u001b[0m 41.91   \u001b[0m | \u001b[0m 0.0323  \u001b[0m | \u001b[0m 0.01598 \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.5438  \u001b[0m | \u001b[0m 73.87   \u001b[0m | \u001b[0m 279.9   \u001b[0m | \u001b[0m 36.65   \u001b[0m | \u001b[0m 0.03905 \u001b[0m | \u001b[0m 0.03458 \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.5417  \u001b[0m | \u001b[0m 54.36   \u001b[0m | \u001b[0m 225.2   \u001b[0m | \u001b[0m 26.8    \u001b[0m | \u001b[0m 0.01225 \u001b[0m | \u001b[0m 0.03311 \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.5517  \u001b[0m | \u001b[0m 11.69   \u001b[0m | \u001b[0m 168.4   \u001b[0m | \u001b[0m 37.81   \u001b[0m | \u001b[0m 0.03012 \u001b[0m | \u001b[0m 0.01578 \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.548   \u001b[0m | \u001b[0m 23.96   \u001b[0m | \u001b[0m 105.6   \u001b[0m | \u001b[0m 48.33   \u001b[0m | \u001b[0m 0.03671 \u001b[0m | \u001b[0m 0.01258 \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.5454  \u001b[0m | \u001b[0m 41.05   \u001b[0m | \u001b[0m 255.6   \u001b[0m | \u001b[0m 73.11   \u001b[0m | \u001b[0m 0.01199 \u001b[0m | \u001b[0m 0.04133 \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.5504  \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 79.33   \u001b[0m | \u001b[0m 87.32   \u001b[0m | \u001b[0m 0.02318 \u001b[0m | \u001b[0m 0.0136  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.5485  \u001b[0m | \u001b[0m 55.42   \u001b[0m | \u001b[0m 198.6   \u001b[0m | \u001b[0m 83.63   \u001b[0m | \u001b[0m 0.005105\u001b[0m | \u001b[0m 0.0291  \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.5419  \u001b[0m | \u001b[0m 59.97   \u001b[0m | \u001b[0m 82.98   \u001b[0m | \u001b[0m 77.47   \u001b[0m | \u001b[0m 0.03845 \u001b[0m | \u001b[0m 0.01965 \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.5507  \u001b[0m | \u001b[0m 63.42   \u001b[0m | \u001b[0m 118.9   \u001b[0m | \u001b[0m 75.62   \u001b[0m | \u001b[0m 0.04775 \u001b[0m | \u001b[0m 0.009735\u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.5443  \u001b[0m | \u001b[0m 62.97   \u001b[0m | \u001b[0m 159.1   \u001b[0m | \u001b[0m 37.78   \u001b[0m | \u001b[0m 0.02954 \u001b[0m | \u001b[0m 0.0443  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.5413  \u001b[0m | \u001b[0m 34.33   \u001b[0m | \u001b[0m 138.7   \u001b[0m | \u001b[0m 78.49   \u001b[0m | \u001b[0m 0.03152 \u001b[0m | \u001b[0m 0.04168 \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.5448  \u001b[0m | \u001b[0m 29.72   \u001b[0m | \u001b[0m 195.7   \u001b[0m | \u001b[0m 74.58   \u001b[0m | \u001b[0m 0.04851 \u001b[0m | \u001b[0m 0.04566 \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.5441  \u001b[0m | \u001b[0m 15.14   \u001b[0m | \u001b[0m 242.1   \u001b[0m | \u001b[0m 63.96   \u001b[0m | \u001b[0m 0.002896\u001b[0m | \u001b[0m 0.03585 \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.5494  \u001b[0m | \u001b[0m 13.49   \u001b[0m | \u001b[0m 283.4   \u001b[0m | \u001b[0m 62.11   \u001b[0m | \u001b[0m 0.002074\u001b[0m | \u001b[0m 0.04544 \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.5516  \u001b[0m | \u001b[0m 41.19   \u001b[0m | \u001b[0m 144.8   \u001b[0m | \u001b[0m 94.87   \u001b[0m | \u001b[0m 0.005027\u001b[0m | \u001b[0m 0.01738 \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.5515  \u001b[0m | \u001b[0m 68.02   \u001b[0m | \u001b[0m 124.5   \u001b[0m | \u001b[0m 53.29   \u001b[0m | \u001b[0m 0.02274 \u001b[0m | \u001b[0m 0.03406 \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.5486  \u001b[0m | \u001b[0m 92.71   \u001b[0m | \u001b[0m 199.6   \u001b[0m | \u001b[0m 75.28   \u001b[0m | \u001b[0m 0.02408 \u001b[0m | \u001b[0m 0.03923 \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.5483  \u001b[0m | \u001b[0m 89.32   \u001b[0m | \u001b[0m 228.5   \u001b[0m | \u001b[0m 49.68   \u001b[0m | \u001b[0m 0.01615 \u001b[0m | \u001b[0m 0.008562\u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.5438  \u001b[0m | \u001b[0m 59.94   \u001b[0m | \u001b[0m 154.9   \u001b[0m | \u001b[0m 84.12   \u001b[0m | \u001b[0m 0.04971 \u001b[0m | \u001b[0m 0.008497\u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.5488  \u001b[0m | \u001b[0m 24.17   \u001b[0m | \u001b[0m 187.5   \u001b[0m | \u001b[0m 65.63   \u001b[0m | \u001b[0m 0.03976 \u001b[0m | \u001b[0m 0.01191 \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.5424  \u001b[0m | \u001b[0m 82.37   \u001b[0m | \u001b[0m 194.2   \u001b[0m | \u001b[0m 53.79   \u001b[0m | \u001b[0m 0.007727\u001b[0m | \u001b[0m 0.02495 \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.5438  \u001b[0m | \u001b[0m 86.13   \u001b[0m | \u001b[0m 257.5   \u001b[0m | \u001b[0m 70.83   \u001b[0m | \u001b[0m 0.009088\u001b[0m | \u001b[0m 0.02769 \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.5539  \u001b[0m | \u001b[0m 33.52   \u001b[0m | \u001b[0m 103.6   \u001b[0m | \u001b[0m 82.01   \u001b[0m | \u001b[0m 0.03622 \u001b[0m | \u001b[0m 0.03937 \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.5485  \u001b[0m | \u001b[0m 30.48   \u001b[0m | \u001b[0m 68.79   \u001b[0m | \u001b[0m 92.44   \u001b[0m | \u001b[0m 0.04525 \u001b[0m | \u001b[0m 0.04176 \u001b[0m |\n",
      "| \u001b[95m 99      \u001b[0m | \u001b[95m 0.5574  \u001b[0m | \u001b[95m 71.14   \u001b[0m | \u001b[95m 64.47   \u001b[0m | \u001b[95m 32.02   \u001b[0m | \u001b[95m 0.009109\u001b[0m | \u001b[95m 0.008254\u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.5453  \u001b[0m | \u001b[0m 15.68   \u001b[0m | \u001b[0m 178.7   \u001b[0m | \u001b[0m 58.35   \u001b[0m | \u001b[0m 0.02957 \u001b[0m | \u001b[0m 0.04873 \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 0.5465  \u001b[0m | \u001b[0m 83.56   \u001b[0m | \u001b[0m 222.9   \u001b[0m | \u001b[0m 98.76   \u001b[0m | \u001b[0m 0.04421 \u001b[0m | \u001b[0m 0.01124 \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 0.5471  \u001b[0m | \u001b[0m 19.1    \u001b[0m | \u001b[0m 280.8   \u001b[0m | \u001b[0m 78.51   \u001b[0m | \u001b[0m 0.04909 \u001b[0m | \u001b[0m 0.03978 \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "                                ('imputer', SimpleImputer(strategy = 'median')),\n",
    "                                ('scaler', RobustScaler())\n",
    "                                ])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "                                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                ])\n",
    "    \n",
    "def search_model_lgbm(num_leaves,max_depth,n_estimators,reg_alpha,reg_lambda):\n",
    "    params = {\n",
    "        'boosting_type':'gbdt',\n",
    "         'num_leaves':int(num_leaves),\n",
    "         'max_depth':int(max_depth),\n",
    "         'n_estimators':int(n_estimators),\n",
    "         'objective':'binary',\n",
    "#          'class_weight':'balanced',\n",
    "         'reg_alpha':reg_alpha,\n",
    "         'reg_lambda':reg_lambda,\n",
    "         'random_state':0}\n",
    "    lgbm = LGBMClassifier(**params)\n",
    "    transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols_fe),\n",
    "            ('cat', cat_transformer, cat_cols_fe)\n",
    "        ])\n",
    "    main_pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                      ('classifier', lgbm)])\n",
    "    \n",
    "    aucs = []\n",
    "    for i in range(len(data_skf['train'])):\n",
    "        model = clone(main_pipeline)\n",
    "        model.fit(data_skf['train'][i][0],data_skf['train'][i][1].values)\n",
    "        pred_proba = model.predict_proba(data_skf['val'][i][0])[:,1]\n",
    "        \n",
    "        aucs.append(roc_auc_score(data_skf['val'][i][1].values, pred_proba,average='weighted'))\n",
    "    return np.mean(aucs)\n",
    "\n",
    "lgbBO = BayesianOptimization(search_model_lgbm, {'num_leaves': (25, 100),\n",
    "                                        'max_depth': (5, 100),\n",
    "                                        'n_estimators':(50,300),\n",
    "                                        'reg_alpha': (0.0, 0.05),\n",
    "                                        'reg_lambda': (0.0, 0.05),\n",
    "                                        },random_state=0)\n",
    "\n",
    "lgbBO.maximize(n_iter=100, init_points=2)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T14:36:20.663029Z",
     "start_time": "2021-02-16T14:36:20.656032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.5573626004632181,\n",
       " 'params': {'max_depth': 71.14463645613029,\n",
       "  'n_estimators': 64.46799939822702,\n",
       "  'num_leaves': 32.02057967524939,\n",
       "  'reg_alpha': 0.00910889806421355,\n",
       "  'reg_lambda': 0.008254388572148113}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbBO.max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:44:44.238916Z",
     "start_time": "2021-02-16T16:44:44.232888Z"
    }
   },
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'boosting_type':'gbdt',\n",
    "#      'num_leaves':int(60.80441469032743),\n",
    "#      'max_depth':int(5.663953027572844),\n",
    "#      'n_estimators':int(52.29955231632742),\n",
    "#      'objective':'binary',\n",
    "#      'class_weight':'balanced',\n",
    "#      'reg_alpha':0.0070860708219850025,\n",
    "#      'reg_lambda':0.04598746020415847,\n",
    "#      'random_state':0}\n",
    "\n",
    "params = {\n",
    "    'boosting_type':'gbdt',\n",
    "     'num_leaves':int(32.02057967524939),\n",
    "     'max_depth':int(71.14463645613029),\n",
    "     'n_estimators':int(64.46799939822702),\n",
    "     'objective':'binary',\n",
    "#      'class_weight':'balanced',\n",
    "     'reg_alpha':0.00910889806421355,\n",
    "     'reg_lambda':0.008254388572148113,\n",
    "     'random_state':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:44:45.961133Z",
     "start_time": "2021-02-16T16:44:45.436135Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5573626004632181"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lgbm = LGBMClassifier(**params)\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols_fe),\n",
    "        ('cat', cat_transformer, cat_cols_fe)\n",
    "    ])\n",
    "main_pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                  ('classifier', lgbm)])\n",
    "\n",
    "aucs = []\n",
    "for i in range(len(data_skf['train'])):\n",
    "    model = clone(main_pipeline)\n",
    "    model.fit(data_skf['train'][i][0],data_skf['train'][i][1].values)\n",
    "    pred_proba = model.predict_proba(data_skf['val'][i][0])[:,1]\n",
    "\n",
    "    aucs.append(roc_auc_score(data_skf['val'][i][1].values, pred_proba,average='samples'))\n",
    "\n",
    "np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T16:05:13.423943Z",
     "start_time": "2021-02-15T16:05:12.460776Z"
    }
   },
   "outputs": [],
   "source": [
    "add_fe = Feature_Engineering(parameters)\n",
    "add_fe.fit(data.iloc[train_index,:])\n",
    "\n",
    "X_train, y_train = add_fe.transform(X,mode='val'),y.copy()\n",
    "X_test = add_fe.transform(data_test,mode='val')\n",
    "\n",
    "\n",
    "model = clone(main_pipeline)\n",
    "model.fit(X_train,y_train.values)\n",
    "\n",
    "pred_proba = model.predict_proba(X_test)[:,1]\n",
    "df_submission = pd.DataFrame({'index':data_test.index,'Best Performance':pred_proba})\n",
    "df_submission\n",
    "\n",
    "df_submission.to_csv('df_submission_15feb_LGBM1CVTUNE_FE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T16:05:51.861372Z",
     "start_time": "2021-02-15T16:05:51.845342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36966666666666664"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_proba[pred_proba>0.5])/len(pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T14:48:18.104055Z",
     "start_time": "2021-02-16T14:37:09.625821Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | n_esti... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5438  \u001b[0m | \u001b[0m 57.14   \u001b[0m | \u001b[0m 228.8   \u001b[0m | \u001b[0m 70.21   \u001b[0m | \u001b[0m 0.02724 \u001b[0m | \u001b[0m 0.02118 \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.5543  \u001b[0m | \u001b[95m 66.36   \u001b[0m | \u001b[95m 159.4   \u001b[0m | \u001b[95m 91.88   \u001b[0m | \u001b[95m 0.04818 \u001b[0m | \u001b[95m 0.01917 \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5467  \u001b[0m | \u001b[0m 69.46   \u001b[0m | \u001b[0m 158.9   \u001b[0m | \u001b[0m 91.43   \u001b[0m | \u001b[0m 0.01489 \u001b[0m | \u001b[0m 0.01442 \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5482  \u001b[0m | \u001b[0m 69.15   \u001b[0m | \u001b[0m 105.8   \u001b[0m | \u001b[0m 80.83   \u001b[0m | \u001b[0m 0.02445 \u001b[0m | \u001b[0m 0.0194  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5421  \u001b[0m | \u001b[0m 8.968   \u001b[0m | \u001b[0m 54.52   \u001b[0m | \u001b[0m 32.94   \u001b[0m | \u001b[0m 0.00111 \u001b[0m | \u001b[0m 0.003873\u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5453  \u001b[0m | \u001b[0m 75.28   \u001b[0m | \u001b[0m 89.26   \u001b[0m | \u001b[0m 93.39   \u001b[0m | \u001b[0m 0.03848 \u001b[0m | \u001b[0m 0.004219\u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.549   \u001b[0m | \u001b[0m 65.03   \u001b[0m | \u001b[0m 139.7   \u001b[0m | \u001b[0m 47.75   \u001b[0m | \u001b[0m 0.03896 \u001b[0m | \u001b[0m 0.02876 \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5416  \u001b[0m | \u001b[0m 88.01   \u001b[0m | \u001b[0m 140.3   \u001b[0m | \u001b[0m 49.35   \u001b[0m | \u001b[0m 0.03074 \u001b[0m | \u001b[0m 0.02099 \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.5549  \u001b[0m | \u001b[95m 68.0    \u001b[0m | \u001b[95m 157.4   \u001b[0m | \u001b[95m 93.54   \u001b[0m | \u001b[95m 0.04594 \u001b[0m | \u001b[95m 0.02207 \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5543  \u001b[0m | \u001b[0m 69.01   \u001b[0m | \u001b[0m 157.3   \u001b[0m | \u001b[0m 95.6    \u001b[0m | \u001b[0m 0.01523 \u001b[0m | \u001b[0m 0.04691 \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5517  \u001b[0m | \u001b[0m 62.97   \u001b[0m | \u001b[0m 159.9   \u001b[0m | \u001b[0m 96.08   \u001b[0m | \u001b[0m 0.001698\u001b[0m | \u001b[0m 0.007428\u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5497  \u001b[0m | \u001b[0m 65.46   \u001b[0m | \u001b[0m 157.0   \u001b[0m | \u001b[0m 95.8    \u001b[0m | \u001b[0m 0.004848\u001b[0m | \u001b[0m 0.04798 \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.552   \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 153.8   \u001b[0m | \u001b[0m 92.17   \u001b[0m | \u001b[0m 0.005177\u001b[0m | \u001b[0m 0.03463 \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5504  \u001b[0m | \u001b[0m 68.42   \u001b[0m | \u001b[0m 155.0   \u001b[0m | \u001b[0m 94.47   \u001b[0m | \u001b[0m 0.02578 \u001b[0m | \u001b[0m 0.004316\u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5514  \u001b[0m | \u001b[0m 64.84   \u001b[0m | \u001b[0m 155.5   \u001b[0m | \u001b[0m 88.95   \u001b[0m | \u001b[0m 0.007182\u001b[0m | \u001b[0m 0.02692 \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5481  \u001b[0m | \u001b[0m 70.94   \u001b[0m | \u001b[0m 159.8   \u001b[0m | \u001b[0m 95.03   \u001b[0m | \u001b[0m 0.002129\u001b[0m | \u001b[0m 0.04187 \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.5545  \u001b[0m | \u001b[0m 66.68   \u001b[0m | \u001b[0m 155.1   \u001b[0m | \u001b[0m 91.17   \u001b[0m | \u001b[0m 0.001201\u001b[0m | \u001b[0m 0.02508 \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.5478  \u001b[0m | \u001b[0m 65.48   \u001b[0m | \u001b[0m 150.8   \u001b[0m | \u001b[0m 90.82   \u001b[0m | \u001b[0m 0.03701 \u001b[0m | \u001b[0m 0.02734 \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5443  \u001b[0m | \u001b[0m 65.58   \u001b[0m | \u001b[0m 156.5   \u001b[0m | \u001b[0m 93.12   \u001b[0m | \u001b[0m 0.02001 \u001b[0m | \u001b[0m 0.03363 \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5534  \u001b[0m | \u001b[0m 66.24   \u001b[0m | \u001b[0m 159.7   \u001b[0m | \u001b[0m 93.37   \u001b[0m | \u001b[0m 0.04819 \u001b[0m | \u001b[0m 0.04839 \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5499  \u001b[0m | \u001b[0m 69.79   \u001b[0m | \u001b[0m 155.3   \u001b[0m | \u001b[0m 90.51   \u001b[0m | \u001b[0m 0.01992 \u001b[0m | \u001b[0m 0.03843 \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.5513  \u001b[0m | \u001b[0m 68.37   \u001b[0m | \u001b[0m 155.2   \u001b[0m | \u001b[0m 91.49   \u001b[0m | \u001b[0m 0.007889\u001b[0m | \u001b[0m 0.03603 \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.554   \u001b[0m | \u001b[0m 63.64   \u001b[0m | \u001b[0m 159.7   \u001b[0m | \u001b[0m 93.79   \u001b[0m | \u001b[0m 0.01873 \u001b[0m | \u001b[0m 0.02614 \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.5465  \u001b[0m | \u001b[0m 65.04   \u001b[0m | \u001b[0m 159.3   \u001b[0m | \u001b[0m 92.79   \u001b[0m | \u001b[0m 0.001048\u001b[0m | \u001b[0m 0.02944 \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.5383  \u001b[0m | \u001b[0m 5.346   \u001b[0m | \u001b[0m 168.8   \u001b[0m | \u001b[0m 72.08   \u001b[0m | \u001b[0m 0.008901\u001b[0m | \u001b[0m 0.02273 \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.5538  \u001b[0m | \u001b[0m 67.75   \u001b[0m | \u001b[0m 155.5   \u001b[0m | \u001b[0m 95.52   \u001b[0m | \u001b[0m 0.02287 \u001b[0m | \u001b[0m 0.01302 \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.5521  \u001b[0m | \u001b[0m 64.86   \u001b[0m | \u001b[0m 160.3   \u001b[0m | \u001b[0m 93.9    \u001b[0m | \u001b[0m 0.02522 \u001b[0m | \u001b[0m 0.03789 \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.5452  \u001b[0m | \u001b[0m 68.85   \u001b[0m | \u001b[0m 153.6   \u001b[0m | \u001b[0m 96.42   \u001b[0m | \u001b[0m 0.011   \u001b[0m | \u001b[0m 0.02322 \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.5479  \u001b[0m | \u001b[0m 67.92   \u001b[0m | \u001b[0m 153.2   \u001b[0m | \u001b[0m 91.3    \u001b[0m | \u001b[0m 0.04542 \u001b[0m | \u001b[0m 0.02845 \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.5466  \u001b[0m | \u001b[0m 66.04   \u001b[0m | \u001b[0m 159.7   \u001b[0m | \u001b[0m 94.53   \u001b[0m | \u001b[0m 0.03761 \u001b[0m | \u001b[0m 0.007799\u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.5518  \u001b[0m | \u001b[0m 70.21   \u001b[0m | \u001b[0m 156.9   \u001b[0m | \u001b[0m 94.91   \u001b[0m | \u001b[0m 0.03949 \u001b[0m | \u001b[0m 0.001505\u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.5477  \u001b[0m | \u001b[0m 64.18   \u001b[0m | \u001b[0m 161.2   \u001b[0m | \u001b[0m 92.68   \u001b[0m | \u001b[0m 0.008264\u001b[0m | \u001b[0m 0.02024 \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.5522  \u001b[0m | \u001b[0m 68.11   \u001b[0m | \u001b[0m 156.4   \u001b[0m | \u001b[0m 97.6    \u001b[0m | \u001b[0m 0.03264 \u001b[0m | \u001b[0m 0.007303\u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.5502  \u001b[0m | \u001b[0m 65.94   \u001b[0m | \u001b[0m 163.4   \u001b[0m | \u001b[0m 94.33   \u001b[0m | \u001b[0m 0.01151 \u001b[0m | \u001b[0m 0.02666 \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.5421  \u001b[0m | \u001b[0m 70.51   \u001b[0m | \u001b[0m 156.1   \u001b[0m | \u001b[0m 93.65   \u001b[0m | \u001b[0m 0.0459  \u001b[0m | \u001b[0m 0.02067 \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.5519  \u001b[0m | \u001b[0m 81.04   \u001b[0m | \u001b[0m 167.6   \u001b[0m | \u001b[0m 89.47   \u001b[0m | \u001b[0m 0.02952 \u001b[0m | \u001b[0m 0.005757\u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.5463  \u001b[0m | \u001b[0m 29.72   \u001b[0m | \u001b[0m 241.8   \u001b[0m | \u001b[0m 66.61   \u001b[0m | \u001b[0m 0.01922 \u001b[0m | \u001b[0m 0.005486\u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.5527  \u001b[0m | \u001b[0m 32.26   \u001b[0m | \u001b[0m 249.9   \u001b[0m | \u001b[0m 48.95   \u001b[0m | \u001b[0m 0.03787 \u001b[0m | \u001b[0m 0.03714 \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.5447  \u001b[0m | \u001b[0m 98.05   \u001b[0m | \u001b[0m 179.3   \u001b[0m | \u001b[0m 54.49   \u001b[0m | \u001b[0m 0.006414\u001b[0m | \u001b[0m 0.02904 \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.5471  \u001b[0m | \u001b[0m 40.15   \u001b[0m | \u001b[0m 180.2   \u001b[0m | \u001b[0m 69.51   \u001b[0m | \u001b[0m 0.0184  \u001b[0m | \u001b[0m 0.02897 \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.5493  \u001b[0m | \u001b[0m 37.64   \u001b[0m | \u001b[0m 90.89   \u001b[0m | \u001b[0m 58.33   \u001b[0m | \u001b[0m 0.02228 \u001b[0m | \u001b[0m 0.01428 \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.5538  \u001b[0m | \u001b[0m 46.45   \u001b[0m | \u001b[0m 53.97   \u001b[0m | \u001b[0m 83.88   \u001b[0m | \u001b[0m 0.00664 \u001b[0m | \u001b[0m 0.03882 \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.5474  \u001b[0m | \u001b[0m 72.61   \u001b[0m | \u001b[0m 220.3   \u001b[0m | \u001b[0m 38.16   \u001b[0m | \u001b[0m 0.04811 \u001b[0m | \u001b[0m 0.01195 \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.5535  \u001b[0m | \u001b[0m 84.87   \u001b[0m | \u001b[0m 81.2    \u001b[0m | \u001b[0m 65.62   \u001b[0m | \u001b[0m 0.02453 \u001b[0m | \u001b[0m 0.02063 \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.5442  \u001b[0m | \u001b[0m 54.14   \u001b[0m | \u001b[0m 77.85   \u001b[0m | \u001b[0m 67.5    \u001b[0m | \u001b[0m 0.01833 \u001b[0m | \u001b[0m 0.03096 \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.5488  \u001b[0m | \u001b[0m 43.13   \u001b[0m | \u001b[0m 228.3   \u001b[0m | \u001b[0m 46.89   \u001b[0m | \u001b[0m 0.03406 \u001b[0m | \u001b[0m 0.04531 \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.5471  \u001b[0m | \u001b[0m 37.8    \u001b[0m | \u001b[0m 119.3   \u001b[0m | \u001b[0m 62.99   \u001b[0m | \u001b[0m 0.01192 \u001b[0m | \u001b[0m 0.03295 \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.5464  \u001b[0m | \u001b[0m 83.49   \u001b[0m | \u001b[0m 172.0   \u001b[0m | \u001b[0m 80.11   \u001b[0m | \u001b[0m 0.02095 \u001b[0m | \u001b[0m 0.01817 \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.546   \u001b[0m | \u001b[0m 10.22   \u001b[0m | \u001b[0m 129.9   \u001b[0m | \u001b[0m 92.09   \u001b[0m | \u001b[0m 0.04869 \u001b[0m | \u001b[0m 0.02234 \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.5476  \u001b[0m | \u001b[0m 66.16   \u001b[0m | \u001b[0m 160.5   \u001b[0m | \u001b[0m 90.94   \u001b[0m | \u001b[0m 0.01429 \u001b[0m | \u001b[0m 0.01195 \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.5508  \u001b[0m | \u001b[0m 24.15   \u001b[0m | \u001b[0m 241.6   \u001b[0m | \u001b[0m 41.85   \u001b[0m | \u001b[0m 0.04828 \u001b[0m | \u001b[0m 0.03796 \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.5524  \u001b[0m | \u001b[0m 14.75   \u001b[0m | \u001b[0m 246.3   \u001b[0m | \u001b[0m 36.73   \u001b[0m | \u001b[0m 0.04309 \u001b[0m | \u001b[0m 0.01097 \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.5394  \u001b[0m | \u001b[0m 5.1     \u001b[0m | \u001b[0m 112.4   \u001b[0m | \u001b[0m 99.55   \u001b[0m | \u001b[0m 0.000574\u001b[0m | \u001b[0m 0.02335 \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.5437  \u001b[0m | \u001b[0m 14.64   \u001b[0m | \u001b[0m 57.06   \u001b[0m | \u001b[0m 45.65   \u001b[0m | \u001b[0m 0.0299  \u001b[0m | \u001b[0m 0.0155  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.5486  \u001b[0m | \u001b[0m 99.7    \u001b[0m | \u001b[0m 162.4   \u001b[0m | \u001b[0m 26.04   \u001b[0m | \u001b[0m 0.02034 \u001b[0m | \u001b[0m 0.04056 \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.5512  \u001b[0m | \u001b[0m 26.15   \u001b[0m | \u001b[0m 128.5   \u001b[0m | \u001b[0m 59.4    \u001b[0m | \u001b[0m 0.01487 \u001b[0m | \u001b[0m 0.03325 \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.5479  \u001b[0m | \u001b[0m 69.82   \u001b[0m | \u001b[0m 156.0   \u001b[0m | \u001b[0m 95.62   \u001b[0m | \u001b[0m 0.03825 \u001b[0m | \u001b[0m 0.0343  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.5487  \u001b[0m | \u001b[0m 25.28   \u001b[0m | \u001b[0m 240.6   \u001b[0m | \u001b[0m 41.54   \u001b[0m | \u001b[0m 0.004665\u001b[0m | \u001b[0m 0.02199 \u001b[0m |\n",
      "| \u001b[95m 59      \u001b[0m | \u001b[95m 0.5553  \u001b[0m | \u001b[95m 74.62   \u001b[0m | \u001b[95m 138.6   \u001b[0m | \u001b[95m 42.67   \u001b[0m | \u001b[95m 0.0249  \u001b[0m | \u001b[95m 0.02317 \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.5459  \u001b[0m | \u001b[0m 27.67   \u001b[0m | \u001b[0m 202.6   \u001b[0m | \u001b[0m 43.5    \u001b[0m | \u001b[0m 0.009518\u001b[0m | \u001b[0m 0.03645 \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.5495  \u001b[0m | \u001b[0m 25.59   \u001b[0m | \u001b[0m 244.0   \u001b[0m | \u001b[0m 99.6    \u001b[0m | \u001b[0m 0.01085 \u001b[0m | \u001b[0m 0.02173 \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.5544  \u001b[0m | \u001b[0m 22.98   \u001b[0m | \u001b[0m 81.21   \u001b[0m | \u001b[0m 47.78   \u001b[0m | \u001b[0m 0.01837 \u001b[0m | \u001b[0m 0.0465  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.5448  \u001b[0m | \u001b[0m 66.12   \u001b[0m | \u001b[0m 163.5   \u001b[0m | \u001b[0m 93.86   \u001b[0m | \u001b[0m 0.045   \u001b[0m | \u001b[0m 0.004859\u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.5496  \u001b[0m | \u001b[0m 65.44   \u001b[0m | \u001b[0m 62.93   \u001b[0m | \u001b[0m 94.63   \u001b[0m | \u001b[0m 0.01357 \u001b[0m | \u001b[0m 0.04303 \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.5466  \u001b[0m | \u001b[0m 28.98   \u001b[0m | \u001b[0m 97.48   \u001b[0m | \u001b[0m 79.83   \u001b[0m | \u001b[0m 0.000395\u001b[0m | \u001b[0m 0.03771 \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.5496  \u001b[0m | \u001b[0m 15.07   \u001b[0m | \u001b[0m 96.63   \u001b[0m | \u001b[0m 80.95   \u001b[0m | \u001b[0m 0.000172\u001b[0m | \u001b[0m 0.04404 \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.5446  \u001b[0m | \u001b[0m 66.05   \u001b[0m | \u001b[0m 209.1   \u001b[0m | \u001b[0m 91.85   \u001b[0m | \u001b[0m 0.001075\u001b[0m | \u001b[0m 0.0276  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.5488  \u001b[0m | \u001b[0m 16.14   \u001b[0m | \u001b[0m 264.8   \u001b[0m | \u001b[0m 81.22   \u001b[0m | \u001b[0m 0.000943\u001b[0m | \u001b[0m 0.04781 \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.5514  \u001b[0m | \u001b[0m 27.74   \u001b[0m | \u001b[0m 196.5   \u001b[0m | \u001b[0m 88.11   \u001b[0m | \u001b[0m 0.0254  \u001b[0m | \u001b[0m 0.0318  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.5467  \u001b[0m | \u001b[0m 7.85    \u001b[0m | \u001b[0m 215.0   \u001b[0m | \u001b[0m 53.53   \u001b[0m | \u001b[0m 0.007122\u001b[0m | \u001b[0m 0.0444  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.5478  \u001b[0m | \u001b[0m 65.56   \u001b[0m | \u001b[0m 109.7   \u001b[0m | \u001b[0m 92.11   \u001b[0m | \u001b[0m 0.03747 \u001b[0m | \u001b[0m 0.03514 \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.5437  \u001b[0m | \u001b[0m 63.9    \u001b[0m | \u001b[0m 86.86   \u001b[0m | \u001b[0m 36.05   \u001b[0m | \u001b[0m 0.01316 \u001b[0m | \u001b[0m 0.04648 \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.5483  \u001b[0m | \u001b[0m 73.5    \u001b[0m | \u001b[0m 99.93   \u001b[0m | \u001b[0m 98.29   \u001b[0m | \u001b[0m 0.04133 \u001b[0m | \u001b[0m 0.02595 \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.5452  \u001b[0m | \u001b[0m 29.87   \u001b[0m | \u001b[0m 264.9   \u001b[0m | \u001b[0m 41.91   \u001b[0m | \u001b[0m 0.0323  \u001b[0m | \u001b[0m 0.01598 \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.5501  \u001b[0m | \u001b[0m 73.87   \u001b[0m | \u001b[0m 279.9   \u001b[0m | \u001b[0m 36.65   \u001b[0m | \u001b[0m 0.03905 \u001b[0m | \u001b[0m 0.03458 \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.5535  \u001b[0m | \u001b[0m 54.36   \u001b[0m | \u001b[0m 225.2   \u001b[0m | \u001b[0m 26.8    \u001b[0m | \u001b[0m 0.01225 \u001b[0m | \u001b[0m 0.03311 \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.5456  \u001b[0m | \u001b[0m 11.69   \u001b[0m | \u001b[0m 168.4   \u001b[0m | \u001b[0m 37.81   \u001b[0m | \u001b[0m 0.03012 \u001b[0m | \u001b[0m 0.01578 \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.5515  \u001b[0m | \u001b[0m 23.96   \u001b[0m | \u001b[0m 105.6   \u001b[0m | \u001b[0m 48.33   \u001b[0m | \u001b[0m 0.03671 \u001b[0m | \u001b[0m 0.01258 \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.5508  \u001b[0m | \u001b[0m 41.05   \u001b[0m | \u001b[0m 255.6   \u001b[0m | \u001b[0m 73.11   \u001b[0m | \u001b[0m 0.01199 \u001b[0m | \u001b[0m 0.04133 \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.5423  \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 79.33   \u001b[0m | \u001b[0m 87.32   \u001b[0m | \u001b[0m 0.02318 \u001b[0m | \u001b[0m 0.0136  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.5482  \u001b[0m | \u001b[0m 55.42   \u001b[0m | \u001b[0m 198.6   \u001b[0m | \u001b[0m 83.63   \u001b[0m | \u001b[0m 0.005105\u001b[0m | \u001b[0m 0.0291  \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.5419  \u001b[0m | \u001b[0m 59.97   \u001b[0m | \u001b[0m 82.98   \u001b[0m | \u001b[0m 77.47   \u001b[0m | \u001b[0m 0.03845 \u001b[0m | \u001b[0m 0.01965 \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.5421  \u001b[0m | \u001b[0m 63.42   \u001b[0m | \u001b[0m 118.9   \u001b[0m | \u001b[0m 75.62   \u001b[0m | \u001b[0m 0.04775 \u001b[0m | \u001b[0m 0.009735\u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.5517  \u001b[0m | \u001b[0m 62.97   \u001b[0m | \u001b[0m 159.1   \u001b[0m | \u001b[0m 37.78   \u001b[0m | \u001b[0m 0.02954 \u001b[0m | \u001b[0m 0.0443  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.5514  \u001b[0m | \u001b[0m 34.33   \u001b[0m | \u001b[0m 138.7   \u001b[0m | \u001b[0m 78.49   \u001b[0m | \u001b[0m 0.03152 \u001b[0m | \u001b[0m 0.04168 \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.5419  \u001b[0m | \u001b[0m 29.72   \u001b[0m | \u001b[0m 195.7   \u001b[0m | \u001b[0m 74.58   \u001b[0m | \u001b[0m 0.04851 \u001b[0m | \u001b[0m 0.04566 \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.5497  \u001b[0m | \u001b[0m 15.14   \u001b[0m | \u001b[0m 242.1   \u001b[0m | \u001b[0m 63.96   \u001b[0m | \u001b[0m 0.002896\u001b[0m | \u001b[0m 0.03585 \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.5473  \u001b[0m | \u001b[0m 13.49   \u001b[0m | \u001b[0m 283.4   \u001b[0m | \u001b[0m 62.11   \u001b[0m | \u001b[0m 0.002074\u001b[0m | \u001b[0m 0.04544 \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.5457  \u001b[0m | \u001b[0m 41.19   \u001b[0m | \u001b[0m 144.8   \u001b[0m | \u001b[0m 94.87   \u001b[0m | \u001b[0m 0.005027\u001b[0m | \u001b[0m 0.01738 \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.5491  \u001b[0m | \u001b[0m 68.02   \u001b[0m | \u001b[0m 124.5   \u001b[0m | \u001b[0m 53.29   \u001b[0m | \u001b[0m 0.02274 \u001b[0m | \u001b[0m 0.03406 \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.5475  \u001b[0m | \u001b[0m 92.71   \u001b[0m | \u001b[0m 199.6   \u001b[0m | \u001b[0m 75.28   \u001b[0m | \u001b[0m 0.02408 \u001b[0m | \u001b[0m 0.03923 \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.5454  \u001b[0m | \u001b[0m 89.32   \u001b[0m | \u001b[0m 228.5   \u001b[0m | \u001b[0m 49.68   \u001b[0m | \u001b[0m 0.01615 \u001b[0m | \u001b[0m 0.008562\u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.5439  \u001b[0m | \u001b[0m 59.94   \u001b[0m | \u001b[0m 154.9   \u001b[0m | \u001b[0m 84.12   \u001b[0m | \u001b[0m 0.04971 \u001b[0m | \u001b[0m 0.008497\u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.5551  \u001b[0m | \u001b[0m 24.17   \u001b[0m | \u001b[0m 187.5   \u001b[0m | \u001b[0m 65.63   \u001b[0m | \u001b[0m 0.03976 \u001b[0m | \u001b[0m 0.01191 \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.5482  \u001b[0m | \u001b[0m 82.37   \u001b[0m | \u001b[0m 194.2   \u001b[0m | \u001b[0m 53.79   \u001b[0m | \u001b[0m 0.007727\u001b[0m | \u001b[0m 0.02495 \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.5445  \u001b[0m | \u001b[0m 86.13   \u001b[0m | \u001b[0m 257.5   \u001b[0m | \u001b[0m 70.83   \u001b[0m | \u001b[0m 0.009088\u001b[0m | \u001b[0m 0.02769 \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.5534  \u001b[0m | \u001b[0m 33.52   \u001b[0m | \u001b[0m 103.6   \u001b[0m | \u001b[0m 82.01   \u001b[0m | \u001b[0m 0.03622 \u001b[0m | \u001b[0m 0.03937 \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.5482  \u001b[0m | \u001b[0m 30.48   \u001b[0m | \u001b[0m 68.79   \u001b[0m | \u001b[0m 92.44   \u001b[0m | \u001b[0m 0.04525 \u001b[0m | \u001b[0m 0.04176 \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.54    \u001b[0m | \u001b[0m 71.14   \u001b[0m | \u001b[0m 64.47   \u001b[0m | \u001b[0m 32.02   \u001b[0m | \u001b[0m 0.009109\u001b[0m | \u001b[0m 0.008254\u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.5502  \u001b[0m | \u001b[0m 15.68   \u001b[0m | \u001b[0m 178.7   \u001b[0m | \u001b[0m 58.35   \u001b[0m | \u001b[0m 0.02957 \u001b[0m | \u001b[0m 0.04873 \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 0.5411  \u001b[0m | \u001b[0m 83.56   \u001b[0m | \u001b[0m 222.9   \u001b[0m | \u001b[0m 98.76   \u001b[0m | \u001b[0m 0.04421 \u001b[0m | \u001b[0m 0.01124 \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 0.5496  \u001b[0m | \u001b[0m 19.1    \u001b[0m | \u001b[0m 280.8   \u001b[0m | \u001b[0m 78.51   \u001b[0m | \u001b[0m 0.04909 \u001b[0m | \u001b[0m 0.03978 \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "                                ('imputer', SimpleImputer(strategy = 'median')),\n",
    "                                ('scaler', RobustScaler())\n",
    "                                ])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "                                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                ])\n",
    "    \n",
    "def search_model_xgb(num_leaves,max_depth,n_estimators,reg_alpha,reg_lambda):\n",
    "    params = {\n",
    "         'max_depth':int(max_depth),\n",
    "         'n_estimators':int(n_estimators),\n",
    "         'reg_alpha':reg_alpha,\n",
    "         'reg_lambda':reg_lambda,\n",
    "#         'scale_pos_weight':scale_pos_weight,\n",
    "         'random_state':0,\n",
    "        'use_label_encoder':False,\n",
    "        'verbosity':0\n",
    "    }\n",
    "    xgb = XGBClassifier(**params)\n",
    "    transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols_fe),\n",
    "            ('cat', cat_transformer, cat_cols_fe)\n",
    "        ])\n",
    "    main_pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                      ('classifier', xgb)])\n",
    "    \n",
    "    aucs = []\n",
    "    for i in range(len(data_skf['train'])):\n",
    "        model = clone(main_pipeline)\n",
    "        model.fit(data_skf['train'][i][0],data_skf['train'][i][1].values)\n",
    "        pred_proba = model.predict_proba(data_skf['val'][i][0])[:,1]\n",
    "        \n",
    "        aucs.append(roc_auc_score(data_skf['val'][i][1].values, pred_proba,average='weighted'))\n",
    "    return np.mean(aucs)\n",
    "\n",
    "xgbBO = BayesianOptimization(search_model_xgb, {'num_leaves': (25, 100),\n",
    "                                        'max_depth': (5, 100),\n",
    "                                        'n_estimators':(50,300),\n",
    "                                        'reg_alpha': (0.0, 0.05),\n",
    "                                        'reg_lambda': (0.0, 0.05),\n",
    "#                                          'scale_pos_weight':(1,9)\n",
    "                                        },random_state=0)\n",
    "xgbBO.maximize(n_iter=100, init_points=2)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T15:49:57.927756Z",
     "start_time": "2021-02-15T15:49:57.919759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.5559541550075702,\n",
       " 'params': {'max_depth': 52.3160713621035,\n",
       "  'n_estimators': 278.30132378597926,\n",
       "  'num_leaves': 96.9938470728089,\n",
       "  'reg_alpha': 0.04800396971863674,\n",
       "  'reg_lambda': 0.047213768862403666,\n",
       "  'scale_pos_weight': 3.8022455273872264}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbBO.max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T15:52:49.745838Z",
     "start_time": "2021-02-15T15:52:49.740811Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type':'gbdt',\n",
    "     'max_depth': int(52.3160713621035),\n",
    "      'n_estimators': int(278.30132378597926),\n",
    "      'num_leaves': int(96.9938470728089),\n",
    "      'reg_alpha': 0.04800396971863674,\n",
    "      'reg_lambda': 0.047213768862403666,\n",
    "      'scale_pos_weight': 3.8022455273872264,\n",
    "     'random_state':0,\n",
    "        'use_label_encoder':False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T15:52:57.518245Z",
     "start_time": "2021-02-15T15:52:50.276248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5559541550075702"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xgb = XGBClassifier(**params)\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols_fe),\n",
    "        ('cat', cat_transformer, cat_cols_fe)\n",
    "    ])\n",
    "main_pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                  ('classifier', xgb)])\n",
    "\n",
    "aucs = []\n",
    "for i in range(len(data_skf['train'])):\n",
    "    model = clone(main_pipeline)\n",
    "    model.fit(data_skf['train'][i][0],data_skf['train'][i][1].values)\n",
    "    pred_proba = model.predict_proba(data_skf['val'][i][0])[:,1]\n",
    "\n",
    "    aucs.append(roc_auc_score(data_skf['val'][i][1].values, pred_proba,average='weighted'))\n",
    "\n",
    "np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
