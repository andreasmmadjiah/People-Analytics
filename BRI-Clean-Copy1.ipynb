{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:18.921811Z",
     "start_time": "2021-02-23T09:57:16.252355Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import calendar\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# from utils_model import * # expand later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:18.925756Z",
     "start_time": "2021-02-23T09:57:18.922724Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:19.016536Z",
     "start_time": "2021-02-23T09:57:18.926745Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "# data['gender'] = data['gender'].astype('str')\n",
    "# data_test['gender'] = data_test['gender'].astype('str')\n",
    "\n",
    "# data['Achievement_above_100%_during3quartal'] = data['Achievement_above_100%_during3quartal'].astype(str)\n",
    "# data_test['Achievement_above_100%_during3quartal'] = data_test['Achievement_above_100%_during3quartal'].astype(str)\n",
    "\n",
    "data = data.rename(columns={'annual leave':'annual_leave'})\n",
    "data_test = data_test.rename(columns={'annual leave':'annual_leave'})\n",
    "\n",
    "data = data.rename(columns={'Last_achievement_%':'Last_achievement','marital_status_maried(Y/N)':'marital_status_maried',\n",
    "                           'Achievement_above_100%_during3quartal':'Achievement_above_100_during3quartal'})\n",
    "data_test = data_test.rename(columns={'Last_achievement_%':'Last_achievement','marital_status_maried(Y/N)':'marital_status_maried',\n",
    "                           'Achievement_above_100%_during3quartal':'Achievement_above_100_during3quartal'})\n",
    "\n",
    "\n",
    "data['gender_str'] = data['gender'].astype('str')\n",
    "data_test['gender_str'] = data_test['gender'].astype('str')\n",
    "\n",
    "data['Achievement_above_100_during3quartal_str'] = data['Achievement_above_100_during3quartal'].astype(str)\n",
    "data_test['Achievement_above_100_during3quartal_str'] = data_test['Achievement_above_100_during3quartal'].astype(str)\n",
    "\n",
    "\n",
    "data['person_level_ordinary'] = LE.fit_transform(data['person_level'])\n",
    "data['job_level_ordinary'] = LE.fit_transform(data['job_level'])\n",
    "data['Education_level_ordinary'] = LE.fit_transform(data['Education_level'])\n",
    "\n",
    "data_test['person_level_ordinary'] = LE.fit_transform(data_test['person_level'])\n",
    "data_test['job_level_ordinary'] = LE.fit_transform(data_test['job_level'])\n",
    "data_test['Education_level_ordinary'] = LE.fit_transform(data_test['Education_level'])\n",
    "\n",
    "drop = ['age', 'job_duration_from_training', 'person_level_ordinary', 'job_level']\n",
    "\n",
    "\n",
    "data = data.drop(columns=drop)\n",
    "data_test = data_test.drop(columns=drop)\n",
    "# data = data[~data['Last_achievement_%'].isna()]\n",
    "# data = data.drop(columns=['job_level'])\n",
    "# data_test = data_test.drop(columns=['job_level'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:19.022519Z",
     "start_time": "2021-02-23T09:57:19.017533Z"
    }
   },
   "outputs": [],
   "source": [
    "# get test data (for final evaluation)\n",
    "X_train = data.drop(columns=['Best Performance'])\n",
    "y_train = data['Best Performance']\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:19.028508Z",
     "start_time": "2021-02-23T09:57:19.023486Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(X_train),len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:19.043433Z",
     "start_time": "2021-02-23T09:57:19.030468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 6, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = list(X_train.select_dtypes(exclude=['object']))\n",
    "cat_cols = list(X_train.select_dtypes(include=['object']))\n",
    "features = list(X_train.columns)\n",
    "len(num_cols),len(cat_cols),len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:19.512389Z",
     "start_time": "2021-02-23T09:57:19.480499Z"
    }
   },
   "outputs": [],
   "source": [
    "class Feature_Engineering:\n",
    "    def __init__(self,parameters):\n",
    "        self.parameters = parameters\n",
    "        self.target = parameters['target']\n",
    "    \n",
    "    @staticmethod  \n",
    "    def check_col(col):\n",
    "        if len(col.split(' '))>1:\n",
    "            col2 = '_'.join(col.split(' '))\n",
    "        else:\n",
    "            col2 = col\n",
    "        return col2\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_bin(data,col,n_bin,mode='cut'):\n",
    "        while True:\n",
    "            try:\n",
    "                if mode=='cut':\n",
    "                    _,bin_dummy = pd.cut(data[col],n_bin,retbins=True)\n",
    "                else:\n",
    "                    _,bin_dummy = pd.qcut(data[col],n_bin,retbins=True)\n",
    "            except:\n",
    "                n_bin -= 1\n",
    "                continue\n",
    "            break\n",
    "        return bin_dummy\n",
    "        \n",
    "    def fit(self,data_ori):\n",
    "        target = self.target\n",
    "        data = data_ori.copy()\n",
    "        for param in self.parameters['bin_numer_qcut']:\n",
    "            col = param[0]\n",
    "            n_bin = param[1]\n",
    "            bin_dummy = self.get_bin(data,col,n_bin,mode='qcut')\n",
    "            bin_dummy[0] = bin_dummy[0]-0.001\n",
    "            bin_dummy[-1] = np.inf\n",
    "            setattr(self,f'{col}_bin_numer_qcut',bin_dummy)\n",
    "        for param in self.parameters['bin_numer_cut']:\n",
    "            col = param[0]\n",
    "            n_bin = param[1]\n",
    "            bin_dummy = self.get_bin(data,col,n_bin,mode='cut')\n",
    "            bin_dummy[0] = bin_dummy[0]-0.001\n",
    "            bin_dummy[-1] = np.inf\n",
    "            setattr(self,f'{col}_bin_numer_cut',bin_dummy)\n",
    "            \n",
    "            \n",
    "        for param in self.parameters['bin_add_categ_numer_bin_cut']:\n",
    "            col = param[1]\n",
    "            n_bin = param[2]\n",
    "            bin_dummy = self.get_bin(data,col,n_bin,mode='cut')\n",
    "            bin_dummy[0] = bin_dummy[0]-0.001\n",
    "            bin_dummy[-1] = np.inf\n",
    "            setattr(self,f'{col}_bin_cut_add_categ',bin_dummy)\n",
    "            \n",
    "        for param in self.parameters['bin_add_categ_numer_bin_qcut']:\n",
    "            col = param[1]\n",
    "            n_bin = param[2]\n",
    "            bin_dummy = self.get_bin(data,col,n_bin,mode='qcut')\n",
    "            bin_dummy[0] = bin_dummy[0]-0.001\n",
    "            bin_dummy[-1] = np.inf\n",
    "            setattr(self,f'{col}_bin_qcut_add_categ',bin_dummy)\n",
    "        \n",
    "        for param in self.parameters['bin_target_encoding_cut']:\n",
    "            col = param[0]\n",
    "            n_bin = param[1]\n",
    "            bin_dummy = self.get_bin(data,col,n_bin,mode='cut')\n",
    "            bin_dummy[0] = bin_dummy[0]-0.001\n",
    "            bin_dummy[-1] = np.inf\n",
    "            setattr(self,f'{col}_bin_cut',bin_dummy)\n",
    "            \n",
    "            data[f'{col}_bin_target_encoding_cut'] = pd.cut(data[col],bins=bin_dummy)\n",
    "            data_dummy = data.groupby([f'{col}_bin_target_encoding_cut'])[target].mean().reset_index(drop=False)\n",
    "            setattr(self,f'{col}_bin_target_encoding_cut',data_dummy)\n",
    "            \n",
    "        for param in self.parameters['bin_target_encoding_qcut']:\n",
    "            col = param[0]\n",
    "            n_bin = param[1]\n",
    "            bin_dummy = self.get_bin(data,col,n_bin,mode='qcut')\n",
    "            bin_dummy[0] = bin_dummy[0]-0.001\n",
    "            bin_dummy[-1] = np.inf\n",
    "            setattr(self,f'{col}_bin_qcut',bin_dummy)\n",
    "            \n",
    "            data[f'{col}_bin_target_encoding_qcut'] = pd.cut(data[col],bins=bin_dummy)\n",
    "            data_dummy = data.groupby([f'{col}_bin_target_encoding_qcut'])[target].mean().reset_index(drop=False)\n",
    "            setattr(self,f'{col}_bin_target_encoding_qcut',data_dummy)\n",
    "           \n",
    "        for param in self.parameters['bin_target_encoding_custom_bin']:\n",
    "            col = param[0]\n",
    "            bins = param[1]\n",
    "            setattr(self,f'{col}_bin_custom_bin',bins)\n",
    "            \n",
    "            data[f'{col}_bin_target_encoding_custom_bin'] = pd.cut(data[col],bins=bins)\n",
    "            data_dummy = data.groupby([f'{col}_bin_target_encoding_custom_bin'])[target].mean().reset_index(drop=False)\n",
    "            setattr(self,f'{col}_bin_target_encoding_custom_bin',data_dummy)\n",
    "        \n",
    "        for param in self.parameters['categorical_mean_encoding']:\n",
    "            col = param\n",
    "            data[f'{col}_categorical_mean_encoding'] = data[col].copy().values\n",
    "            data_dummy = data.groupby([f'{col}_categorical_mean_encoding'])[target].mean().reset_index(drop=False)\n",
    "            setattr(self,f'{col}_categorical_mean_encoding',data_dummy)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fit = True\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def transform(self,X,mode='train'):\n",
    "        data = X.copy()\n",
    "        target = self.target\n",
    "        if mode!='train':\n",
    "            target_encode = self.target\n",
    "        else:\n",
    "            target_encode = self.target +\"_y\"\n",
    "            \n",
    "        if self.fit==False:\n",
    "            raise Exception(\"Fit to train data first\")\n",
    "        \n",
    "        for param in self.parameters['bin_numer_qcut']:\n",
    "            col = param[0]\n",
    "            bin_dummy = eval(f'self.{col}_bin_numer_qcut')\n",
    "            data[f'{col}_bin_numer_qcut'] = pd.cut(data[col],bins=bin_dummy).astype(str).values\n",
    "        for param in self.parameters['bin_numer_cut']:\n",
    "            col = param[0]\n",
    "            bin_dummy = eval(f'self.{col}_bin_numer_cut')\n",
    "            data[f'{col}_bin_numer_cut'] = pd.cut(data[col],bins=bin_dummy).astype(str).values\n",
    "            \n",
    "        for cols in self.parameters['bin_add_categ_numer_bin_cut']:\n",
    "            col_add = cols[0] + '_' + cols[1]\n",
    "            bin_dummy = eval(f'self.{cols[1]}_bin_cut_add_categ')\n",
    "            data[f'{col_add}_bin_add_categ_numer_bin_cut'] = pd.cut(data[cols[1]],bins=bin_dummy).values\n",
    "            data[f'{col_add}_bin_add_categ_numer_bin_cut'] = (data[cols[0]].astype(str)+'_' + data[f'{col_add}_bin_add_categ_numer_bin_cut'].astype(str)).values\n",
    "            \n",
    "        for cols in self.parameters['bin_add_categ_numer_bin_qcut']:\n",
    "            col_add = cols[0] + '_' + cols[1]\n",
    "            bin_dummy = eval(f'self.{cols[1]}_bin_qcut_add_categ')\n",
    "            data[f'{col_add}_bin_add_categ_numer_bin_qcut'] = pd.cut(data[cols[1]],bins=bin_dummy).values\n",
    "            data[f'{col_add}_bin_add_categ_numer_bin_qcut'] = (data[cols[0]].astype(str)+'_' + data[f'{col_add}_bin_add_categ_numer_bin_qcut'].astype(str)).values\n",
    "        \n",
    "        for param in self.parameters['bin_target_encoding_cut']:\n",
    "            col = param[0]\n",
    "            bin_dummy = eval(f'self.{col}_bin_cut')\n",
    "            data_dummy = eval(f'self.{col}_bin_target_encoding_cut')\n",
    "            data[f'{col}_bin_target_encoding_cut'] = pd.cut(data[col],bins=bin_dummy).values\n",
    "            data[f'{col}_bin_target_encoding_cut'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_bin_target_encoding_cut'])[f'{target_encode}'].values\n",
    "        \n",
    "        for param in self.parameters['bin_target_encoding_qcut']:\n",
    "            col = param[0]\n",
    "            bin_dummy = eval(f'self.{col}_bin_qcut')\n",
    "            data_dummy = eval(f'self.{col}_bin_target_encoding_qcut')\n",
    "            data[f'{col}_bin_target_encoding_qcut'] = pd.cut(data[col],bins=bin_dummy).values\n",
    "            data[f'{col}_bin_target_encoding_qcut'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_bin_target_encoding_qcut'])[f'{target_encode}'].values\n",
    "        \n",
    "        for param in self.parameters['bin_target_encoding_custom_bin']:\n",
    "            col = param[0]\n",
    "            bin_dummy = eval(f'self.{col}_bin_custom_bin')\n",
    "            data_dummy = eval(f'self.{col}_bin_target_encoding_custom_bin')\n",
    "            data[f'{col}_bin_target_encoding_custom_bin'] = pd.cut(data[col],bins=bin_dummy).values\n",
    "            data[f'{col}_bin_target_encoding_custom_bin'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_bin_target_encoding_custom_bin'])[f'{target_encode}'].values\n",
    "        \n",
    "        for param in self.parameters['categorical_mean_encoding']:\n",
    "            col = param\n",
    "            data_dummy = eval(f'self.{col}_categorical_mean_encoding')\n",
    "            data[f'{col}_categorical_mean_encoding'] = data[col].copy().values\n",
    "            data[f'{col}_categorical_mean_encoding'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_categorical_mean_encoding'])[f'{target_encode}'].values\n",
    "        \n",
    "        \n",
    "        for cols in self.parameters['multiply']:\n",
    "            data[cols[0] + '_times_' +cols[1]] = (data[cols[0]] * data[cols[1]]).values\n",
    "        for cols in self.parameters['add']:\n",
    "            data[cols[0] + '_plus_' +cols[1]] = (data[cols[0]] + data[cols[1]]).values\n",
    "        for cols in self.parameters['add_str']:\n",
    "            data[cols[0] + '_plus_' +cols[1]] = (data[cols[0]].astype(str)+'_' + data[cols[1]].astype(str)).values\n",
    "            \n",
    "        for cols in self.parameters['substract']:\n",
    "            data[cols[0] + '_minus_' +cols[1]] = (data[cols[0]] - data[cols[1]]).values\n",
    "        for cols in self.parameters['divide']:\n",
    "            data[cols[0] + '_divide_' +cols[1]] = (data[cols[0]] / np.where(data[cols[1]]==0,0.0001,data[cols[1]])).values\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:26.403862Z",
     "start_time": "2021-02-23T09:57:26.391862Z"
    }
   },
   "outputs": [],
   "source": [
    "def fast_build_model_FE(X,y,cv,Feature_Engineering,parameters,model_base=LogisticRegression(class_weight='balanced')):\n",
    "\n",
    "    num_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "                                    ('scaler', RobustScaler())\n",
    "                                    ])\n",
    "\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                    ])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv,random_state = 3,shuffle = True)\n",
    "\n",
    "\n",
    "    # oof validation\n",
    "    oof_y_valid = []\n",
    "    oof_y_valid_pred = []\n",
    "    oof_y_valid_pred_proba = []\n",
    "    pipelines = []\n",
    "    add_fes = []\n",
    "    data = pd.concat([X,y],axis=1)\n",
    "    aucs=[]\n",
    "#     print(data.columns)\n",
    "    for cv,(train_index, val_index) in enumerate(skf.split(X,y)):\n",
    "        start_fit = time.time()\n",
    "        data_train = data.iloc[train_index,:].copy()\n",
    "#         data_val = data.iloc[val_index,:][features]\n",
    "        \n",
    "        add_fe = Feature_Engineering(parameters)\n",
    "        add_fe.fit(data_train)\n",
    "        \n",
    "        X_train = add_fe.transform(data_train).drop(columns=[parameters['target']])\n",
    "        num_cols_fe = list(X_train.select_dtypes(exclude='object').columns)\n",
    "        cat_cols_fe = list(X_train.select_dtypes(include='object').columns)\n",
    "        \n",
    "        print(X_train.shape,data.shape)\n",
    "        y_train = y.iloc[train_index]\n",
    "        \n",
    "        X_val = add_fe.transform(X.iloc[val_index,:],mode='val')\n",
    "        y_val = y.iloc[val_index]\n",
    "        print(X_val.shape,data.shape)\n",
    "        \n",
    "        transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols_fe),\n",
    "            ('cat', cat_transformer, cat_cols_fe)\n",
    "        ])\n",
    "        \n",
    "        main_pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                          ('classifier', model_base)])\n",
    "        \n",
    "\n",
    "        \n",
    "        add_fes.append(add_fe)\n",
    "        model = clone(main_pipeline)\n",
    "        model.fit(X_train,y_train.values.ravel())\n",
    "        pred = model.predict(X_val)\n",
    "        pred_proba = model.predict_proba(X_val)[:,1]\n",
    "        oof_y_valid_pred.extend(pred)\n",
    "        oof_y_valid_pred_proba.extend(pred_proba)\n",
    "        oof_y_valid.extend(y_val.values)\n",
    "        aucs.append(roc_auc_score(y_val.values, pred_proba,average='weighted'))\n",
    "        pipelines.append(model)\n",
    "        print(f'Fit iteration {cv} done in : {str(time.time()-start_fit)}')\n",
    "\n",
    "    prec,rec,f1, _ = precision_recall_fscore_support(oof_y_valid,oof_y_valid_pred)\n",
    "    auc = roc_auc_score(oof_y_valid, oof_y_valid_pred_proba,average='weighted')\n",
    "    print(f'PRec Rec AUC average : {prec} {rec} <==> {auc}')\n",
    "    print(aucs)\n",
    "    print(np.mean(aucs[:2]))\n",
    "    return add_fes,pipelines\n",
    "\n",
    "\n",
    "def fast_predict_FE(data,add_fes,pipelines):\n",
    "    X = data.copy()\n",
    "#     pred = np.zeros(1,len(X))\n",
    "    pred_proba = np.zeros((len(X)))\n",
    "    for i in range(len(pipelines)):\n",
    "        \n",
    "        pred_proba += pipelines[i].predict_proba(add_fes[i].transform(X,mode='test'))[:,1] / len(pipelines)\n",
    "    \n",
    "    return pred_proba\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:08:14.156342Z",
     "start_time": "2021-02-15T14:08:14.141349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job_duration_in_current_job_level',\n",
       " 'job_duration_in_current_person_level',\n",
       " 'job_duration_in_current_branch',\n",
       " 'age',\n",
       " 'number_of_dependences',\n",
       " 'GPA',\n",
       " 'year_graduated',\n",
       " 'job_duration_from_training',\n",
       " 'branch_rotation',\n",
       " 'job_rotation',\n",
       " 'assign_of_otherposition',\n",
       " 'annual_leave',\n",
       " 'sick_leaves',\n",
       " 'Last_achievement']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:08:14.442020Z",
     "start_time": "2021-02-15T14:08:14.432020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job_level',\n",
       " 'person_level',\n",
       " 'Employee_type',\n",
       " 'gender',\n",
       " 'marital_status_maried(Y/N)',\n",
       " 'Education_level',\n",
       " 'Achievement_above_100%_during3quartal']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:10:08.712689Z",
     "start_time": "2021-02-13T14:10:08.695691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11153.000000\n",
       "mean         1.034646\n",
       "std          0.416723\n",
       "min          0.000000\n",
       "25%          0.707107\n",
       "50%          1.118034\n",
       "75%          1.224745\n",
       "max          2.677686\n",
       "Name: job_duration_in_current_branch, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['job_duration_in_current_branch'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T15:50:31.133854Z",
     "start_time": "2021-02-14T15:50:31.113870Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'multiply':[['GPA','number_of_dependences']],\n",
    "              'add':[['annual_leave','sick_leaves'],['assign_of_otherposition','branch_rotation']],\n",
    "              'add_str':[['Education_level','job_level']],\n",
    "              'substract':[],'divide':[],\n",
    "              'bin_numer_qcut':[],\n",
    "              'bin_numer_cut':[],\n",
    "              'bin_add_categ_numer_bin_qcut':[['job_level','GPA',5],['Education_level','GPA',5]],\n",
    "            'bin_target_encoding_cut':[],\n",
    "             'bin_target_encoding_qcut':[['year_graduated',5],['GPA',5],['annual_leave',5]],\n",
    "             'bin_target_encoding_custom_bin':[],\n",
    "              'categorical_mean_encoding':['job_level','person_level','Employee_type','Education_level'],\n",
    "             'target':'Best Performance'}\n",
    "\n",
    "\n",
    "# parameters = {'multiply':[['GPA','number_of_dependences']],\n",
    "#               'add':[],\n",
    "#               'add_str':[],\n",
    "#               'substract':[],\n",
    "#               'divide':[],\n",
    "#               'bin_numer_qcut':[],\n",
    "#               'bin_numer_cut':[],\n",
    "#               'bin_add_categ_numer_bin_qcut':[],\n",
    "#             'bin_target_encoding_cut':[],\n",
    "#              'bin_target_encoding_qcut':[['year_graduated',5],['GPA',5],['annual_leave',5]],\n",
    "#              'bin_target_encoding_custom_bin':[],\n",
    "#               'categorical_mean_encoding':[],\n",
    "#              'target':'Best Performance'}\n",
    "\n",
    "\n",
    "# parameters = {'multiply':[],\n",
    "#               'add':[],\n",
    "#               'add_str':[],\n",
    "#               'substract':[],\n",
    "#               'divide':[],\n",
    "#               'bin_numer_qcut':[],\n",
    "#               'bin_numer_cut':[],\n",
    "#               'bin_add_categ_numer_bin_qcut':[],\n",
    "#             'bin_target_encoding_cut':[],\n",
    "#              'bin_target_encoding_qcut':[],\n",
    "#              'bin_target_encoding_custom_bin':[],\n",
    "#               'categorical_mean_encoding':[],\n",
    "#              'target':'Best Performance'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T05:19:41.389671Z",
     "start_time": "2021-02-22T05:19:41.381704Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters = {'multiply':[['GPA','number_of_dependences']],\n",
    "#               'add':[['annual_leave','sick_leaves'],['assign_of_otherposition','branch_rotation']],\n",
    "#               'add_str':[['Education_level','job_level']],\n",
    "#               'substract':[],'divide':[],\n",
    "#               'bin_numer_qcut':[],\n",
    "#               'bin_numer_cut':[['GPA',30]],\n",
    "#               'bin_add_categ_numer_bin_qcut':[['job_level','GPA',5],['Education_level','GPA',5]],\n",
    "#             'bin_target_encoding_cut':[],\n",
    "#              'bin_target_encoding_qcut':[['year_graduated',5],['GPA',5],['annual_leave',5]],\n",
    "#              'bin_target_encoding_custom_bin':[],\n",
    "#               'categorical_mean_encoding':['job_level','person_level','Employee_type','Education_level'],\n",
    "#              'target':'Best Performance'}\n",
    "\n",
    "\n",
    "parameters = {'multiply':[['job_duration_in_current_job_level','number_of_dependences'],\n",
    "                         ['job_duration_in_current_job_level','job_rotation'],\n",
    "                         ['job_duration_in_current_job_level','job_level_ordinary'],\n",
    "                         ['gender','GPA'],['gender','year_graduated'],['gender','sick_leaves'],['gender','job_level_ordinary'],\n",
    "                         ['number_of_dependences','year_graduated'],['number_of_dependences','annual_leave'],['number_of_dependences','job_level_ordinary'],\n",
    "                         ['GPA','branch_rotation'],['year_graduated','job_level_ordinary']],\n",
    "              'add':[],\n",
    "              'add_str':[['person_level','Education_level'],['Employee_type','Education_level']],\n",
    "              'substract':[],\n",
    "              'divide':[],\n",
    "              'bin_numer_qcut':[['assign_of_otherposition',10],['Last_achievement',10]],\n",
    "              'bin_numer_cut':[['Last_achievement',20]],\n",
    "              'bin_add_categ_numer_bin_cut':[],\n",
    "              'bin_add_categ_numer_bin_qcut':[],\n",
    "            'bin_target_encoding_cut':[['job_duration_in_current_job_level',10],['assign_of_otherposition',20]],\n",
    "             'bin_target_encoding_qcut':[['job_duration_in_current_branch',10]\n",
    "                                        ],\n",
    "             'bin_target_encoding_custom_bin':[],\n",
    "              'categorical_mean_encoding':[],\n",
    "             'target':'Best Performance'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T05:19:41.579699Z",
     "start_time": "2021-02-22T05:19:41.568706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job_duration_in_current_job_level',\n",
       " 'job_duration_in_current_person_level',\n",
       " 'job_duration_in_current_branch',\n",
       " 'gender',\n",
       " 'number_of_dependences',\n",
       " 'GPA',\n",
       " 'year_graduated',\n",
       " 'branch_rotation',\n",
       " 'job_rotation',\n",
       " 'assign_of_otherposition',\n",
       " 'annual_leave',\n",
       " 'sick_leaves',\n",
       " 'Last_achievement',\n",
       " 'Achievement_above_100_during3quartal',\n",
       " 'job_level_ordinary',\n",
       " 'Education_level_ordinary']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T05:20:46.616322Z",
     "start_time": "2021-02-22T05:20:42.324658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8922, 42) (11153, 23)\n",
      "(2231, 42) (11153, 23)\n",
      "Fit iteration 0 done in : 0.875169038772583\n",
      "(8922, 42) (11153, 23)\n",
      "(2231, 42) (11153, 23)\n",
      "Fit iteration 1 done in : 0.7901849746704102\n",
      "(8922, 42) (11153, 23)\n",
      "(2231, 42) (11153, 23)\n",
      "Fit iteration 2 done in : 0.8934223651885986\n",
      "(8923, 42) (11153, 23)\n",
      "(2230, 42) (11153, 23)\n",
      "Fit iteration 3 done in : 0.8351471424102783\n",
      "(8923, 42) (11153, 23)\n",
      "(2230, 42) (11153, 23)\n",
      "Fit iteration 4 done in : 0.8423306941986084\n",
      "PRec Rec AUC average : [0.87365591 0.17747364] [0.6147541  0.48320098] <==> 0.5650265777497719\n",
      "[0.5803876596510164, 0.5668729092703434, 0.571831383053715, 0.5822723174900085, 0.5303327596375271]\n",
      "0.5736302844606799\n"
     ]
    }
   ],
   "source": [
    "cv=5\n",
    "add_fes,pipelines = fast_build_model_FE(X_train,y_train,cv,\n",
    "                    Feature_Engineering,parameters,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=3000,C=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T19:32:59.041733Z",
     "start_time": "2021-02-20T19:32:58.184493Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_proba = fast_predict_FE(data_test.copy(),add_fes,pipelines)\n",
    "\n",
    "df_submission = pd.DataFrame({'index':data_test.index,'Best Performance':pred_proba})\n",
    "df_submission\n",
    "\n",
    "df_submission.to_csv('df_submission_20feb_LOGREG5CV057968_FE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T19:32:22.623536Z",
     "start_time": "2021-02-20T19:32:22.617536Z"
    }
   },
   "outputs": [],
   "source": [
    "# params = {'C': 4.599171011731616,\n",
    "#  'class_weight': {0.0: 0.19089603168342784, 1.0: 1.938865730782311},\n",
    "#  'random_state': 0,\n",
    "#  'max_iter': 10000}\n",
    "# cv=5\n",
    "# add_fes,pipelines = fast_build_model_FE(X_train,y_train,cv,\n",
    "#                     Feature_Engineering,parameters,model_base=LogisticRegression(**params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T19:33:03.381320Z",
     "start_time": "2021-02-20T19:33:03.367290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Best Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.429413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.536009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.649043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.410727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.580435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>5995</td>\n",
       "      <td>0.455349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>5996</td>\n",
       "      <td>0.454197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>5997</td>\n",
       "      <td>0.400584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>5998</td>\n",
       "      <td>0.408598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>5999</td>\n",
       "      <td>0.503052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Best Performance\n",
       "0         0          0.429413\n",
       "1         1          0.536009\n",
       "2         2          0.649043\n",
       "3         3          0.410727\n",
       "4         4          0.580435\n",
       "...     ...               ...\n",
       "5995   5995          0.455349\n",
       "5996   5996          0.454197\n",
       "5997   5997          0.400584\n",
       "5998   5998          0.408598\n",
       "5999   5999          0.503052\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T18:30:07.967442Z",
     "start_time": "2021-02-20T18:30:07.951449Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'multiply':[['job_duration_in_current_job_level','number_of_dependences'],\n",
    "                         ['job_duration_in_current_job_level','job_rotation'],\n",
    "                         ['job_duration_in_current_job_level','job_level_ordinary'],\n",
    "                         ['gender','GPA'],['gender','year_graduated'],['gender','sick_leaves'],['gender','job_level_ordinary'],\n",
    "                         ['number_of_dependences','year_graduated'],['number_of_dependences','annual_leave'],['number_of_dependences','job_level_ordinary'],\n",
    "                         ['GPA','branch_rotation'],['year_graduated','job_level_ordinary']],\n",
    "              'add':[],\n",
    "              'add_str':[['person_level','Education_level'],['Employee_type','Education_level']],\n",
    "              'substract':[],\n",
    "              'divide':[],\n",
    "              'bin_numer_qcut':[['assign_of_otherposition',10],['Last_achievement',10]],\n",
    "              'bin_numer_cut':[['Last_achievement',20]],\n",
    "              'bin_add_categ_numer_bin_qcut':[],\n",
    "            'bin_target_encoding_cut':[['job_duration_in_current_job_level',10],['assign_of_otherposition',20]],\n",
    "             'bin_target_encoding_qcut':[['job_duration_in_current_branch',10]\n",
    "                                        ],\n",
    "             'bin_target_encoding_custom_bin':[],\n",
    "              'categorical_mean_encoding':[],\n",
    "             'target':'Best Performance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T19:24:54.304694Z",
     "start_time": "2021-02-20T18:55:54.279145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8922, 42) (11153, 23)\n",
      "(2231, 42) (11153, 23)\n",
      "Fit iteration 0 done in : 389.66250944137573\n",
      "(8922, 42) (11153, 23)\n",
      "(2231, 42) (11153, 23)\n",
      "Fit iteration 1 done in : 343.26217770576477\n",
      "(8922, 42) (11153, 23)\n",
      "(2231, 42) (11153, 23)\n",
      "Fit iteration 2 done in : 360.49450063705444\n",
      "(8923, 42) (11153, 23)\n",
      "(2230, 42) (11153, 23)\n",
      "Fit iteration 3 done in : 324.6629695892334\n",
      "(8923, 42) (11153, 23)\n",
      "(2230, 42) (11153, 23)\n",
      "Fit iteration 4 done in : 321.88740038871765\n",
      "PRec Rec AUC average : [0.8745357  0.18666323] [0.66803279 0.44288332] <==> 0.5799965103944795\n",
      "[0.604585871045666, 0.5815224356920395, 0.5899910923701985, 0.5778418431544592, 0.5550016793056513]\n",
      "0.5930541533688527\n"
     ]
    }
   ],
   "source": [
    "cv=5\n",
    "add_fes,pipelines = fast_build_model_FE(X_train,y_train,cv,\n",
    "                    Feature_Engineering,parameters,model_base=SVC(class_weight='balanced',probability=True,kernel='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T19:27:49.327599Z",
     "start_time": "2021-02-20T19:27:15.392600Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_proba = fast_predict_FE(data_test.copy(),add_fes,pipelines)\n",
    "\n",
    "df_submission = pd.DataFrame({'index':data_test.index,'Best Performance':pred_proba})\n",
    "df_submission\n",
    "\n",
    "df_submission.to_csv('df_submission_20feb_SCV5CV05799_FE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T19:28:21.015435Z",
     "start_time": "2021-02-20T19:28:20.991403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Best Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.125095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.154628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.210143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.122740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.171385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>5995</td>\n",
       "      <td>0.129253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>5996</td>\n",
       "      <td>0.132509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>5997</td>\n",
       "      <td>0.118102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>5998</td>\n",
       "      <td>0.122387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>5999</td>\n",
       "      <td>0.154152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Best Performance\n",
       "0         0          0.125095\n",
       "1         1          0.154628\n",
       "2         2          0.210143\n",
       "3         3          0.122740\n",
       "4         4          0.171385\n",
       "...     ...               ...\n",
       "5995   5995          0.129253\n",
       "5996   5996          0.132509\n",
       "5997   5997          0.118102\n",
       "5998   5998          0.122387\n",
       "5999   5999          0.154152\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-20T19:29:35.518450Z",
     "start_time": "2021-02-20T19:29:35.478474Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"pipelines_05799_SCV.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pipelines, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:35.283075Z",
     "start_time": "2021-02-23T09:57:35.271076Z"
    }
   },
   "outputs": [],
   "source": [
    "def fast_build_model_FE_1(X,y,Feature_Engineering,parameters,model_base=LogisticRegression(class_weight='balanced')):\n",
    "\n",
    "    num_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "                                    ('scaler', RobustScaler())\n",
    "                                    ])\n",
    "\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                    ])\n",
    "    data = pd.concat([X,y],axis=1)\n",
    "    aucs=[]\n",
    "    start_fit = time.time()\n",
    "    data_train = data.copy()\n",
    "    add_fe = Feature_Engineering(parameters)\n",
    "    add_fe.fit(data_train)\n",
    "\n",
    "    X_train = add_fe.transform(data_train).drop(columns=[parameters['target']])\n",
    "    num_cols_fe = list(X_train.select_dtypes(exclude='object').columns)\n",
    "    cat_cols_fe = list(X_train.select_dtypes(include='object').columns)\n",
    "\n",
    "    y_train = y\n",
    "\n",
    "    \n",
    "    transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols_fe),\n",
    "        ('cat', cat_transformer, cat_cols_fe)\n",
    "    ])\n",
    "\n",
    "    main_pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                      ('classifier', model_base)])\n",
    "\n",
    "\n",
    "\n",
    "#     add_fes.append(add_fe)\n",
    "    model = clone(main_pipeline)\n",
    "    model.fit(X_train,y_train.values.ravel())\n",
    "    \n",
    "    return [add_fe],[model]\n",
    "\n",
    "\n",
    "def fast_build_model_FE_2fe_1(X,y,Feature_Engineering,parameters1,parameters2,model_base=LogisticRegression(class_weight='balanced')):\n",
    "\n",
    "    num_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "                                    ('scaler', RobustScaler())\n",
    "                                    ])\n",
    "\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                    ])\n",
    "    data = pd.concat([X,y],axis=1)\n",
    "    aucs=[]\n",
    "    start_fit = time.time()\n",
    "    data_train = data.copy()\n",
    "    add_fe1 = Feature_Engineering(parameters1)\n",
    "    add_fe2 = Feature_Engineering(parameters2)\n",
    "    \n",
    "    X_train = add_fe1.transform(data_train)\n",
    "    add_fe2.fit(X_train)\n",
    "    X_train = add_fe2.transform(X_train).drop(columns=[parameters1['target']])\n",
    "\n",
    "    num_cols_fe = list(X_train.select_dtypes(exclude='object').columns)\n",
    "    cat_cols_fe = list(X_train.select_dtypes(include='object').columns)\n",
    "    y_train = y.iloc[train_index]\n",
    "\n",
    "\n",
    "    transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols_fe),\n",
    "        ('cat', cat_transformer, cat_cols_fe)\n",
    "    ])\n",
    "\n",
    "    main_pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                      ('classifier', model_base)])\n",
    "\n",
    "\n",
    "\n",
    "    model = clone(main_pipeline)\n",
    "    model.fit(X_train,y_train.values.ravel())\n",
    "    \n",
    "    \n",
    "    return [add_fe1],[add_fe2],[model]\n",
    "\n",
    "\n",
    "\n",
    "def fast_predict_FE(data,add_fes,pipelines):\n",
    "    X = data.copy()\n",
    "#     pred = np.zeros(1,len(X))\n",
    "    pred_proba = np.zeros((len(X)))\n",
    "    for i in range(len(pipelines)):\n",
    "        \n",
    "        pred_proba += pipelines[i].predict_proba(add_fes[i].transform(X,mode='test'))[:,1] / len(pipelines)\n",
    "    \n",
    "    return pred_proba\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:35.647102Z",
     "start_time": "2021-02-23T09:57:35.635133Z"
    }
   },
   "outputs": [],
   "source": [
    "def fast_build_model_FE_automatic(X,y,cv,Feature_Engineering,parameters,model_base=LogisticRegression(class_weight='balanced')):\n",
    "\n",
    "    num_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "                                    ('scaler', RobustScaler())\n",
    "                                    ])\n",
    "\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                    ])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv,random_state = 3,shuffle = True)\n",
    "\n",
    "\n",
    "    # oof validation\n",
    "    oof_y_valid = []\n",
    "    oof_y_valid_pred = []\n",
    "    oof_y_valid_pred_proba = []\n",
    "    pipelines = []\n",
    "    add_fes = []\n",
    "    data = pd.concat([X,y],axis=1)\n",
    "    aucs=[]\n",
    "#     print(data.columns)\n",
    "    for cv,(train_index, val_index) in enumerate(skf.split(X,y)):\n",
    "        start_fit = time.time()\n",
    "        data_train = data.iloc[train_index,:].copy()\n",
    "#         data_val = data.iloc[val_index,:][features]\n",
    "        \n",
    "        add_fe = Feature_Engineering(parameters)\n",
    "        add_fe.fit(data_train)\n",
    "        \n",
    "        X_train = add_fe.transform(data_train).drop(columns=[parameters['target']])\n",
    "        num_cols_fe = list(X_train.select_dtypes(exclude='object').columns)\n",
    "        cat_cols_fe = list(X_train.select_dtypes(include='object').columns)\n",
    "        \n",
    "\n",
    "        y_train = y.iloc[train_index]\n",
    "        \n",
    "        X_val = add_fe.transform(X.iloc[val_index,:],mode='val')\n",
    "        y_val = y.iloc[val_index]\n",
    "        \n",
    "        \n",
    "        transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols_fe),\n",
    "            ('cat', cat_transformer, cat_cols_fe)\n",
    "        ])\n",
    "        \n",
    "        main_pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                          ('classifier', model_base)])\n",
    "        \n",
    "\n",
    "        \n",
    "        add_fes.append(add_fe)\n",
    "        model = clone(main_pipeline)\n",
    "        model.fit(X_train,y_train.values.ravel())\n",
    "        pred = model.predict(X_val)\n",
    "        pred_proba = model.predict_proba(X_val)[:,1]\n",
    "        oof_y_valid_pred.extend(pred)\n",
    "        oof_y_valid_pred_proba.extend(pred_proba)\n",
    "        oof_y_valid.extend(y_val.values)\n",
    "        aucs.append(roc_auc_score(y_val.values, pred_proba,average='weighted'))\n",
    "        pipelines.append(model)\n",
    "#         print(f'Fit iteration {cv} done in : {str(time.time()-start_fit)}')\n",
    "\n",
    "    prec,rec,f1, _ = precision_recall_fscore_support(oof_y_valid,oof_y_valid_pred)\n",
    "    auc = roc_auc_score(oof_y_valid, oof_y_valid_pred_proba,average='weighted')\n",
    "#     print(f'PRec Rec AUC average : {prec} {rec} <==> {auc}')\n",
    "#     print(np.mean(aucs))\n",
    "    return auc\n",
    "\n",
    "\n",
    "def fast_predict_FE(data,add_fes,pipelines):\n",
    "    X = data.copy()\n",
    "#     pred = np.zeros(1,len(X))\n",
    "    pred_proba = np.zeros((len(X)))\n",
    "    for i in range(len(pipelines)):\n",
    "        \n",
    "        pred_proba += pipelines[i].predict_proba(add_fes[i].transform(X,mode='test'))[:,1] / len(pipelines)\n",
    "    \n",
    "    return pred_proba\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:42.811047Z",
     "start_time": "2021-02-23T09:57:42.798112Z"
    }
   },
   "outputs": [],
   "source": [
    "def fast_build_model_FE_automatic_2(X,y,cv,Feature_Engineering,parameters1,parameters2,model_base=LogisticRegression(class_weight='balanced')):\n",
    "\n",
    "    num_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "                                    ('scaler', RobustScaler())\n",
    "                                    ])\n",
    "\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                    ])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv,random_state = 3,shuffle = True)\n",
    "\n",
    "\n",
    "    # oof validation\n",
    "    oof_y_valid = []\n",
    "    oof_y_valid_pred = []\n",
    "    oof_y_valid_pred_proba = []\n",
    "    pipelines = []\n",
    "    add_fes1 = []\n",
    "    add_fes2 = []\n",
    "    data = pd.concat([X,y],axis=1)\n",
    "    aucs=[]\n",
    "#     print(data.columns)\n",
    "    for cv,(train_index, val_index) in enumerate(skf.split(X,y)):\n",
    "        start_fit = time.time()\n",
    "        data_train = data.iloc[train_index,:].copy()\n",
    "#         data_val = data.iloc[val_index,:][features]\n",
    "        \n",
    "        add_fe1 = Feature_Engineering(parameters1)\n",
    "        add_fe2 = Feature_Engineering(parameters2)\n",
    "        add_fe1.fit(data_train)\n",
    "        \n",
    "        X_train = add_fe1.transform(data_train)\n",
    "        add_fe2.fit(X_train)\n",
    "        X_train = add_fe2.transform(X_train).drop(columns=[parameters1['target']])\n",
    "        \n",
    "        num_cols_fe = list(X_train.select_dtypes(exclude='object').columns)\n",
    "        cat_cols_fe = list(X_train.select_dtypes(include='object').columns)\n",
    "        \n",
    "\n",
    "        y_train = y.iloc[train_index]\n",
    "        \n",
    "        X_val = add_fe1.transform(X.iloc[val_index,:],mode='val')\n",
    "        X_val = add_fe2.transform(X_val,mode='val')\n",
    "        y_val = y.iloc[val_index]\n",
    "        \n",
    "        \n",
    "        transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols_fe),\n",
    "            ('cat', cat_transformer, cat_cols_fe)\n",
    "        ])\n",
    "        \n",
    "        main_pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                          ('classifier', model_base)])\n",
    "        \n",
    "\n",
    "        \n",
    "        add_fes1.append(add_fe1)\n",
    "        add_fes2.append(add_fe2)\n",
    "        model = clone(main_pipeline)\n",
    "        model.fit(X_train,y_train.values.ravel())\n",
    "        pred = model.predict(X_val)\n",
    "        pred_proba = model.predict_proba(X_val)[:,1]\n",
    "        oof_y_valid_pred.extend(pred)\n",
    "        oof_y_valid_pred_proba.extend(pred_proba)\n",
    "        oof_y_valid.extend(y_val.values)\n",
    "        aucs.append(roc_auc_score(y_val.values, pred_proba,average='weighted'))\n",
    "        pipelines.append(model)\n",
    "#         print(f'Fit iteration {cv} done in : {str(time.time()-start_fit)}')\n",
    "\n",
    "    prec,rec,f1, _ = precision_recall_fscore_support(oof_y_valid,oof_y_valid_pred)\n",
    "    auc = roc_auc_score(oof_y_valid, oof_y_valid_pred_proba,average='weighted')\n",
    "#     print(f'PRec Rec AUC average : {prec} {rec} <==> {auc}')\n",
    "#     print(np.mean(aucs))\n",
    "    return auc\n",
    "\n",
    "\n",
    "def fast_predict_FE_2(data,add_fes1,add_fes2,pipelines):\n",
    "    X = data.copy()\n",
    "#     pred = np.zeros(1,len(X))\n",
    "    pred_proba = np.zeros((len(X)))\n",
    "    for i in range(len(pipelines)):\n",
    "        \n",
    "        pred_proba += pipelines[i].predict_proba(add_fes2[i].transform(add_fes1[i].transform(X,mode='test'),mode='test'))[:,1] / len(pipelines)\n",
    "    \n",
    "    return pred_proba\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:43.434413Z",
     "start_time": "2021-02-23T09:57:43.423443Z"
    }
   },
   "outputs": [],
   "source": [
    "def fast_build_model_FE_automatic_2_pipe(X,y,cv,Feature_Engineering,parameters1,parameters2,model_base=LogisticRegression(class_weight='balanced')):\n",
    "\n",
    "    num_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "                                    ('scaler', RobustScaler())\n",
    "                                    ])\n",
    "\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                    ])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv,random_state = 3,shuffle = True)\n",
    "\n",
    "\n",
    "    # oof validation\n",
    "    oof_y_valid = []\n",
    "    oof_y_valid_pred = []\n",
    "    oof_y_valid_pred_proba = []\n",
    "    pipelines = []\n",
    "    add_fes1 = []\n",
    "    add_fes2 = []\n",
    "    data = pd.concat([X,y],axis=1)\n",
    "    aucs=[]\n",
    "#     print(data.columns)\n",
    "    for cv,(train_index, val_index) in enumerate(skf.split(X,y)):\n",
    "        start_fit = time.time()\n",
    "        data_train = data.iloc[train_index,:].copy()\n",
    "#         data_val = data.iloc[val_index,:][features]\n",
    "        \n",
    "        add_fe1 = Feature_Engineering(parameters1)\n",
    "        add_fe2 = Feature_Engineering(parameters2)\n",
    "        add_fe1.fit(data_train)\n",
    "        \n",
    "        X_train = add_fe1.transform(data_train)\n",
    "        add_fe2.fit(X_train)\n",
    "        X_train = add_fe2.transform(X_train).drop(columns=[parameters1['target']])\n",
    "        \n",
    "        num_cols_fe = list(X_train.select_dtypes(exclude='object').columns)\n",
    "        cat_cols_fe = list(X_train.select_dtypes(include='object').columns)\n",
    "        \n",
    "\n",
    "        y_train = y.iloc[train_index]\n",
    "        \n",
    "        X_val = add_fe1.transform(X.iloc[val_index,:],mode='val')\n",
    "        X_val = add_fe2.transform(X_val,mode='val')\n",
    "        y_val = y.iloc[val_index]\n",
    "        \n",
    "        \n",
    "        transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols_fe),\n",
    "            ('cat', cat_transformer, cat_cols_fe)\n",
    "        ])\n",
    "        \n",
    "        main_pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                          ('classifier', model_base)])\n",
    "        \n",
    "\n",
    "        \n",
    "        add_fes1.append(add_fe1)\n",
    "        add_fes2.append(add_fe2)\n",
    "        model = clone(main_pipeline)\n",
    "        model.fit(X_train,y_train.values.ravel())\n",
    "        pred = model.predict(X_val)\n",
    "        pred_proba = model.predict_proba(X_val)[:,1]\n",
    "        oof_y_valid_pred.extend(pred)\n",
    "        oof_y_valid_pred_proba.extend(pred_proba)\n",
    "        oof_y_valid.extend(y_val.values)\n",
    "        aucs.append(roc_auc_score(y_val.values, pred_proba,average='weighted'))\n",
    "        pipelines.append(model)\n",
    "        print(f'Fit iteration {cv} done in : {str(time.time()-start_fit)}')\n",
    "\n",
    "    prec,rec,f1, _ = precision_recall_fscore_support(oof_y_valid,oof_y_valid_pred)\n",
    "    auc = roc_auc_score(oof_y_valid, oof_y_valid_pred_proba,average='weighted')\n",
    "    print(f'PRec Rec AUC average : {prec} {rec} <==> {auc}')\n",
    "    print(np.mean(aucs))\n",
    "    return add_fes1,add_fes2,pipelines\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:57:45.498364Z",
     "start_time": "2021-02-23T09:57:45.491414Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, y_train, test_size=0.1, random_state=0,shuffle=True)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, y_train, test_size=0.5, random_state=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-23T11:42:54.979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "['job_duration_in_current_job_level', 'job_duration_in_current_person_level'] 0.5172544790216418\n",
      "['number_of_dependences', 'assign_of_otherposition'] 0.5227792484525233\n",
      "=========================\n",
      "\n",
      "add\n",
      "=========================\n",
      "\n",
      "add_str\n",
      "=========================\n",
      "\n",
      "substract\n",
      "=========================\n",
      "\n",
      "divide\n",
      "['job_duration_in_current_job_level', 'Last_achievement'] 0.5274137694374178\n",
      "['number_of_dependences', 'sick_leaves'] 0.5326454497323372\n",
      "=========================\n",
      "\n",
      "bin_numer_qcut\n",
      "['job_duration_in_current_branch', 5] 0.5473867090220993\n",
      "=========================\n",
      "\n",
      "bin_numer_cut\n",
      "['job_duration_in_current_branch', 5] 0.5545860867632737\n",
      "['Last_achievement', 5] 0.5590049087854843\n",
      "=========================\n",
      "\n",
      "bin_add_categ_numer_bin_cut\n",
      "['Employee_type', 'job_duration_in_current_job_level', 10] 0.5631546953742377\n",
      "=========================\n",
      "\n",
      "bin_add_categ_numer_bin_qcut\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "cv=2\n",
    "\n",
    "parameters = {'multiply':[],\n",
    "              'add':[],\n",
    "              'add_str':[],\n",
    "              'substract':[],'divide':[],\n",
    "              'bin_numer_qcut':[],\n",
    "              'bin_numer_cut':[],\n",
    "              'bin_add_categ_numer_bin_cut':[],\n",
    "              'bin_add_categ_numer_bin_qcut':[],\n",
    "            'bin_target_encoding_cut':[],\n",
    "             'bin_target_encoding_qcut':[],\n",
    "             'bin_target_encoding_custom_bin':[],\n",
    "              'categorical_mean_encoding':[],\n",
    "             'target':'Best Performance'}\n",
    "\n",
    "\n",
    "\n",
    "auc_end = 0\n",
    "\n",
    "for i,param in enumerate(parameters):\n",
    "    if i in [0,1,3,4]:\n",
    "        print(param)\n",
    "        for j in range(len(num_cols)):\n",
    "            if j!=len(num_cols)-1:\n",
    "                for k in range(len(num_cols[j+1:])):\n",
    "                    parameters2 = copy.deepcopy(parameters)\n",
    "                    col_col = [num_cols[j],num_cols[j+1+k]]\n",
    "                    if col_col in parameters2[param]:\n",
    "                        continue\n",
    "                    parameters2[param].append(col_col)\n",
    "    #                 print(parameters)\n",
    "    #                 print(parameters2)\n",
    "    #                 print()\n",
    "\n",
    "                    try:\n",
    "                        auc = fast_build_model_FE_automatic(X_train2,y_train2,cv,\n",
    "                                        Feature_Engineering,parameters2,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.01))\n",
    "                    except ZeroDivisionError:\n",
    "                        continue\n",
    "                    except AttributeError:\n",
    "                        continue\n",
    "                        \n",
    "                    if auc>auc_end+0.004:\n",
    "                        auc_end = auc.copy()\n",
    "                        parameters[param].append(col_col)\n",
    "                        print(parameters[param][-1],auc)\n",
    "                    else:\n",
    "    #                     print(parameters)\n",
    "                        continue\n",
    "    elif i in [2]:\n",
    "        print(param)\n",
    "        for j in range(len(cat_cols)):\n",
    "            if j!=len(cat_cols)-1:\n",
    "                for k in range(len(cat_cols[j+1:])):\n",
    "                    parameters2 = copy.deepcopy(parameters)\n",
    "                    col_col = [cat_cols[j],cat_cols[j+1+k]]\n",
    "                    if col_col in parameters2[param]:\n",
    "                        continue\n",
    "                    parameters2[param].append(col_col)\n",
    "    #                 print(parameters)\n",
    "    #                 print(parameters2)\n",
    "    #                 print()\n",
    "\n",
    "                    try:\n",
    "                        auc = fast_build_model_FE_automatic(X_train2,y_train2,cv,\n",
    "                                        Feature_Engineering,parameters2,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.01))\n",
    "                    except ZeroDivisionError:\n",
    "                        continue\n",
    "                    except AttributeError:\n",
    "                        continue\n",
    "                        \n",
    "                    if auc>auc_end+0.004:\n",
    "                        auc_end = auc.copy()\n",
    "                        parameters[param].append(col_col)\n",
    "                        print(parameters[param][-1],auc)\n",
    "                    else:\n",
    "    #                     print(parameters)\n",
    "                        continue\n",
    "    elif i in [5,6,9,10]:\n",
    "        print(param)\n",
    "        for j in range(len(num_cols)):\n",
    "            if j!=len(num_cols)-1:\n",
    "                bins = [5,10,20]\n",
    "                for bin_ in bins:\n",
    "                    parameters2 = copy.deepcopy(parameters)\n",
    "                    col_col = [num_cols[j],bin_]\n",
    "                    if col_col in parameters2[param]:\n",
    "                        continue\n",
    "                    parameters2[param].append(col_col)\n",
    "    #                 print(parameters)\n",
    "    #                 print(parameters2)\n",
    "    #                 print()\n",
    "                    \n",
    "                    try:\n",
    "                        auc = fast_build_model_FE_automatic(X_train2,y_train2,cv,\n",
    "                                        Feature_Engineering,parameters2,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.01))\n",
    "                    except ZeroDivisionError:\n",
    "                        continue\n",
    "                    except AttributeError:\n",
    "                        continue\n",
    "                    if auc>auc_end+0.004:\n",
    "                        auc_end = auc.copy()\n",
    "                        parameters[param].append(col_col)\n",
    "                        print(parameters[param][-1],auc)\n",
    "                    else:\n",
    "    #                     print(parameters)\n",
    "                        continue\n",
    "        \n",
    "    elif i in [7,8]:\n",
    "        print(param)\n",
    "        for j in range(len(num_cols)):\n",
    "            if j!=len(num_cols)-1:\n",
    "                bins = [10]\n",
    "                for bin_ in bins:\n",
    "                    for col2 in cat_cols:\n",
    "                        parameters2 = copy.deepcopy(parameters)\n",
    "                        col_col = [col2,num_cols[j],bin_]\n",
    "                        if col_col in parameters2[param]:\n",
    "                            continue\n",
    "                        parameters2[param].append(col_col)\n",
    "        #                 print(parameters)\n",
    "        #                 print(parameters2)\n",
    "        #                 print()\n",
    "\n",
    "                        try:\n",
    "                            auc = fast_build_model_FE_automatic(X_train2,y_train2,cv,\n",
    "                                            Feature_Engineering,parameters2,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.01))\n",
    "                        except ZeroDivisionError:\n",
    "                            continue\n",
    "                        except AttributeError:\n",
    "                            continue\n",
    "                        if auc>auc_end+0.004:\n",
    "                            auc_end = auc.copy()\n",
    "                            parameters[param].append(col_col)\n",
    "                            print(parameters[param][-1],auc)\n",
    "                        else:\n",
    "        #                     print(parameters)\n",
    "                            continue\n",
    "        \n",
    "    elif i in [12]:\n",
    "        print(param)\n",
    "        for j in range(len(cat_cols)):\n",
    "            if j!=len(cat_cols)-1:\n",
    "                parameters2 = copy.deepcopy(parameters)\n",
    "                col_col = cat_cols[j]\n",
    "                if col_col in parameters2[param]:\n",
    "                    continue\n",
    "                parameters2[param].append(col_col)\n",
    "                \n",
    "#                 print(parameters)\n",
    "#                 print(parameters2)\n",
    "#                 print()\n",
    "                \n",
    "                try:\n",
    "                    auc = fast_build_model_FE_automatic(X_train2,y_train2,cv,\n",
    "                                    Feature_Engineering,parameters2,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.01))\n",
    "                except ZeroDivisionError:\n",
    "                    continue\n",
    "                except AttributeError:\n",
    "                    continue\n",
    "                if auc>auc_end+0.004:\n",
    "                    auc_end = auc.copy()\n",
    "                    parameters[param].append(col_col)\n",
    "                    print(parameters[param][-1],auc)\n",
    "                else:\n",
    "#                     print(parameters)\n",
    "                    continue\n",
    "    print('=========================\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:41:13.643030Z",
     "start_time": "2021-02-23T11:41:13.636021Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters # 5.85 --> 5.66\n",
    "# parameters_backup = {'multiply': [['job_duration_in_current_job_level',\n",
    "#    'job_duration_in_current_person_level'],\n",
    "#   ['job_duration_in_current_job_level', 'branch_rotation'],\n",
    "#   ['job_duration_in_current_branch', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_branch', 'Achievement_above_100_during3quartal'],\n",
    "#   ['number_of_dependences', 'assign_of_otherposition'],\n",
    "#   ['assign_of_otherposition', 'sick_leaves'],\n",
    "#   ['Last_achievement', 'Achievement_above_100_during3quartal']],\n",
    "#  'add': [['gender', 'number_of_dependences']],\n",
    "#  'add_str': [],\n",
    "#  'substract': [],\n",
    "#  'divide': [['job_duration_in_current_job_level', 'sick_leaves'],\n",
    "#   ['job_duration_in_current_job_level', 'Last_achievement'],\n",
    "#   ['job_rotation', 'assign_of_otherposition']],\n",
    "#  'bin_numer_qcut': [['job_duration_in_current_branch', 5]],\n",
    "#  'bin_numer_cut': [['job_duration_in_current_branch', 5],\n",
    "#   ['number_of_dependences', 5],\n",
    "#   ['Last_achievement', 5]],\n",
    "#  'bin_add_categ_numer_bin_cut': [['Employee_type',\n",
    "#    'job_duration_in_current_job_level',\n",
    "#    10],\n",
    "#   ['Education_level', 'branch_rotation', 10]],\n",
    "#  'bin_add_categ_numer_bin_qcut': [['Employee_type', 'Last_achievement', 10]],\n",
    "#  'bin_target_encoding_cut': [['job_duration_in_current_branch', 20],\n",
    "#   ['year_graduated', 10]],\n",
    "#  'bin_target_encoding_qcut': [],\n",
    "#  'bin_target_encoding_custom_bin': [],\n",
    "#  'categorical_mean_encoding': [],\n",
    "#  'target': 'Best Performance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:25:32.377435Z",
     "start_time": "2021-02-23T11:25:32.373442Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters # 5.78 --> 5.58\n",
    "# parameters_backup = {'multiply': [['job_duration_in_current_job_level',\n",
    "#    'job_duration_in_current_person_level'],\n",
    "#   ['job_duration_in_current_job_level', 'branch_rotation'],\n",
    "#   ['job_duration_in_current_branch', 'assign_of_otherposition'],\n",
    "#   ['number_of_dependences', 'assign_of_otherposition'],\n",
    "#   ['assign_of_otherposition', 'sick_leaves']],\n",
    "#  'add': [],\n",
    "#  'add_str': [],\n",
    "#  'substract': [],\n",
    "#  'divide': [['job_duration_in_current_job_level', 'Last_achievement'],\n",
    "#   ['gender', 'sick_leaves'],\n",
    "#   ['number_of_dependences', 'sick_leaves'],\n",
    "#   ['job_rotation', 'assign_of_otherposition']],\n",
    "#  'bin_numer_qcut': [['job_duration_in_current_branch', 5]],\n",
    "#  'bin_numer_cut': [['job_duration_in_current_branch', 5],\n",
    "#   ['number_of_dependences', 5],\n",
    "#   ['Last_achievement', 5]],\n",
    "#  'bin_add_categ_numer_bin_cut': [],\n",
    "#  'bin_add_categ_numer_bin_qcut': [['Employee_type', 'Last_achievement', 10]],\n",
    "#  'bin_target_encoding_cut': [['year_graduated', 10]],\n",
    "#  'bin_target_encoding_qcut': [],\n",
    "#  'bin_target_encoding_custom_bin': [],\n",
    "#  'categorical_mean_encoding': [],\n",
    "#  'target': 'Best Performance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:25:34.420051Z",
     "start_time": "2021-02-23T11:25:34.412109Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters # 5.97 --> 5.72\n",
    "# parameters_backup = {'multiply': [['job_duration_in_current_job_level',\n",
    "#    'job_duration_in_current_person_level'],\n",
    "#   ['job_duration_in_current_job_level', 'branch_rotation'],\n",
    "#   ['job_duration_in_current_job_level', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_person_level', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_branch', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_branch', 'Achievement_above_100_during3quartal'],\n",
    "#   ['number_of_dependences', 'assign_of_otherposition'],\n",
    "#   ['number_of_dependences', 'Last_achievement'],\n",
    "#   ['assign_of_otherposition', 'sick_leaves'],\n",
    "#   ['Last_achievement', 'Achievement_above_100_during3quartal']],\n",
    "#  'add': [['gender', 'number_of_dependences']],\n",
    "#  'add_str': [['person_level', 'gender_str'],\n",
    "#   ['marital_status_maried', 'gender_str']],\n",
    "#  'substract': [],\n",
    "#  'divide': [['job_duration_in_current_job_level', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_job_level', 'sick_leaves'],\n",
    "#   ['job_duration_in_current_job_level', 'Last_achievement'],\n",
    "#   ['gender', 'sick_leaves'],\n",
    "#   ['branch_rotation', 'Achievement_above_100_during3quartal'],\n",
    "#   ['job_rotation', 'assign_of_otherposition'],\n",
    "#   ['Achievement_above_100_during3quartal', 'Education_level_ordinary']],\n",
    "#  'bin_numer_qcut': [['job_duration_in_current_branch', 5],\n",
    "#   ['Last_achievement', 10]],\n",
    "#  'bin_numer_cut': [['job_duration_in_current_branch', 5],\n",
    "#   ['number_of_dependences', 5],\n",
    "#   ['branch_rotation', 5],\n",
    "#   ['Last_achievement', 5]],\n",
    "#  'bin_add_categ_numer_bin_cut': [['Employee_type',\n",
    "#    'job_duration_in_current_job_level',\n",
    "#    10],\n",
    "#   ['marital_status_maried', 'job_duration_in_current_branch', 10],\n",
    "#   ['Education_level', 'year_graduated', 10],\n",
    "#   ['Employee_type', 'branch_rotation', 10],\n",
    "#   ['Education_level', 'branch_rotation', 10],\n",
    "#   ['gender_str', 'job_rotation', 10],\n",
    "#   ['Employee_type', 'annual_leave', 10],\n",
    "#   ['Employee_type', 'Last_achievement', 10]],\n",
    "#  'bin_add_categ_numer_bin_qcut': [['Education_level',\n",
    "#    'job_duration_in_current_branch',\n",
    "#    10],\n",
    "#   ['Achievement_above_100_during3quartal_str', 'year_graduated', 10],\n",
    "#   ['Employee_type', 'Last_achievement', 10]],\n",
    "#  'bin_target_encoding_cut': [['job_duration_in_current_branch', 20],\n",
    "#   ['job_rotation', 5]],\n",
    "#  'bin_target_encoding_qcut': [],\n",
    "#  'bin_target_encoding_custom_bin': [],\n",
    "#  'categorical_mean_encoding': [],\n",
    "#  'target': 'Best Performance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:01:35.374961Z",
     "start_time": "2021-02-23T11:01:35.371960Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters  # 5.64 --> 5.65\n",
    "# parameters_backup = {'multiply': [['job_duration_in_current_job_level',\n",
    "#    'job_duration_in_current_person_level'],\n",
    "#   ['number_of_dependences', 'assign_of_otherposition']],\n",
    "#  'add': [],\n",
    "#  'add_str': [],\n",
    "#  'substract': [],\n",
    "#  'divide': [['job_duration_in_current_person_level', 'Last_achievement'],\n",
    "#   ['number_of_dependences', 'sick_leaves']],\n",
    "#  'bin_numer_qcut': [['job_duration_in_current_branch', 5]],\n",
    "#  'bin_numer_cut': [['job_duration_in_current_branch', 5]],\n",
    "#  'bin_add_categ_numer_bin_cut': [],\n",
    "#  'bin_add_categ_numer_bin_qcut': [['Employee_type', 'Last_achievement', 10]],\n",
    "#  'bin_target_encoding_cut': [['job_rotation', 20]],\n",
    "#  'bin_target_encoding_qcut': [],\n",
    "#  'bin_target_encoding_custom_bin': [],\n",
    "#  'categorical_mean_encoding': [],\n",
    "#  'target': 'Best Performance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T10:33:06.513527Z",
     "start_time": "2021-02-23T10:33:06.496541Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters_backup = {'multiply': [['job_duration_in_current_job_level',\n",
    "#    'job_duration_in_current_person_level']],\n",
    "#  'add': [],\n",
    "#  'add_str': [],\n",
    "#  'substract': [],\n",
    "#  'divide': [['job_duration_in_current_job_level', 'branch_rotation']],\n",
    "#  'bin_numer_qcut': [['job_duration_in_current_branch', 5]],\n",
    "#  'bin_numer_cut': [['job_duration_in_current_branch', 5]],\n",
    "#  'bin_add_categ_numer_bin_cut': [],\n",
    "#  'bin_add_categ_numer_bin_qcut': [['marital_status_maried',\n",
    "#    'branch_rotation',\n",
    "#    10]],\n",
    "#  'bin_target_encoding_cut': [['job_duration_in_current_branch', 20]],\n",
    "#  'bin_target_encoding_qcut': [],\n",
    "#  'bin_target_encoding_custom_bin': [],\n",
    "#  'categorical_mean_encoding': [],\n",
    "#  'target': 'Best Performance'}\n",
    "\n",
    "\n",
    "# parameters_backup = {'multiply': [['job_duration_in_current_job_level',\n",
    "#    'job_duration_in_current_person_level'],\n",
    "#   ['job_duration_in_current_job_level', 'number_of_dependences'],\n",
    "#   ['job_duration_in_current_job_level', 'job_rotation'],\n",
    "#   ['job_duration_in_current_branch', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_branch', 'Achievement_above_100_during3quartal'],\n",
    "#   ['gender', 'assign_of_otherposition'],\n",
    "#   ['gender', 'Achievement_above_100_during3quartal'],\n",
    "#   ['number_of_dependences', 'job_rotation'],\n",
    "#   ['number_of_dependences', 'assign_of_otherposition'],\n",
    "#   ['GPA', 'branch_rotation'],\n",
    "#   ['branch_rotation', 'job_rotation'],\n",
    "#   ['assign_of_otherposition', 'sick_leaves'],\n",
    "#   ['assign_of_otherposition', 'Education_level_ordinary'],\n",
    "#   ['annual_leave', 'Last_achievement'],\n",
    "#   ['Last_achievement', 'Achievement_above_100_during3quartal']],\n",
    "#  'add': [['number_of_dependences', 'job_level_ordinary']],\n",
    "#  'add_str': [['person_level', 'gender_str'],\n",
    "#   ['Employee_type', 'Education_level'],\n",
    "#   ['Employee_type', 'Achievement_above_100_during3quartal_str'],\n",
    "#   ['marital_status_maried', 'Education_level'],\n",
    "#   ['marital_status_maried', 'Achievement_above_100_during3quartal_str']],\n",
    "#  'substract': [],\n",
    "#  'divide': [['job_duration_in_current_job_level', 'branch_rotation'],\n",
    "#   ['job_duration_in_current_job_level', 'sick_leaves'],\n",
    "#   ['job_duration_in_current_branch', 'sick_leaves'],\n",
    "#   ['job_duration_in_current_branch', 'Last_achievement'],\n",
    "#   ['job_duration_in_current_branch', 'Achievement_above_100_during3quartal'],\n",
    "#   ['gender', 'Last_achievement'],\n",
    "#   ['number_of_dependences', 'Last_achievement'],\n",
    "#   ['year_graduated', 'Last_achievement'],\n",
    "#   ['annual_leave', 'Achievement_above_100_during3quartal'],\n",
    "#   ['Achievement_above_100_during3quartal', 'Education_level_ordinary']],\n",
    "#  'bin_numer_qcut': [['job_duration_in_current_branch', 5],\n",
    "#   ['branch_rotation', 5],\n",
    "#   ['Last_achievement', 20]],\n",
    "#  'bin_numer_cut': [['job_duration_in_current_branch', 5],\n",
    "#   ['job_duration_in_current_branch', 20],\n",
    "#   ['year_graduated', 5],\n",
    "#   ['assign_of_otherposition', 20]],\n",
    "#  'bin_add_categ_numer_bin_cut': [['Employee_type',\n",
    "#    'job_duration_in_current_job_level',\n",
    "#    10],\n",
    "#   ['Achievement_above_100_during3quartal_str', 'number_of_dependences', 10],\n",
    "#   ['marital_status_maried', 'branch_rotation', 10],\n",
    "#   ['Education_level', 'branch_rotation', 10],\n",
    "#   ['marital_status_maried', 'sick_leaves', 10]],\n",
    "#  'bin_add_categ_numer_bin_qcut': [['person_level', 'branch_rotation', 10],\n",
    "#   ['marital_status_maried', 'branch_rotation', 10],\n",
    "#   ['Achievement_above_100_during3quartal_str', 'branch_rotation', 10],\n",
    "#   ['gender_str', 'Last_achievement', 10],\n",
    "#   ['Achievement_above_100_during3quartal_str', 'Last_achievement', 10]],\n",
    "#  'bin_target_encoding_cut': [['job_duration_in_current_branch', 5],\n",
    "#   ['job_duration_in_current_branch', 20],\n",
    "#   ['job_rotation', 5]],\n",
    "#  'bin_target_encoding_qcut': [],\n",
    "#  'bin_target_encoding_custom_bin': [],\n",
    "#  'categorical_mean_encoding': [],\n",
    "#  'target': 'Best Performance'}\n",
    "\n",
    "\n",
    "# parameters_backup = {'multiply': [['job_duration_in_current_job_level',\n",
    "#    'job_duration_in_current_person_level'],\n",
    "#   ['job_duration_in_current_job_level', 'branch_rotation'],\n",
    "#   ['job_duration_in_current_job_level', 'job_rotation'],\n",
    "#   ['job_duration_in_current_job_level', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_person_level', 'number_of_dependences'],\n",
    "#   ['job_duration_in_current_person_level', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_branch', 'year_graduated'],\n",
    "#   ['job_duration_in_current_branch', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_branch', 'annual_leave'],\n",
    "#   ['job_duration_in_current_branch', 'Achievement_above_100_during3quartal'],\n",
    "#   ['gender', 'sick_leaves'],\n",
    "#   ['gender', 'Achievement_above_100_during3quartal'],\n",
    "#   ['number_of_dependences', 'assign_of_otherposition'],\n",
    "#   ['number_of_dependences', 'Last_achievement'],\n",
    "#   ['branch_rotation', 'job_level_ordinary'],\n",
    "#   ['job_rotation', 'annual_leave'],\n",
    "#   ['job_rotation', 'sick_leaves'],\n",
    "#   ['job_rotation', 'job_level_ordinary'],\n",
    "#   ['assign_of_otherposition', 'sick_leaves'],\n",
    "#   ['assign_of_otherposition', 'Achievement_above_100_during3quartal'],\n",
    "#   ['annual_leave', 'sick_leaves'],\n",
    "#   ['sick_leaves', 'job_level_ordinary'],\n",
    "#   ['Last_achievement', 'Achievement_above_100_during3quartal']],\n",
    "#  'add': [['job_duration_in_current_job_level', 'job_level_ordinary']],\n",
    "#  'add_str': [['person_level', 'gender_str'],\n",
    "#   ['marital_status_maried', 'gender_str'],\n",
    "#   ['marital_status_maried', 'Achievement_above_100_during3quartal_str']],\n",
    "#  'substract': [['number_of_dependences',\n",
    "#    'Achievement_above_100_during3quartal']],\n",
    "#  'divide': [['job_duration_in_current_job_level', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_job_level', 'sick_leaves'],\n",
    "#   ['job_duration_in_current_job_level', 'Last_achievement'],\n",
    "#   ['job_duration_in_current_branch', 'Last_achievement'],\n",
    "#   ['gender', 'sick_leaves'],\n",
    "#   ['number_of_dependences', 'sick_leaves'],\n",
    "#   ['GPA', 'Last_achievement'],\n",
    "#   ['branch_rotation', 'Achievement_above_100_during3quartal'],\n",
    "#   ['job_rotation', 'assign_of_otherposition'],\n",
    "#   ['job_rotation', 'Last_achievement'],\n",
    "#   ['Achievement_above_100_during3quartal', 'job_level_ordinary'],\n",
    "#   ['Achievement_above_100_during3quartal', 'Education_level_ordinary']],\n",
    "#  'bin_numer_qcut': [['job_duration_in_current_branch', 5],\n",
    "#   ['GPA', 5],\n",
    "#   ['Last_achievement', 10]],\n",
    "#  'bin_numer_cut': [['job_duration_in_current_branch', 5],\n",
    "#   ['number_of_dependences', 5],\n",
    "#   ['branch_rotation', 5],\n",
    "#   ['job_rotation', 5],\n",
    "#   ['Last_achievement', 5]],\n",
    "#  'bin_add_categ_numer_bin_cut': [['Employee_type',\n",
    "#    'job_duration_in_current_job_level',\n",
    "#    10],\n",
    "#   ['Education_level', 'job_duration_in_current_job_level', 10],\n",
    "#   ['marital_status_maried', 'job_duration_in_current_branch', 10],\n",
    "#   ['Education_level', 'job_duration_in_current_branch', 10],\n",
    "#   ['Achievement_above_100_during3quartal_str',\n",
    "#    'job_duration_in_current_branch',\n",
    "#    10],\n",
    "#   ['Education_level', 'year_graduated', 10],\n",
    "#   ['Employee_type', 'branch_rotation', 10],\n",
    "#   ['Education_level', 'branch_rotation', 10],\n",
    "#   ['gender_str', 'job_rotation', 10],\n",
    "#   ['Employee_type', 'annual_leave', 10],\n",
    "#   ['Employee_type', 'Last_achievement', 10]],\n",
    "#  'bin_add_categ_numer_bin_qcut': [['marital_status_maried',\n",
    "#    'job_duration_in_current_branch',\n",
    "#    10],\n",
    "#   ['Education_level', 'year_graduated', 10],\n",
    "#   ['Achievement_above_100_during3quartal_str', 'year_graduated', 10],\n",
    "#   ['Employee_type', 'Last_achievement', 10],\n",
    "#   ['marital_status_maried', 'Last_achievement', 10]],\n",
    "#  'bin_target_encoding_cut': [['job_duration_in_current_branch', 20],\n",
    "#   ['year_graduated', 10],\n",
    "#   ['job_rotation', 5]],\n",
    "#  'bin_target_encoding_qcut': [],\n",
    "#  'bin_target_encoding_custom_bin': [],\n",
    "#  'categorical_mean_encoding': [],\n",
    "#  'target': 'Best Performance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T10:33:10.049723Z",
     "start_time": "2021-02-23T10:33:10.044706Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters_backup = {'multiply': [['job_duration_in_current_job_level',\n",
    "#    'job_duration_in_current_person_level'],\n",
    "#   ['job_duration_in_current_job_level', 'job_duration_in_current_branch'],\n",
    "#   ['job_duration_in_current_job_level', 'gender'],\n",
    "#   ['job_duration_in_current_job_level', 'branch_rotation'],\n",
    "#   ['job_duration_in_current_job_level', 'sick_leaves'],\n",
    "#   ['job_duration_in_current_job_level', 'Last_achievement'],\n",
    "#   ['job_duration_in_current_job_level', 'job_level_ordinary'],\n",
    "#   ['job_duration_in_current_job_level', 'Education_level_ordinary'],\n",
    "#   ['job_duration_in_current_person_level', 'job_duration_in_current_branch'],\n",
    "#   ['job_duration_in_current_person_level', 'gender'],\n",
    "#   ['job_duration_in_current_person_level', 'branch_rotation'],\n",
    "#   ['job_duration_in_current_person_level', 'job_rotation'],\n",
    "#   ['job_duration_in_current_branch', 'gender'],\n",
    "#   ['job_duration_in_current_branch', 'number_of_dependences'],\n",
    "#   ['job_duration_in_current_branch', 'GPA'],\n",
    "#   ['job_duration_in_current_branch', 'year_graduated'],\n",
    "#   ['job_duration_in_current_branch', 'branch_rotation'],\n",
    "#   ['job_duration_in_current_branch', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_branch', 'Achievement_above_100_during3quartal'],\n",
    "#   ['job_duration_in_current_branch', 'Education_level_ordinary'],\n",
    "#   ['gender', 'number_of_dependences'],\n",
    "#   ['gender', 'GPA'],\n",
    "#   ['gender', 'sick_leaves'],\n",
    "#   ['gender', 'Last_achievement'],\n",
    "#   ['gender', 'job_level_ordinary'],\n",
    "#   ['number_of_dependences', 'GPA'],\n",
    "#   ['number_of_dependences', 'assign_of_otherposition'],\n",
    "#   ['number_of_dependences', 'Last_achievement'],\n",
    "#   ['number_of_dependences', 'Education_level_ordinary'],\n",
    "#   ['GPA', 'year_graduated'],\n",
    "#   ['year_graduated', 'assign_of_otherposition'],\n",
    "#   ['year_graduated', 'job_level_ordinary'],\n",
    "#   ['branch_rotation', 'assign_of_otherposition'],\n",
    "#   ['branch_rotation', 'job_level_ordinary'],\n",
    "#   ['assign_of_otherposition', 'sick_leaves'],\n",
    "#   ['sick_leaves', 'Last_achievement'],\n",
    "#   ['sick_leaves', 'Education_level_ordinary'],\n",
    "#   ['job_level_ordinary', 'Education_level_ordinary']],\n",
    "#  'add': [['job_duration_in_current_job_level', 'number_of_dependences'],\n",
    "#   ['job_duration_in_current_job_level', 'GPA'],\n",
    "#   ['job_duration_in_current_job_level', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_job_level', 'job_level_ordinary'],\n",
    "#   ['job_duration_in_current_person_level', 'job_duration_in_current_branch'],\n",
    "#   ['job_duration_in_current_person_level', 'number_of_dependences'],\n",
    "#   ['job_duration_in_current_branch', 'GPA'],\n",
    "#   ['job_duration_in_current_branch', 'job_level_ordinary'],\n",
    "#   ['gender', 'number_of_dependences'],\n",
    "#   ['gender', 'GPA'],\n",
    "#   ['gender', 'branch_rotation'],\n",
    "#   ['number_of_dependences', 'assign_of_otherposition'],\n",
    "#   ['number_of_dependences', 'Education_level_ordinary'],\n",
    "#   ['GPA', 'Last_achievement'],\n",
    "#   ['GPA', 'job_level_ordinary']],\n",
    "#  'add_str': [['person_level', 'Employee_type'],\n",
    "#   ['person_level', 'gender_str'],\n",
    "#   ['person_level', 'Achievement_above_100_during3quartal_str'],\n",
    "#   ['Employee_type', 'marital_status_maried'],\n",
    "#   ['Employee_type', 'Education_level'],\n",
    "#   ['marital_status_maried', 'gender_str'],\n",
    "#   ['marital_status_maried', 'Achievement_above_100_during3quartal_str'],\n",
    "#   ['Education_level', 'Achievement_above_100_during3quartal_str']],\n",
    "#  'substract': [['job_duration_in_current_job_level',\n",
    "#    'job_duration_in_current_person_level'],\n",
    "#   ['job_duration_in_current_job_level', 'job_duration_in_current_branch'],\n",
    "#   ['job_duration_in_current_job_level', 'GPA'],\n",
    "#   ['job_duration_in_current_job_level', 'branch_rotation'],\n",
    "#   ['job_duration_in_current_job_level', 'job_level_ordinary'],\n",
    "#   ['job_duration_in_current_person_level', 'job_duration_in_current_branch'],\n",
    "#   ['job_duration_in_current_person_level', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_branch', 'number_of_dependences'],\n",
    "#   ['job_duration_in_current_branch', 'job_level_ordinary'],\n",
    "#   ['job_duration_in_current_branch', 'Education_level_ordinary'],\n",
    "#   ['number_of_dependences', 'branch_rotation'],\n",
    "#   ['GPA', 'Achievement_above_100_during3quartal']],\n",
    "#  'divide': [['job_duration_in_current_job_level', 'year_graduated'],\n",
    "#   ['job_duration_in_current_job_level', 'branch_rotation'],\n",
    "#   ['job_duration_in_current_job_level', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_job_level', 'Last_achievement'],\n",
    "#   ['job_duration_in_current_job_level',\n",
    "#    'Achievement_above_100_during3quartal'],\n",
    "#   ['job_duration_in_current_job_level', 'Education_level_ordinary'],\n",
    "#   ['job_duration_in_current_person_level', 'Last_achievement'],\n",
    "#   ['job_duration_in_current_person_level',\n",
    "#    'Achievement_above_100_during3quartal'],\n",
    "#   ['job_duration_in_current_branch', 'job_rotation'],\n",
    "#   ['job_duration_in_current_branch', 'assign_of_otherposition'],\n",
    "#   ['job_duration_in_current_branch', 'Achievement_above_100_during3quartal'],\n",
    "#   ['job_duration_in_current_branch', 'job_level_ordinary'],\n",
    "#   ['gender', 'number_of_dependences'],\n",
    "#   ['gender', 'branch_rotation'],\n",
    "#   ['gender', 'Achievement_above_100_during3quartal'],\n",
    "#   ['job_rotation', 'Last_achievement'],\n",
    "#   ['job_rotation', 'Achievement_above_100_during3quartal'],\n",
    "#   ['annual_leave', 'Last_achievement']],\n",
    "#  'bin_numer_qcut': [['job_duration_in_current_branch', 5],\n",
    "#   ['number_of_dependences', 5],\n",
    "#   ['year_graduated', 10],\n",
    "#   ['branch_rotation', 5],\n",
    "#   ['Last_achievement', 10]],\n",
    "#  'bin_numer_cut': [['job_duration_in_current_branch', 5],\n",
    "#   ['job_duration_in_current_branch', 10],\n",
    "#   ['number_of_dependences', 5],\n",
    "#   ['branch_rotation', 5],\n",
    "#   ['assign_of_otherposition', 5],\n",
    "#   ['assign_of_otherposition', 10],\n",
    "#   ['Last_achievement', 5]],\n",
    "#  'bin_add_categ_numer_bin_cut': [['Education_level',\n",
    "#    'job_duration_in_current_job_level',\n",
    "#    10],\n",
    "#   ['gender_str', 'job_duration_in_current_job_level', 10],\n",
    "#   ['Achievement_above_100_during3quartal_str',\n",
    "#    'job_duration_in_current_job_level',\n",
    "#    10],\n",
    "#   ['person_level', 'job_duration_in_current_branch', 10],\n",
    "#   ['Employee_type', 'job_duration_in_current_branch', 10],\n",
    "#   ['marital_status_maried', 'job_duration_in_current_branch', 10],\n",
    "#   ['Education_level', 'job_duration_in_current_branch', 10],\n",
    "#   ['gender_str', 'job_duration_in_current_branch', 10],\n",
    "#   ['Achievement_above_100_during3quartal_str',\n",
    "#    'job_duration_in_current_branch',\n",
    "#    10],\n",
    "#   ['person_level', 'gender', 10],\n",
    "#   ['marital_status_maried', 'gender', 10],\n",
    "#   ['marital_status_maried', 'number_of_dependences', 10],\n",
    "#   ['Employee_type', 'branch_rotation', 10],\n",
    "#   ['Achievement_above_100_during3quartal_str', 'branch_rotation', 10],\n",
    "#   ['person_level', 'job_rotation', 10],\n",
    "#   ['person_level', 'assign_of_otherposition', 10],\n",
    "#   ['Achievement_above_100_during3quartal_str', 'assign_of_otherposition', 10],\n",
    "#   ['Employee_type', 'annual_leave', 10],\n",
    "#   ['gender_str', 'Last_achievement', 10],\n",
    "#   ['Achievement_above_100_during3quartal_str', 'Last_achievement', 10]],\n",
    "#  'bin_add_categ_numer_bin_qcut': [['Education_level',\n",
    "#    'job_duration_in_current_job_level',\n",
    "#    10],\n",
    "#   ['person_level', 'job_duration_in_current_branch', 10],\n",
    "#   ['Employee_type', 'job_duration_in_current_branch', 10],\n",
    "#   ['marital_status_maried', 'job_duration_in_current_branch', 10],\n",
    "#   ['gender_str', 'job_duration_in_current_branch', 10],\n",
    "#   ['Achievement_above_100_during3quartal_str',\n",
    "#    'job_duration_in_current_branch',\n",
    "#    10],\n",
    "#   ['person_level', 'gender', 10],\n",
    "#   ['Education_level', 'GPA', 10],\n",
    "#   ['Education_level', 'year_graduated', 10],\n",
    "#   ['Employee_type', 'branch_rotation', 10],\n",
    "#   ['marital_status_maried', 'job_rotation', 10],\n",
    "#   ['gender_str', 'assign_of_otherposition', 10],\n",
    "#   ['person_level', 'sick_leaves', 10]],\n",
    "#  'bin_target_encoding_cut': [['job_duration_in_current_branch', 20],\n",
    "#   ['number_of_dependences', 5],\n",
    "#   ['branch_rotation', 5],\n",
    "#   ['assign_of_otherposition', 10],\n",
    "#   ['annual_leave', 5],\n",
    "#   ['sick_leaves', 10],\n",
    "#   ['Last_achievement', 5],\n",
    "#   ['Last_achievement', 10],\n",
    "#   ['Achievement_above_100_during3quartal', 5]],\n",
    "#  'bin_target_encoding_qcut': [['job_duration_in_current_job_level', 5],\n",
    "#   ['job_duration_in_current_job_level', 10],\n",
    "#   ['job_duration_in_current_branch', 5],\n",
    "#   ['number_of_dependences', 5],\n",
    "#   ['assign_of_otherposition', 5],\n",
    "#   ['sick_leaves', 5],\n",
    "#   ['Last_achievement', 5],\n",
    "#   ['Achievement_above_100_during3quartal', 5]],\n",
    "#  'bin_target_encoding_custom_bin': [],\n",
    "#  'categorical_mean_encoding': [],\n",
    "#  'target': 'Best Performance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:41:44.860522Z",
     "start_time": "2021-02-23T11:41:43.882167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2788, 42) (5576, 23)\n",
      "(2788, 42) (5576, 23)\n",
      "Fit iteration 0 done in : 0.5056495666503906\n",
      "(2788, 42) (5576, 23)\n",
      "(2788, 42) (5576, 23)\n",
      "Fit iteration 1 done in : 0.45082664489746094\n",
      "PRec Rec AUC average : [0.88002418 0.17820909] [0.60984293 0.50436954] <==> 0.5851936388415004\n",
      "[0.5899748743718594, 0.5813085635304283]\n",
      "0.5856417189511438\n"
     ]
    }
   ],
   "source": [
    "cv=2\n",
    "\n",
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, y_train, test_size=0.5, random_state=3,shuffle=True)\n",
    "\n",
    "add_fes,pipelines = fast_build_model_FE(X_train2,y_train2,cv,\n",
    "                    Feature_Engineering,parameters_backup,model_base=LogisticRegression(solver='newton-cg',class_weight='balanced',random_state=0,max_iter=10000,C=0.01))\n",
    "\n",
    "# add_fes,pipelines = fast_build_model_FE_1(X_train2,y_train2,\n",
    "#                     Feature_Engineering,parameters_backup,model_base=LogisticRegression(solver='newton-cg',class_weight='balanced',random_state=0,max_iter=10000,C=0.01))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:41:45.457964Z",
     "start_time": "2021-02-23T11:41:44.861520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5665436097001723"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = fast_predict_FE(X_test2.copy(),add_fes,pipelines)\n",
    "roc_auc_score(y_test2.values, pred_proba,average='weighted')\n",
    "\n",
    "# pred_proba = fast_predict_FE(X_train2.copy(),add_fes,pipelines)\n",
    "# roc_auc_score(y_train2.values, pred_proba,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T09:20:41.563640Z",
     "start_time": "2021-02-23T09:20:41.560617Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T06:33:48.193594Z",
     "start_time": "2021-02-23T06:33:48.190572Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, y_train, test_size=0.5, random_state=3,shuffle=True)\n",
    "\n",
    "# add_fes,pipelines = fast_build_model_FE(X_train2,y_train2,cv,\n",
    "#                     Feature_Engineering,parameters_drop2,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.01))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T06:33:50.650034Z",
     "start_time": "2021-02-23T06:33:50.647012Z"
    }
   },
   "outputs": [],
   "source": [
    "# pred_proba = fast_predict_FE(X_test2.copy(),add_fes,pipelines)\n",
    "\n",
    "# roc_auc_score(y_test2.values, pred_proba,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:40:21.528713Z",
     "start_time": "2021-02-22T13:40:10.737622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5576, 171) (11153, 23)\n",
      "(5577, 171) (11153, 23)\n",
      "Fit iteration 0 done in : 5.409177780151367\n",
      "(5577, 171) (11153, 23)\n",
      "(5576, 171) (11153, 23)\n",
      "Fit iteration 1 done in : 5.338063716888428\n",
      "PRec Rec AUC average : [0.87511931 0.1750565 ] [0.57807902 0.52046426] <==> 0.5604599834173124\n",
      "[0.565341272150856, 0.5567539832540433]\n",
      "0.5610476277024496\n"
     ]
    }
   ],
   "source": [
    "cv=2\n",
    "add_fes,pipelines = fast_build_model_FE(X_train,y_train,cv,\n",
    "                    Feature_Engineering,parameters_backup,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:11:56.000917Z",
     "start_time": "2021-02-22T13:11:16.631493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8922, 171) (11153, 23)\n",
      "(2231, 171) (11153, 23)\n",
      "Fit iteration 0 done in : 7.69919228553772\n",
      "(8922, 171) (11153, 23)\n",
      "(2231, 171) (11153, 23)\n",
      "Fit iteration 1 done in : 7.944198131561279\n",
      "(8922, 171) (11153, 23)\n",
      "(2231, 171) (11153, 23)\n",
      "Fit iteration 2 done in : 7.729879856109619\n",
      "(8923, 171) (11153, 23)\n",
      "(2230, 171) (11153, 23)\n",
      "Fit iteration 3 done in : 8.474101543426514\n",
      "(8923, 171) (11153, 23)\n",
      "(2230, 171) (11153, 23)\n",
      "Fit iteration 4 done in : 7.472262620925903\n",
      "PRec Rec AUC average : [0.8763625  0.17818643] [0.59142497 0.5149664 ] <==> 0.5753824764284722\n",
      "[0.5991635186184565, 0.564666829011958, 0.5918286915396742, 0.5916410753341336, 0.5350171385595897]\n",
      "0.5819151738152073\n"
     ]
    }
   ],
   "source": [
    "cv=5\n",
    "add_fes,pipelines = fast_build_model_FE(X_train,y_train,cv,\n",
    "                    Feature_Engineering,parameters_backup,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T13:14:47.428575Z",
     "start_time": "2021-02-22T13:13:24.895205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10037, 171) (11153, 23)\n",
      "(1116, 171) (11153, 23)\n",
      "Fit iteration 0 done in : 7.970711708068848\n",
      "(10037, 171) (11153, 23)\n",
      "(1116, 171) (11153, 23)\n",
      "Fit iteration 1 done in : 8.354789972305298\n",
      "(10037, 171) (11153, 23)\n",
      "(1116, 171) (11153, 23)\n",
      "Fit iteration 2 done in : 10.407728910446167\n",
      "(10038, 171) (11153, 23)\n",
      "(1115, 171) (11153, 23)\n",
      "Fit iteration 3 done in : 8.743772506713867\n",
      "(10038, 171) (11153, 23)\n",
      "(1115, 171) (11153, 23)\n",
      "Fit iteration 4 done in : 7.586367130279541\n",
      "(10038, 171) (11153, 23)\n",
      "(1115, 171) (11153, 23)\n",
      "Fit iteration 5 done in : 7.7707109451293945\n",
      "(10038, 171) (11153, 23)\n",
      "(1115, 171) (11153, 23)\n",
      "Fit iteration 6 done in : 8.127434730529785\n",
      "(10038, 171) (11153, 23)\n",
      "(1115, 171) (11153, 23)\n",
      "Fit iteration 7 done in : 7.865878343582153\n",
      "(10038, 171) (11153, 23)\n",
      "(1115, 171) (11153, 23)\n",
      "Fit iteration 8 done in : 7.926168441772461\n",
      "(10038, 171) (11153, 23)\n",
      "(1115, 171) (11153, 23)\n",
      "Fit iteration 9 done in : 7.732975959777832\n",
      "PRec Rec AUC average : [0.87778456 0.18177865] [0.60456074 0.51069029] <==> 0.5759470016482544\n",
      "[0.6081612523058004, 0.6022814613650337, 0.594006200040992, 0.5223488168273444, 0.5566131360519667, 0.6303616538639996, 0.5831602164602089, 0.5938101100253904, 0.5030583980918674, 0.5798581723987587]\n",
      "0.605221356835417\n"
     ]
    }
   ],
   "source": [
    "cv=10\n",
    "add_fes,pipelines = fast_build_model_FE(X_train,y_train,cv,\n",
    "                    Feature_Engineering,parameters_backup,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T06:35:46.461281Z",
     "start_time": "2021-02-23T06:35:46.235883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 9)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_skf = {'train':[],'val':[]}\n",
    "cv =5\n",
    "skf = StratifiedKFold(n_splits=cv,random_state = 3,shuffle = True)\n",
    "\n",
    "\n",
    "\n",
    "for train_index,val_index in skf.split(X_train,y_train):\n",
    "    add_fe = Feature_Engineering(parameters_backup)\n",
    "    add_fe.fit(data.iloc[train_index,:])\n",
    "    data_skf['train'].append([add_fe.transform(X_train.iloc[train_index,:],mode='val'),y_train.iloc[train_index]])\n",
    "    data_skf['val'].append([add_fe.transform(X_train.iloc[val_index,:],mode='val'),y_train.iloc[val_index]])\n",
    "    break\n",
    "num_cols_fe = list(data_skf['train'][0][0].select_dtypes(exclude='object').columns)\n",
    "cat_cols_fe = list(data_skf['train'][0][0].select_dtypes(include='object').columns)\n",
    "len(num_cols_fe),len(cat_cols_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T06:37:31.374538Z",
     "start_time": "2021-02-23T06:37:19.285515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "['job_duration_in_current_job_level', 'job_duration_in_current_job_level_times_job_duration_in_current_person_level'] 0.5906770060965563\n",
      "['job_duration_in_current_person_level', 'job_duration_in_current_job_level_times_job_duration_in_current_person_level'] 0.5908116555445708\n",
      "['job_duration_in_current_branch', 'job_duration_in_current_job_level_divide_branch_rotation'] 0.5909995983687593\n",
      "=========================\n",
      "\n",
      "add\n",
      "['job_duration_in_current_job_level', 'job_duration_in_current_job_level_times_job_duration_in_current_person_level'] 0.5910907377656945\n",
      "['job_duration_in_current_job_level', 'job_duration_in_current_job_level_divide_branch_rotation'] 0.5911177706376668\n",
      "['job_duration_in_current_person_level', 'job_duration_in_current_job_level_times_job_duration_in_current_person_level'] 0.5911836793540947\n",
      "=========================\n",
      "\n",
      "add_str\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-60d32345d4ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                             auc = fast_build_model_FE_automatic_2(X_train2,y_train2,cv,\n\u001b[1;32m---> 65\u001b[1;33m                                             Feature_Engineering,parameters_backup,parameters_fe2,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.1))\n\u001b[0m\u001b[0;32m     66\u001b[0m                         \u001b[1;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-9c6183803d59>\u001b[0m in \u001b[0;36mfast_build_model_FE_automatic_2\u001b[1;34m(X, y, cv, Feature_Engineering, parameters1, parameters2, model_base)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0madd_fes2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_fe2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_pipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mpred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1415\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m                       sample_weight=sample_weight)\n\u001b[1;32m-> 1417\u001b[1;33m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    758\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L-BFGS-B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m                 \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"iprint\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gtol\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"maxiter\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m             )\n\u001b[0;32m    762\u001b[0m             n_iter_i = _check_optimize_result(\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m--> 620\u001b[1;33m                                 callback=callback, **options)\n\u001b[0m\u001b[0;32m    621\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ojtaa\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[1;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlog_logistic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m     \u001b[0mz0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "parameters_fe = {'multiply':[],\n",
    "              'add':[],\n",
    "              'add_str':[],\n",
    "              'substract':[],'divide':[],\n",
    "              'bin_numer_qcut':[],\n",
    "              'bin_numer_cut':[],\n",
    "              'bin_add_categ_numer_bin_cut':[],\n",
    "              'bin_add_categ_numer_bin_qcut':[],\n",
    "            'bin_target_encoding_cut':[],\n",
    "             'bin_target_encoding_qcut':[],\n",
    "             'bin_target_encoding_custom_bin':[],\n",
    "              'categorical_mean_encoding':[],\n",
    "             'target':'Best Performance'}\n",
    "\n",
    "cv=2\n",
    "num_cols_2 = copy.deepcopy(num_cols_fe)  # 16\n",
    "cat_cols_2 = copy.deepcopy(cat_cols_fe)   # 6\n",
    "\n",
    "# auc_end = 0\n",
    "auc_end = 0.5903428283077937\n",
    "# auc_end = 0.5950855235807718\n",
    "for i,param in enumerate(parameters_fe):\n",
    "    if i in [0,1,3,4]:\n",
    "        print(param)\n",
    "        for j in range(len(num_cols_2)):\n",
    "            if j!=len(num_cols_2)-1:\n",
    "                for k in range(len(num_cols_2[j+1:])):\n",
    "                    if k>=15:\n",
    "                        parameters_fe2 = copy.deepcopy(parameters_fe)\n",
    "                        col_col = [num_cols_2[j],num_cols_2[j+1+k]]\n",
    "                        parameters_fe2[param].append(col_col)\n",
    "        #                 print(parameters_fe)\n",
    "        #                 print(parameters_fe2)\n",
    "                        \n",
    "\n",
    "                        try:\n",
    "                            auc = fast_build_model_FE_automatic_2(X_train2,y_train2,cv,\n",
    "                                            Feature_Engineering,parameters_backup,parameters_fe2,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.1))\n",
    "                        except ZeroDivisionError:\n",
    "                            pass\n",
    "                        if auc>auc_end+0.0005:\n",
    "                            auc_end = auc.copy()\n",
    "                            parameters_fe[param].append(col_col)\n",
    "                            print(parameters_fe[param][-1],auc)\n",
    "                        else:\n",
    "        #                     print(parameters_fe)\n",
    "                            continue\n",
    "    elif i in [2]:\n",
    "        print(param)\n",
    "        for j in range(len(cat_cols_2)):\n",
    "            if j!=len(cat_cols_2)-1:\n",
    "                for k in range(len(cat_cols_2[j+1:])):\n",
    "                    if k>=5:\n",
    "                        parameters_fe2 = copy.deepcopy(parameters_fe)\n",
    "                        col_col = [cat_cols_2[j],cat_cols_2[j+1+k]]\n",
    "                        parameters_fe2[param].append(col_col)\n",
    "        #                 print(parameters_fe)\n",
    "        #                 print(parameters_fe2)\n",
    "        #                 print()\n",
    "                        \n",
    "\n",
    "                        try:\n",
    "                            auc = fast_build_model_FE_automatic_2(X_train2,y_train2,cv,\n",
    "                                            Feature_Engineering,parameters_backup,parameters_fe2,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.1))\n",
    "                        except ZeroDivisionError:\n",
    "                            pass\n",
    "                        if auc>auc_end+0.0005:\n",
    "                            auc_end = auc.copy()\n",
    "                            parameters_fe[param].append(col_col)\n",
    "                            print(parameters_fe[param][-1],auc)\n",
    "                        else:\n",
    "        #                     print(parameters_fe)\n",
    "                            continue\n",
    "    elif i in [5,6,9,10]:\n",
    "        print(param)\n",
    "        for j in range(len(num_cols_2)):\n",
    "            if j!=len(num_cols_2)-1 and j>15:\n",
    "                bins = [5,10,20]\n",
    "                for bin_ in bins:\n",
    "                    parameters_fe2 = copy.deepcopy(parameters_fe)\n",
    "                    col_col = [num_cols_2[j],bin_]\n",
    "                    parameters_fe2[param].append(col_col)\n",
    "    #                 print(parameters_fe)\n",
    "    #                 print(parameters_fe2)\n",
    "    #                 print()\n",
    "                    \n",
    "                    \n",
    "                    try:\n",
    "                        auc = fast_build_model_FE_automatic_2(X_train2,y_train2,cv,\n",
    "                                        Feature_Engineering,parameters_backup,parameters_fe2,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.1))\n",
    "                    except ZeroDivisionError:\n",
    "                        pass\n",
    "                    if auc>auc_end+0.0005:\n",
    "                        auc_end = auc.copy()\n",
    "                        parameters_fe[param].append(col_col)\n",
    "                        print(parameters_fe[param][-1],auc)\n",
    "                    else:\n",
    "    #                     print(parameters_fe)\n",
    "                        continue\n",
    "        \n",
    "    elif i in [7,8]:\n",
    "        print(param)\n",
    "        for j in range(len(num_cols_2)):\n",
    "            if j!=len(num_cols_2)-1:\n",
    "                bins = [10]\n",
    "                for bin_ in bins:\n",
    "                    for k,col2 in enumerate(cat_cols_2):\n",
    "                        if k>=6:\n",
    "                            parameters_fe2 = copy.deepcopy(parameters_fe)\n",
    "                            col_col = [col2,num_cols_2[j],bin_]\n",
    "                            parameters_fe2[param].append(col_col)\n",
    "            #                 print(parameters_fe)\n",
    "            #                 print(parameters_fe2)\n",
    "            #                 print()\n",
    "                            try:\n",
    "                                auc = fast_build_model_FE_automatic_2(X_train2,y_train2,cv,\n",
    "                                                Feature_Engineering,parameters_backup,parameters_fe2,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.1))\n",
    "                            except ZeroDivisionError:\n",
    "                                pass\n",
    "                            if auc>auc_end+0.0005:\n",
    "                                auc_end = auc.copy()\n",
    "                                parameters_fe[param].append(col_col)\n",
    "                                print(parameters_fe[param][-1],auc)\n",
    "                            else:\n",
    "            #                     print(parameters_fe)\n",
    "                                continue\n",
    "        \n",
    "    elif i in [12]:\n",
    "        print(param)\n",
    "        for j in range(len(cat_cols_2)):\n",
    "            if j!=len(cat_cols_2)-1:\n",
    "                if j>=6:\n",
    "                    parameters_fe2 = copy.deepcopy(parameters_fe)\n",
    "                    col_col = cat_cols_2[j]\n",
    "                    parameters_fe2[param].append(col_col)\n",
    "    #                 print(parameters_fe)\n",
    "    #                 print(parameters_fe2)\n",
    "    #                 print()\n",
    "\n",
    "#                     print(col_col)\n",
    "                    try:\n",
    "                        auc = fast_build_model_FE_automatic_2(X_train2,y_train2,cv,\n",
    "                                        Feature_Engineering,parameters_backup,parameters_fe2,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=10000,C=0.1))\n",
    "                    except ZeroDivisionError:\n",
    "                        pass\n",
    "                    if auc>auc_end+0.0005:\n",
    "                        auc_end = auc.copy()\n",
    "                        parameters_fe[param].append(col_col)\n",
    "                        print(parameters_fe[param][-1],auc)\n",
    "                    else:\n",
    "    #                     print(parameters_fe)\n",
    "                        continue\n",
    "    print('=========================\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mix ordinary and fe features not yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T18:43:24.473228Z",
     "start_time": "2021-02-21T18:43:24.465228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multiply': [['job_duration_in_current_job_level_bin_target_encoding_cut',\n",
       "   'job_duration_in_current_person_level_bin_target_encoding_cut'],\n",
       "  ['job_duration_in_current_person_level_bin_target_encoding_cut',\n",
       "   'job_duration_in_current_branch_bin_target_encoding_cut'],\n",
       "  ['job_duration_in_current_branch_bin_target_encoding_cut',\n",
       "   'gender_bin_target_encoding_cut'],\n",
       "  ['number_of_dependences_bin_target_encoding_cut',\n",
       "   'GPA_bin_target_encoding_cut'],\n",
       "  ['job_rotation_bin_target_encoding_cut',\n",
       "   'assign_of_otherposition_bin_target_encoding_cut'],\n",
       "  ['assign_of_otherposition_bin_target_encoding_cut',\n",
       "   'annual_leave_bin_target_encoding_cut'],\n",
       "  ['Achievement_above_100_during3quartal_bin_target_encoding_cut',\n",
       "   'job_level_ordinary_bin_target_encoding_cut'],\n",
       "  ['assign_of_otherposition_bin_target_encoding_qcut',\n",
       "   'marital_status_maried_categorical_mean_encoding'],\n",
       "  ['Last_achievement_times_Achievement_above_100_during3quartal',\n",
       "   'job_duration_in_current_branch_plus_gender'],\n",
       "  ['gender_plus_number_of_dependences',\n",
       "   'assign_of_otherposition_plus_annual_leave'],\n",
       "  ['job_duration_in_current_branch_minus_gender', 'GPA_minus_year_graduated']],\n",
       " 'add': [],\n",
       " 'add_str': [['Last_achievement_bin_numer_cut',\n",
       "   'Achievement_above_100_during3quartal_bin_numer_cut'],\n",
       "  ['marital_status_maried_Achievement_above_100_during3quartal_bin_add_categ_numer_bin_qcut',\n",
       "   'gender_str_Achievement_above_100_during3quartal_bin_add_categ_numer_bin_qcut']],\n",
       " 'substract': [['job_duration_in_current_branch_bin_target_encoding_cut',\n",
       "   'gender_bin_target_encoding_cut'],\n",
       "  ['marital_status_maried_categorical_mean_encoding',\n",
       "   'job_duration_in_current_job_level_times_job_duration_in_current_person_level'],\n",
       "  ['job_duration_in_current_job_level_times_job_duration_in_current_person_level',\n",
       "   'number_of_dependences_times_GPA']],\n",
       " 'divide': [['GPA_bin_target_encoding_cut',\n",
       "   'job_rotation_bin_target_encoding_cut'],\n",
       "  ['job_rotation_bin_target_encoding_cut',\n",
       "   'assign_of_otherposition_bin_target_encoding_cut'],\n",
       "  ['annual_leave_bin_target_encoding_cut',\n",
       "   'Achievement_above_100_during3quartal_bin_target_encoding_cut'],\n",
       "  ['job_level_ordinary_bin_target_encoding_cut',\n",
       "   'year_graduated_bin_target_encoding_qcut'],\n",
       "  ['job_duration_in_current_branch_minus_gender', 'GPA_minus_year_graduated'],\n",
       "  ['job_rotation_divide_assign_of_otherposition',\n",
       "   'sick_leaves_divide_Last_achievement']],\n",
       " 'bin_numer_qcut': [['job_duration_in_current_person_level_bin_target_encoding_cut',\n",
       "   5],\n",
       "  ['gender_bin_target_encoding_cut', 5],\n",
       "  ['assign_of_otherposition_bin_target_encoding_cut', 5],\n",
       "  ['job_level_ordinary_bin_target_encoding_cut', 5],\n",
       "  ['job_duration_in_current_person_level_bin_target_encoding_cut', 5],\n",
       "  ['assign_of_otherposition_plus_annual_leave', 5],\n",
       "  ['GPA_minus_year_graduated', 5],\n",
       "  ['job_rotation_divide_assign_of_otherposition', 10]],\n",
       " 'bin_numer_cut': [['Achievement_above_100_during3quartal_bin_target_encoding_cut',\n",
       "   10],\n",
       "  ['Achievement_above_100_during3quartal_bin_target_encoding_cut', 20],\n",
       "  ['year_graduated_bin_target_encoding_qcut', 5],\n",
       "  ['year_graduated_bin_target_encoding_qcut', 10],\n",
       "  ['year_graduated_bin_target_encoding_qcut', 20],\n",
       "  ['assign_of_otherposition_bin_target_encoding_qcut', 5],\n",
       "  ['number_of_dependences_times_GPA', 5],\n",
       "  ['assign_of_otherposition_times_annual_leave', 5],\n",
       "  ['Last_achievement_times_Achievement_above_100_during3quartal', 5],\n",
       "  ['Last_achievement_plus_Achievement_above_100_during3quartal', 20],\n",
       "  ['job_duration_in_current_job_level_minus_job_duration_in_current_person_level',\n",
       "   5],\n",
       "  ['GPA_minus_year_graduated', 5],\n",
       "  ['year_graduated_minus_branch_rotation', 5]],\n",
       " 'bin_add_categ_numer_bin_cut': [['job_duration_in_current_job_level_bin_numer_qcut',\n",
       "   'job_duration_in_current_job_level_bin_target_encoding_cut',\n",
       "   10],\n",
       "  ['GPA_bin_numer_cut',\n",
       "   'job_duration_in_current_job_level_bin_target_encoding_cut',\n",
       "   10],\n",
       "  ['gender_str_job_duration_in_current_job_level_bin_add_categ_numer_bin_cut',\n",
       "   'job_duration_in_current_job_level_bin_target_encoding_cut',\n",
       "   10]],\n",
       " 'bin_add_categ_numer_bin_qcut': [],\n",
       " 'bin_target_encoding_cut': [],\n",
       " 'bin_target_encoding_qcut': [],\n",
       " 'bin_target_encoding_custom_bin': [],\n",
       " 'categorical_mean_encoding': [],\n",
       " 'target': 'Best Performance'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T16:16:29.260958Z",
     "start_time": "2021-02-22T16:16:29.251983Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_fe = {'multiply': [['job_duration_in_current_job_level_bin_target_encoding_cut',\n",
    "   'job_duration_in_current_person_level_bin_target_encoding_cut'],\n",
    "  ['job_duration_in_current_person_level_bin_target_encoding_cut',\n",
    "   'job_duration_in_current_branch_bin_target_encoding_cut'],\n",
    "  ['job_duration_in_current_branch_bin_target_encoding_cut',\n",
    "   'gender_bin_target_encoding_cut'],\n",
    "  ['number_of_dependences_bin_target_encoding_cut',\n",
    "   'GPA_bin_target_encoding_cut'],\n",
    "  ['job_rotation_bin_target_encoding_cut',\n",
    "   'assign_of_otherposition_bin_target_encoding_cut'],\n",
    "  ['assign_of_otherposition_bin_target_encoding_cut',\n",
    "   'annual_leave_bin_target_encoding_cut'],\n",
    "  ['Achievement_above_100_during3quartal_bin_target_encoding_cut',\n",
    "   'job_level_ordinary_bin_target_encoding_cut'],\n",
    "  ['assign_of_otherposition_bin_target_encoding_qcut',\n",
    "   'marital_status_maried_categorical_mean_encoding'],\n",
    "  ['Last_achievement_times_Achievement_above_100_during3quartal',\n",
    "   'job_duration_in_current_branch_plus_gender'],\n",
    "  ['gender_plus_number_of_dependences',\n",
    "   'assign_of_otherposition_plus_annual_leave'],\n",
    "  ['job_duration_in_current_branch_minus_gender', 'GPA_minus_year_graduated']],\n",
    " 'add': [],\n",
    " 'add_str': [['Last_achievement_bin_numer_cut',\n",
    "   'Achievement_above_100_during3quartal_bin_numer_cut'],\n",
    "  ['marital_status_maried_Achievement_above_100_during3quartal_bin_add_categ_numer_bin_qcut',\n",
    "   'gender_str_Achievement_above_100_during3quartal_bin_add_categ_numer_bin_qcut']],\n",
    " 'substract': [['job_duration_in_current_branch_bin_target_encoding_cut',\n",
    "   'gender_bin_target_encoding_cut'],\n",
    "  ['marital_status_maried_categorical_mean_encoding',\n",
    "   'job_duration_in_current_job_level_times_job_duration_in_current_person_level'],\n",
    "  ['job_duration_in_current_job_level_times_job_duration_in_current_person_level',\n",
    "   'number_of_dependences_times_GPA']],\n",
    " 'divide': [['GPA_bin_target_encoding_cut',\n",
    "   'job_rotation_bin_target_encoding_cut'],\n",
    "  ['job_rotation_bin_target_encoding_cut',\n",
    "   'assign_of_otherposition_bin_target_encoding_cut'],\n",
    "  ['annual_leave_bin_target_encoding_cut',\n",
    "   'Achievement_above_100_during3quartal_bin_target_encoding_cut'],\n",
    "  ['job_level_ordinary_bin_target_encoding_cut',\n",
    "   'year_graduated_bin_target_encoding_qcut'],\n",
    "  ['job_duration_in_current_branch_minus_gender', 'GPA_minus_year_graduated'],\n",
    "  ['job_rotation_divide_assign_of_otherposition',\n",
    "   'sick_leaves_divide_Last_achievement']],\n",
    " 'bin_numer_qcut': [['job_duration_in_current_person_level_bin_target_encoding_cut',\n",
    "   5],\n",
    "  ['gender_bin_target_encoding_cut', 5],\n",
    "  ['assign_of_otherposition_bin_target_encoding_cut', 5],\n",
    "  ['job_level_ordinary_bin_target_encoding_cut', 5],\n",
    "  ['job_duration_in_current_person_level_bin_target_encoding_cut', 5],\n",
    "  ['assign_of_otherposition_plus_annual_leave', 5],\n",
    "  ['GPA_minus_year_graduated', 5],\n",
    "  ['job_rotation_divide_assign_of_otherposition', 10]],\n",
    " 'bin_numer_cut': [['Achievement_above_100_during3quartal_bin_target_encoding_cut',\n",
    "   10],\n",
    "  ['Achievement_above_100_during3quartal_bin_target_encoding_cut', 20],\n",
    "  ['year_graduated_bin_target_encoding_qcut', 5],\n",
    "  ['year_graduated_bin_target_encoding_qcut', 10],\n",
    "  ['year_graduated_bin_target_encoding_qcut', 20],\n",
    "  ['assign_of_otherposition_bin_target_encoding_qcut', 5],\n",
    "  ['number_of_dependences_times_GPA', 5],\n",
    "  ['assign_of_otherposition_times_annual_leave', 5],\n",
    "  ['Last_achievement_times_Achievement_above_100_during3quartal', 5],\n",
    "  ['Last_achievement_plus_Achievement_above_100_during3quartal', 20],\n",
    "  ['job_duration_in_current_job_level_minus_job_duration_in_current_person_level',\n",
    "   5],\n",
    "  ['GPA_minus_year_graduated', 5],\n",
    "  ['year_graduated_minus_branch_rotation', 5]],\n",
    " 'bin_add_categ_numer_bin_cut': [['job_duration_in_current_job_level_bin_numer_qcut',\n",
    "   'job_duration_in_current_job_level_bin_target_encoding_cut',\n",
    "   10],\n",
    "  ['GPA_bin_numer_cut',\n",
    "   'job_duration_in_current_job_level_bin_target_encoding_cut',\n",
    "   10],\n",
    "  ['gender_str_job_duration_in_current_job_level_bin_add_categ_numer_bin_cut',\n",
    "   'job_duration_in_current_job_level_bin_target_encoding_cut',\n",
    "   10]],\n",
    " 'bin_add_categ_numer_bin_qcut': [],\n",
    " 'bin_target_encoding_cut': [],\n",
    " 'bin_target_encoding_qcut': [],\n",
    " 'bin_target_encoding_custom_bin': [],\n",
    " 'categorical_mean_encoding': [],\n",
    " 'target': 'Best Performance'}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T16:12:15.869658Z",
     "start_time": "2021-02-22T16:12:15.866693Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, y_train, test_size=0.5, random_state=3,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:21:32.910778Z",
     "start_time": "2021-02-22T17:21:32.906798Z"
    }
   },
   "outputs": [],
   "source": [
    "# cv=5\n",
    "# add_fes1,add_fes2,pipelines = fast_build_model_FE_automatic_2_pipe(X_train2,y_train2,cv,\n",
    "#                     Feature_Engineering,parameters_backup,parameters_fe,model_base=MLPClassifier(hidden_layer_sizes=(50,),\n",
    "#                                                                                                 activation='identity',\n",
    "#                                                                                                 alpha=0.001,\n",
    "#                                                                                                 random_state=0,\n",
    "#                                                                                                  max_iter=20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:22:40.530845Z",
     "start_time": "2021-02-22T17:22:10.355055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit iteration 0 done in : 8.156850814819336\n",
      "Fit iteration 1 done in : 5.634549856185913\n",
      "Fit iteration 2 done in : 5.0862181186676025\n",
      "Fit iteration 3 done in : 5.7015910148620605\n",
      "Fit iteration 4 done in : 5.564695358276367\n",
      "PRec Rec AUC average : [0.87331378 0.17728532] [0.62563025 0.47058824] <==> 0.5778979238754325\n",
      "0.5795683689456629\n"
     ]
    }
   ],
   "source": [
    "cv=5\n",
    "add_fes1,add_fes2,pipelines = fast_build_model_FE_automatic_2_pipe(X_train2,y_train2,cv,\n",
    "                    Feature_Engineering,parameters_backup,parameters_fe,model_base=LogisticRegression(solver='newton-cg',class_weight='balanced',random_state=0,max_iter=20000,C=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:17:11.025098Z",
     "start_time": "2021-02-22T17:17:11.022106Z"
    }
   },
   "outputs": [],
   "source": [
    "# cv=2\n",
    "# add_fes1,add_fes2,pipelines = fast_build_model_FE_automatic_2_pipe(X_train2,y_train2,cv,\n",
    "#                     Feature_Engineering,parameters_backup,parameters_fe,model_base=SVC(class_weight='balanced',probability=True,kernel='linear',gamma='auto',random_state=0,C=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:22:51.110894Z",
     "start_time": "2021-02-22T17:22:40.531841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5644752599191328"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = fast_predict_FE_2(X_test2.copy(),add_fes1,add_fes2,pipelines)\n",
    "\n",
    "roc_auc_score(y_test2.values, pred_proba,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T16:14:32.683805Z",
     "start_time": "2021-02-22T16:14:21.274035Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:14:27.356364Z",
     "start_time": "2021-02-22T17:14:16.385676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5765182565723763"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_proba2 = fast_predict_FE(X_test2.copy(),add_fes,pipelines)\n",
    "pred_proba2 = fast_predict_FE_2(X_test2.copy(),add_fes1,add_fes2,pipelines)\n",
    "\n",
    "roc_auc_score(y_test2.values, (pred_proba+pred_proba2)/2,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T05:01:02.351337Z",
     "start_time": "2021-02-22T05:01:00.668355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_duration_in_current_job_level</th>\n",
       "      <th>person_level</th>\n",
       "      <th>job_duration_in_current_person_level</th>\n",
       "      <th>job_duration_in_current_branch</th>\n",
       "      <th>Employee_type</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital_status_maried</th>\n",
       "      <th>number_of_dependences</th>\n",
       "      <th>Education_level</th>\n",
       "      <th>GPA</th>\n",
       "      <th>...</th>\n",
       "      <th>marital_status_maried_Achievement_above_100_during3quartal_bin_add_categ_numer_bin_qcut_plus_gender_str_Achievement_above_100_during3quartal_bin_add_categ_numer_bin_qcut</th>\n",
       "      <th>job_duration_in_current_branch_bin_target_encoding_cut_minus_gender_bin_target_encoding_cut</th>\n",
       "      <th>marital_status_maried_categorical_mean_encoding_minus_job_duration_in_current_job_level_times_job_duration_in_current_person_level</th>\n",
       "      <th>job_duration_in_current_job_level_times_job_duration_in_current_person_level_minus_number_of_dependences_times_GPA</th>\n",
       "      <th>GPA_bin_target_encoding_cut_divide_job_rotation_bin_target_encoding_cut</th>\n",
       "      <th>job_rotation_bin_target_encoding_cut_divide_assign_of_otherposition_bin_target_encoding_cut</th>\n",
       "      <th>annual_leave_bin_target_encoding_cut_divide_Achievement_above_100_during3quartal_bin_target_encoding_cut</th>\n",
       "      <th>job_level_ordinary_bin_target_encoding_cut_divide_year_graduated_bin_target_encoding_qcut</th>\n",
       "      <th>job_duration_in_current_branch_minus_gender_divide_GPA_minus_year_graduated</th>\n",
       "      <th>job_rotation_divide_assign_of_otherposition_divide_sick_leaves_divide_Last_achievement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.256981</td>\n",
       "      <td>PG03</td>\n",
       "      <td>1.256981</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>RM_type_A</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>level_3</td>\n",
       "      <td>3.08</td>\n",
       "      <td>...</td>\n",
       "      <td>N_(-0.001, inf]_1_(-0.001, inf]</td>\n",
       "      <td>-0.037096</td>\n",
       "      <td>-1.416596</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.005129</td>\n",
       "      <td>1.242308</td>\n",
       "      <td>0.982086</td>\n",
       "      <td>0.980657</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>4.000952e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>PG03</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>1.256981</td>\n",
       "      <td>RM_type_B</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>level_4</td>\n",
       "      <td>3.31</td>\n",
       "      <td>...</td>\n",
       "      <td>N_(-0.001, inf]_2_(-0.001, inf]</td>\n",
       "      <td>0.026256</td>\n",
       "      <td>-1.336596</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.005129</td>\n",
       "      <td>0.983905</td>\n",
       "      <td>0.982086</td>\n",
       "      <td>0.908693</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>2.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>PG03</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.081665</td>\n",
       "      <td>RM_type_A</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>level_4</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>Y_(-0.001, inf]_2_(-0.001, inf]</td>\n",
       "      <td>0.125542</td>\n",
       "      <td>-0.106202</td>\n",
       "      <td>-3.19</td>\n",
       "      <td>1.005129</td>\n",
       "      <td>0.983905</td>\n",
       "      <td>1.217694</td>\n",
       "      <td>0.984076</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>1.763800e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.256981</td>\n",
       "      <td>PG03</td>\n",
       "      <td>1.256981</td>\n",
       "      <td>1.802776</td>\n",
       "      <td>RM_type_A</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>level_4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>Y_(-0.001, inf]_2_(-0.001, inf]</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>-1.436202</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.005129</td>\n",
       "      <td>0.983905</td>\n",
       "      <td>0.982086</td>\n",
       "      <td>0.908693</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>3.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.352775</td>\n",
       "      <td>PG03</td>\n",
       "      <td>1.352775</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>RM_type_B</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>level_4</td>\n",
       "      <td>3.34</td>\n",
       "      <td>...</td>\n",
       "      <td>Y_(-0.001, inf]_1_(-0.001, inf]</td>\n",
       "      <td>0.013061</td>\n",
       "      <td>-1.686202</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.005129</td>\n",
       "      <td>0.983905</td>\n",
       "      <td>0.982086</td>\n",
       "      <td>1.054285</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>2.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>1.292285</td>\n",
       "      <td>PG03</td>\n",
       "      <td>1.292285</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>RM_type_B</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>level_4</td>\n",
       "      <td>3.01</td>\n",
       "      <td>...</td>\n",
       "      <td>Y_(-0.001, inf]_2_(-0.001, inf]</td>\n",
       "      <td>-0.023901</td>\n",
       "      <td>-1.526202</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.005129</td>\n",
       "      <td>0.983905</td>\n",
       "      <td>0.982086</td>\n",
       "      <td>0.908693</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>2.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>1.352775</td>\n",
       "      <td>PG03</td>\n",
       "      <td>1.352775</td>\n",
       "      <td>1.581139</td>\n",
       "      <td>RM_type_A</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>level_4</td>\n",
       "      <td>3.56</td>\n",
       "      <td>...</td>\n",
       "      <td>Y_(-0.001, inf]_2_(-0.001, inf]</td>\n",
       "      <td>-0.023351</td>\n",
       "      <td>-1.686202</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>1.005129</td>\n",
       "      <td>1.242308</td>\n",
       "      <td>0.967674</td>\n",
       "      <td>0.984076</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>2.857143e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>1.385641</td>\n",
       "      <td>PG03</td>\n",
       "      <td>1.385641</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>RM_type_A</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>level_4</td>\n",
       "      <td>3.59</td>\n",
       "      <td>...</td>\n",
       "      <td>Y_(-0.001, inf]_2_(-0.001, inf]</td>\n",
       "      <td>0.026256</td>\n",
       "      <td>-1.776202</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.005129</td>\n",
       "      <td>0.983905</td>\n",
       "      <td>1.211128</td>\n",
       "      <td>0.908693</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>3.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>1.385641</td>\n",
       "      <td>PG05</td>\n",
       "      <td>1.385641</td>\n",
       "      <td>0.648074</td>\n",
       "      <td>RM_type_A</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>level_4</td>\n",
       "      <td>2.93</td>\n",
       "      <td>...</td>\n",
       "      <td>Y_(-0.001, inf]_2_(-0.001, inf]</td>\n",
       "      <td>-0.008831</td>\n",
       "      <td>-1.776202</td>\n",
       "      <td>-3.94</td>\n",
       "      <td>1.037787</td>\n",
       "      <td>1.203213</td>\n",
       "      <td>0.982086</td>\n",
       "      <td>1.080526</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>7.500000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>1.352775</td>\n",
       "      <td>PG03</td>\n",
       "      <td>1.352775</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>RM_type_A</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>level_3</td>\n",
       "      <td>3.08</td>\n",
       "      <td>...</td>\n",
       "      <td>Y_(-0.001, inf]_2_(-0.001, inf]</td>\n",
       "      <td>-0.023901</td>\n",
       "      <td>-1.686202</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>1.005129</td>\n",
       "      <td>0.983905</td>\n",
       "      <td>0.982086</td>\n",
       "      <td>0.980657</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>1.500000e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      job_duration_in_current_job_level person_level  \\\n",
       "0                              1.256981         PG03   \n",
       "1                              1.224745         PG03   \n",
       "2                              0.500000         PG03   \n",
       "3                              1.256981         PG03   \n",
       "4                              1.352775         PG03   \n",
       "...                                 ...          ...   \n",
       "5995                           1.292285         PG03   \n",
       "5996                           1.352775         PG03   \n",
       "5997                           1.385641         PG03   \n",
       "5998                           1.385641         PG05   \n",
       "5999                           1.352775         PG03   \n",
       "\n",
       "      job_duration_in_current_person_level  job_duration_in_current_branch  \\\n",
       "0                                 1.256981                        0.707107   \n",
       "1                                 1.224745                        1.256981   \n",
       "2                                 0.500000                        1.081665   \n",
       "3                                 1.256981                        1.802776   \n",
       "4                                 1.352775                        1.224745   \n",
       "...                                    ...                             ...   \n",
       "5995                              1.292285                        0.707107   \n",
       "5996                              1.352775                        1.581139   \n",
       "5997                              1.385641                        1.224745   \n",
       "5998                              1.385641                        0.648074   \n",
       "5999                              1.352775                        0.707107   \n",
       "\n",
       "     Employee_type  gender marital_status_maried  number_of_dependences  \\\n",
       "0        RM_type_A       1                     N                      0   \n",
       "1        RM_type_B       2                     N                      0   \n",
       "2        RM_type_A       2                     Y                      1   \n",
       "3        RM_type_A       2                     Y                      1   \n",
       "4        RM_type_B       1                     Y                      0   \n",
       "...            ...     ...                   ...                    ...   \n",
       "5995     RM_type_B       2                     Y                      0   \n",
       "5996     RM_type_A       2                     Y                      1   \n",
       "5997     RM_type_A       2                     Y                      0   \n",
       "5998     RM_type_A       2                     Y                      2   \n",
       "5999     RM_type_A       2                     Y                      1   \n",
       "\n",
       "     Education_level   GPA  ...  \\\n",
       "0            level_3  3.08  ...   \n",
       "1            level_4  3.31  ...   \n",
       "2            level_4  3.44  ...   \n",
       "3            level_4  0.00  ...   \n",
       "4            level_4  3.34  ...   \n",
       "...              ...   ...  ...   \n",
       "5995         level_4  3.01  ...   \n",
       "5996         level_4  3.56  ...   \n",
       "5997         level_4  3.59  ...   \n",
       "5998         level_4  2.93  ...   \n",
       "5999         level_3  3.08  ...   \n",
       "\n",
       "      marital_status_maried_Achievement_above_100_during3quartal_bin_add_categ_numer_bin_qcut_plus_gender_str_Achievement_above_100_during3quartal_bin_add_categ_numer_bin_qcut  \\\n",
       "0                       N_(-0.001, inf]_1_(-0.001, inf]                                                                                                                           \n",
       "1                       N_(-0.001, inf]_2_(-0.001, inf]                                                                                                                           \n",
       "2                       Y_(-0.001, inf]_2_(-0.001, inf]                                                                                                                           \n",
       "3                       Y_(-0.001, inf]_2_(-0.001, inf]                                                                                                                           \n",
       "4                       Y_(-0.001, inf]_1_(-0.001, inf]                                                                                                                           \n",
       "...                                                 ...                                                                                                                           \n",
       "5995                    Y_(-0.001, inf]_2_(-0.001, inf]                                                                                                                           \n",
       "5996                    Y_(-0.001, inf]_2_(-0.001, inf]                                                                                                                           \n",
       "5997                    Y_(-0.001, inf]_2_(-0.001, inf]                                                                                                                           \n",
       "5998                    Y_(-0.001, inf]_2_(-0.001, inf]                                                                                                                           \n",
       "5999                    Y_(-0.001, inf]_2_(-0.001, inf]                                                                                                                           \n",
       "\n",
       "      job_duration_in_current_branch_bin_target_encoding_cut_minus_gender_bin_target_encoding_cut  \\\n",
       "0                                             -0.037096                                             \n",
       "1                                              0.026256                                             \n",
       "2                                              0.125542                                             \n",
       "3                                              0.003959                                             \n",
       "4                                              0.013061                                             \n",
       "...                                                 ...                                             \n",
       "5995                                          -0.023901                                             \n",
       "5996                                          -0.023351                                             \n",
       "5997                                           0.026256                                             \n",
       "5998                                          -0.008831                                             \n",
       "5999                                          -0.023901                                             \n",
       "\n",
       "      marital_status_maried_categorical_mean_encoding_minus_job_duration_in_current_job_level_times_job_duration_in_current_person_level  \\\n",
       "0                                             -1.416596                                                                                    \n",
       "1                                             -1.336596                                                                                    \n",
       "2                                             -0.106202                                                                                    \n",
       "3                                             -1.436202                                                                                    \n",
       "4                                             -1.686202                                                                                    \n",
       "...                                                 ...                                                                                    \n",
       "5995                                          -1.526202                                                                                    \n",
       "5996                                          -1.686202                                                                                    \n",
       "5997                                          -1.776202                                                                                    \n",
       "5998                                          -1.776202                                                                                    \n",
       "5999                                          -1.686202                                                                                    \n",
       "\n",
       "      job_duration_in_current_job_level_times_job_duration_in_current_person_level_minus_number_of_dependences_times_GPA  \\\n",
       "0                                                  1.58                                                                    \n",
       "1                                                  1.50                                                                    \n",
       "2                                                 -3.19                                                                    \n",
       "3                                                  1.58                                                                    \n",
       "4                                                  1.83                                                                    \n",
       "...                                                 ...                                                                    \n",
       "5995                                               1.67                                                                    \n",
       "5996                                              -1.73                                                                    \n",
       "5997                                               1.92                                                                    \n",
       "5998                                              -3.94                                                                    \n",
       "5999                                              -1.25                                                                    \n",
       "\n",
       "      GPA_bin_target_encoding_cut_divide_job_rotation_bin_target_encoding_cut  \\\n",
       "0                                              1.005129                         \n",
       "1                                              1.005129                         \n",
       "2                                              1.005129                         \n",
       "3                                              1.005129                         \n",
       "4                                              1.005129                         \n",
       "...                                                 ...                         \n",
       "5995                                           1.005129                         \n",
       "5996                                           1.005129                         \n",
       "5997                                           1.005129                         \n",
       "5998                                           1.037787                         \n",
       "5999                                           1.005129                         \n",
       "\n",
       "      job_rotation_bin_target_encoding_cut_divide_assign_of_otherposition_bin_target_encoding_cut  \\\n",
       "0                                              1.242308                                             \n",
       "1                                              0.983905                                             \n",
       "2                                              0.983905                                             \n",
       "3                                              0.983905                                             \n",
       "4                                              0.983905                                             \n",
       "...                                                 ...                                             \n",
       "5995                                           0.983905                                             \n",
       "5996                                           1.242308                                             \n",
       "5997                                           0.983905                                             \n",
       "5998                                           1.203213                                             \n",
       "5999                                           0.983905                                             \n",
       "\n",
       "      annual_leave_bin_target_encoding_cut_divide_Achievement_above_100_during3quartal_bin_target_encoding_cut  \\\n",
       "0                                              0.982086                                                          \n",
       "1                                              0.982086                                                          \n",
       "2                                              1.217694                                                          \n",
       "3                                              0.982086                                                          \n",
       "4                                              0.982086                                                          \n",
       "...                                                 ...                                                          \n",
       "5995                                           0.982086                                                          \n",
       "5996                                           0.967674                                                          \n",
       "5997                                           1.211128                                                          \n",
       "5998                                           0.982086                                                          \n",
       "5999                                           0.982086                                                          \n",
       "\n",
       "      job_level_ordinary_bin_target_encoding_cut_divide_year_graduated_bin_target_encoding_qcut  \\\n",
       "0                                              0.980657                                           \n",
       "1                                              0.908693                                           \n",
       "2                                              0.984076                                           \n",
       "3                                              0.908693                                           \n",
       "4                                              1.054285                                           \n",
       "...                                                 ...                                           \n",
       "5995                                           0.908693                                           \n",
       "5996                                           0.984076                                           \n",
       "5997                                           0.908693                                           \n",
       "5998                                           1.080526                                           \n",
       "5999                                           0.980657                                           \n",
       "\n",
       "     job_duration_in_current_branch_minus_gender_divide_GPA_minus_year_graduated  \\\n",
       "0                                              0.000146                            \n",
       "1                                              0.000370                            \n",
       "2                                              0.000457                            \n",
       "3                                              0.000098                            \n",
       "4                                             -0.000112                            \n",
       "...                                                 ...                            \n",
       "5995                                           0.000643                            \n",
       "5996                                           0.000209                            \n",
       "5997                                           0.000386                            \n",
       "5998                                           0.000676                            \n",
       "5999                                           0.000645                            \n",
       "\n",
       "     job_rotation_divide_assign_of_otherposition_divide_sick_leaves_divide_Last_achievement  \n",
       "0                                          4.000952e+00                                      \n",
       "1                                          2.000000e+08                                      \n",
       "2                                          1.763800e+06                                      \n",
       "3                                          3.000000e+08                                      \n",
       "4                                          2.000000e+08                                      \n",
       "...                                                 ...                                      \n",
       "5995                                       2.000000e+08                                      \n",
       "5996                                       2.857143e+03                                      \n",
       "5997                                       3.000000e+08                                      \n",
       "5998                                       7.500000e+03                                      \n",
       "5999                                       1.500000e+04                                      \n",
       "\n",
       "[6000 rows x 122 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ha = data_test.copy()\n",
    "add_fes2[1].transform(add_fes1[1].transform(X_ha,mode='test'),mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:41:03.159927Z",
     "start_time": "2021-02-22T17:40:25.246638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit iteration 0 done in : 7.88448429107666\n",
      "Fit iteration 1 done in : 7.247299909591675\n",
      "Fit iteration 2 done in : 7.898740291595459\n",
      "Fit iteration 3 done in : 7.478065252304077\n",
      "Fit iteration 4 done in : 7.358240842819214\n",
      "PRec Rec AUC average : [0.87791901 0.18486437] [0.62421185 0.49541845] <==> 0.5909752869680567\n",
      "0.5911841992015716\n"
     ]
    }
   ],
   "source": [
    "cv=5\n",
    "add_fes1,add_fes2,pipelines = fast_build_model_FE_automatic_2_pipe(X_train,y_train,cv,\n",
    "                    Feature_Engineering,parameters_backup,parameters_fe,model_base=LogisticRegression(solver='newton-cg',class_weight='balanced',random_state=0,max_iter=20000,C=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:42:16.284863Z",
     "start_time": "2021-02-22T17:42:05.102331Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_proba = fast_predict_FE_2(data_test.copy(),add_fes1,add_fes2,pipelines)\n",
    "\n",
    "df_submission = pd.DataFrame({'index':data_test.index,'Best Performance':pred_proba})\n",
    "df_submission\n",
    "\n",
    "df_submission.to_csv('df_submission_22feb_LOGREG5CV059C01_FE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T05:13:06.968286Z",
     "start_time": "2021-02-22T05:07:33.884843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit iteration 0 done in : 13.59222674369812\n",
      "Fit iteration 1 done in : 11.736554861068726\n",
      "Fit iteration 2 done in : 19.517606258392334\n",
      "Fit iteration 3 done in : 14.122777223587036\n",
      "Fit iteration 4 done in : 18.369574069976807\n",
      "Fit iteration 5 done in : 21.2182834148407\n",
      "Fit iteration 6 done in : 18.07462978363037\n",
      "Fit iteration 7 done in : 16.51407289505005\n",
      "Fit iteration 8 done in : 17.289663076400757\n",
      "Fit iteration 9 done in : 15.852121114730835\n",
      "Fit iteration 10 done in : 18.008126497268677\n",
      "Fit iteration 11 done in : 15.563772916793823\n",
      "Fit iteration 12 done in : 11.28114914894104\n",
      "Fit iteration 13 done in : 16.022382259368896\n",
      "Fit iteration 14 done in : 22.8385066986084\n",
      "Fit iteration 15 done in : 11.751692533493042\n",
      "Fit iteration 16 done in : 23.057936668395996\n",
      "Fit iteration 17 done in : 21.86928963661194\n",
      "Fit iteration 18 done in : 11.695711135864258\n",
      "Fit iteration 19 done in : 14.633818864822388\n",
      "PRec Rec AUC average : [0.88384592 0.19281706] [0.62211013 0.52474038] <==> 0.5986764919989431\n",
      "0.5992536526900972\n"
     ]
    }
   ],
   "source": [
    "# cv=20\n",
    "# add_fes1,add_fes2,pipelines = fast_build_model_FE_automatic_2_pipe(X_train,y_train,cv,\n",
    "#                     Feature_Engineering,parameters_backup,parameters_fe,model_base=LogisticRegression(class_weight='balanced',random_state=0,max_iter=20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T18:59:46.043401Z",
     "start_time": "2021-02-21T18:59:26.827370Z"
    }
   },
   "outputs": [],
   "source": [
    "# pred_proba = fast_predict_FE_2(data_test.copy(),add_fes1,add_fes2,pipelines)\n",
    "\n",
    "# df_submission = pd.DataFrame({'index':data_test.index,'Best Performance':pred_proba})\n",
    "# df_submission\n",
    "\n",
    "# df_submission.to_csv('df_submission_21feb_LOGREG10CV0598_FE.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T07:38:35.821732Z",
     "start_time": "2021-02-14T07:38:35.807729Z"
    }
   },
   "outputs": [],
   "source": [
    "class Ensemble_Models():\n",
    "    def __init__(self,list_models):\n",
    "        self.list_models = list_models\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        num_transformer = Pipeline(steps=[\n",
    "                                    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "                                    ('scaler', RobustScaler())\n",
    "                                    ])\n",
    "\n",
    "        cat_transformer = Pipeline(steps=[\n",
    "                                        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "                                        ])\n",
    "        num_cols_fe = list(X.select_dtypes(exclude='object').columns)\n",
    "        cat_cols_fe = list(X.select_dtypes(include='object').columns)\n",
    "        \n",
    "        \n",
    "        transformer = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', num_transformer, num_cols_fe),\n",
    "                ('cat', cat_transformer, cat_cols_fe)\n",
    "            ])\n",
    "        pipelines=[]\n",
    "        for mod in self.list_models:\n",
    "            main_pipeline = Pipeline(steps=[('transformer', transformer),\n",
    "                          ('classifier', mod)])\n",
    "            model = clone(main_pipeline)\n",
    "            model.fit(X,y)\n",
    "            pipelines.append(model)\n",
    "        \n",
    "        self.pipelines = pipelines\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        predict_proba = np.zeros(len(X))\n",
    "        for i,pipe in enumerate(self.pipelines):\n",
    "            predict_proba += pipe.predict_proba(X)[:,1] / len(self.pipelines)\n",
    "            \n",
    "        return predict_proba\n",
    "    \n",
    "    def predict(self,X,threshold=0.5):\n",
    "        predict_proba = np.zeros(len(X))\n",
    "        for i,pipe in enumerate(self.pipelines):\n",
    "            predict_proba += pipe.predict_proba(X)[:,1] / len(self.pipelines)\n",
    "        \n",
    "        predict = np.where(predict_proba>threshold,1,0)\n",
    "        \n",
    "        return predict\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T07:38:36.487132Z",
     "start_time": "2021-02-14T07:38:36.476132Z"
    }
   },
   "outputs": [],
   "source": [
    "def fast_build_model_FE_ensemble(X,y,cv,Feature_Engineering,parameters,list_models=[]):\n",
    "\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=cv,random_state = 0)\n",
    "\n",
    "    # oof validation\n",
    "    oof_y_valid = []\n",
    "    oof_y_valid_pred = []\n",
    "    oof_y_valid_pred_proba = []\n",
    "    pipelines = []\n",
    "    add_fes = []\n",
    "    data = pd.concat([X,y],axis=1)\n",
    "    aucs = []\n",
    "    \n",
    "#     print(data.columns)\n",
    "    for cv,(train_index, val_index) in enumerate(skf.split(X,y)):\n",
    "        start_fit = time.time()\n",
    "        data_train = data.iloc[train_index,:].copy()\n",
    "#         data_val = data.iloc[val_index,:][features]\n",
    "        \n",
    "        add_fe = Feature_Engineering(parameters)\n",
    "        add_fe.fit(data_train)\n",
    "        \n",
    "        X_train = add_fe.transform(data_train).drop(columns=[parameters['target']])\n",
    "#         X_train = data_train.drop(columns=[parameters['target']])\n",
    "    \n",
    "        print(X_train.shape,data.shape)\n",
    "        y_train = y.iloc[train_index]\n",
    "        \n",
    "        X_val = add_fe.transform(X.iloc[val_index,:],mode='val')\n",
    "#         X_val = X.iloc[val_index,:]\n",
    "    \n",
    "        y_val = y.iloc[val_index]\n",
    "        print(X_val.shape,data.shape)\n",
    "        \n",
    "        model = Ensemble_Models(list_models)\n",
    "\n",
    "        \n",
    "        add_fes.append(add_fe)\n",
    "        model.fit(X_train,y_train.values.ravel())\n",
    "        pred = model.predict(X_val)\n",
    "        pred_proba = model.predict_proba(X_val)\n",
    "        \n",
    "        oof_y_valid_pred.extend(pred)\n",
    "        oof_y_valid_pred_proba.extend(pred_proba)\n",
    "        oof_y_valid.extend(y_val.values)\n",
    "\n",
    "        pipelines.append(model)\n",
    "        \n",
    "        \n",
    "        \n",
    "        aucs.append(roc_auc_score(y_val.values, pred_proba,average='micro'))\n",
    "        \n",
    "        \n",
    "        print(f'Fit iteration {cv} done in : {str(time.time()-start_fit)}')\n",
    "\n",
    "    prec,rec,f1, _ = precision_recall_fscore_support(oof_y_valid,oof_y_valid_pred)\n",
    "    auc = roc_auc_score(oof_y_valid, oof_y_valid_pred_proba,average='micro')\n",
    "    print(f'PRec Rec AUC average : {prec} {rec} <==> {auc}')\n",
    "    print(aucs)\n",
    "    print(np.mean(aucs[:2]))\n",
    "    \n",
    "    return add_fes,pipelines\n",
    "\n",
    "\n",
    "def fast_predict_FE_ensemble(X,add_fes,pipelines):\n",
    "    data = X.copy()\n",
    "#     pred = np.zeros(1,len(X))\n",
    "    pred_proba = np.zeros((len(X)))\n",
    "    for i in range(len(pipelines)):\n",
    "        \n",
    "        pred_proba += pipelines[i].predict_proba(add_fes[i].transform(data,mode='test')) / len(pipelines)\n",
    "    \n",
    "    return pred_proba\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T07:49:48.918850Z",
     "start_time": "2021-02-14T07:49:48.914852Z"
    }
   },
   "outputs": [],
   "source": [
    "list_models = [\n",
    "#     LogisticRegression(class_weight='balanced',random_state = 0),\n",
    "    XGBClassifier(scale_pos_weight=3,random_state = 0),\n",
    "    LGBMClassifier(scale_pos_weight=3,random_state = 0),\n",
    "    RandomForestClassifier(class_weight='balanced',random_state = 0),\n",
    "#     MLPClassifier(hidden_layer_sizes=(100,),activation='identity',random_state = 0)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T07:49:49.364050Z",
     "start_time": "2021-02-14T07:49:49.346022Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'multiply':[['GPA','number_of_dependences']],\n",
    "              'add':[['annual_leave','sick_leaves'],['assign_of_otherposition','branch_rotation']],\n",
    "              'add_str':[['Education_level','job_level']],\n",
    "              'substract':[],'divide':[],\n",
    "              'bin_numer_qcut':[],\n",
    "              'bin_numer_cut':[],\n",
    "              'bin_add_categ_numer_bin_qcut':[['job_level','GPA',5],['Education_level','GPA',5]],\n",
    "            'bin_target_encoding_cut':[],\n",
    "             'bin_target_encoding_qcut':[['year_graduated',5],['GPA',5],['annual_leave',5]],\n",
    "             'bin_target_encoding_custom_bin':[],\n",
    "              'categorical_mean_encoding':['job_level','person_level','Employee_type','Education_level'],\n",
    "             'target':'Best Performance'}\n",
    "\n",
    "# parameters = {'multiply':[],\n",
    "#               'add':[],\n",
    "#               'add_str':[],\n",
    "#               'substract':[],'divide':[],\n",
    "#               'bin_numer_qcut':[],\n",
    "#               'bin_numer_cut':[],\n",
    "#               'bin_add_categ_numer_bin_qcut':[],\n",
    "#             'bin_target_encoding_cut':[['GPA',30]],\n",
    "#              'bin_target_encoding_qcut':[],\n",
    "#              'bin_target_encoding_custom_bin':[],\n",
    "#               'categorical_mean_encoding':[],\n",
    "#              'target':'Best Performance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T07:50:31.732444Z",
     "start_time": "2021-02-14T07:49:49.931527Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning:\n",
      "\n",
      "Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPA\n",
      "GPA\n",
      "year_graduated\n",
      "GPA\n",
      "annual_leave\n",
      "(9033, 34) (10037, 22)\n",
      "(1004, 34) (10037, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3e64f3dfca2c>:124: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:125: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:139: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:152: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:156: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:158: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:160: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:49:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 0 done in : 3.4611732959747314\n",
      "GPA\n",
      "GPA\n",
      "year_graduated\n",
      "GPA\n",
      "annual_leave\n",
      "(9033, 34) (10037, 22)\n",
      "(1004, 34) (10037, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3e64f3dfca2c>:124: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:125: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:139: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:152: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:156: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:158: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:160: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:49:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 1 done in : 3.547661542892456\n",
      "GPA\n",
      "GPA\n",
      "year_graduated\n",
      "GPA\n",
      "annual_leave\n",
      "(9033, 34) (10037, 22)\n",
      "(1004, 34) (10037, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3e64f3dfca2c>:124: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:125: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:139: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:152: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:156: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:158: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:160: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:49:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 2 done in : 3.696000337600708\n",
      "GPA\n",
      "GPA\n",
      "year_graduated\n",
      "GPA\n",
      "annual_leave\n",
      "(9033, 34) (10037, 22)\n",
      "(1004, 34) (10037, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3e64f3dfca2c>:124: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:125: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:139: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:152: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:156: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:158: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:160: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 3 done in : 3.838998556137085\n",
      "GPA\n",
      "GPA\n",
      "year_graduated\n",
      "GPA\n",
      "annual_leave\n",
      "(9033, 34) (10037, 22)\n",
      "(1004, 34) (10037, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3e64f3dfca2c>:124: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:125: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:139: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:152: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:156: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:158: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:160: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 4 done in : 3.9938435554504395\n",
      "GPA\n",
      "GPA\n",
      "year_graduated\n",
      "GPA\n",
      "annual_leave\n",
      "(9033, 34) (10037, 22)\n",
      "(1004, 34) (10037, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3e64f3dfca2c>:124: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:125: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:139: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:152: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:156: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:158: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:160: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 5 done in : 4.347000360488892\n",
      "GPA\n",
      "GPA\n",
      "year_graduated\n",
      "GPA\n",
      "annual_leave\n",
      "(9033, 34) (10037, 22)\n",
      "(1004, 34) (10037, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3e64f3dfca2c>:124: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:125: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:139: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:152: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:156: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:158: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:160: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 6 done in : 4.32400107383728\n",
      "GPA\n",
      "GPA\n",
      "year_graduated\n",
      "GPA\n",
      "annual_leave\n",
      "(9034, 34) (10037, 22)\n",
      "(1003, 34) (10037, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3e64f3dfca2c>:124: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:125: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:139: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:152: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:156: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:158: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:160: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 7 done in : 4.467153310775757\n",
      "GPA\n",
      "GPA\n",
      "year_graduated\n",
      "GPA\n",
      "annual_leave\n",
      "(9034, 34) (10037, 22)\n",
      "(1003, 34) (10037, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3e64f3dfca2c>:124: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:125: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:139: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:152: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:156: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:158: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:160: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 8 done in : 4.683999061584473\n",
      "GPA\n",
      "GPA\n",
      "year_graduated\n",
      "GPA\n",
      "annual_leave\n",
      "(9034, 34) (10037, 22)\n",
      "(1003, 34) (10037, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3e64f3dfca2c>:124: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:125: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:138: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:139: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:152: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:156: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:158: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-3e64f3dfca2c>:160: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 9 done in : 5.395112752914429\n",
      "PRec Rec AUC average : [0.85593476 0.25961538] [0.99102459 0.01851852] <==> 0.5718078774357457\n",
      "[0.5900708880160935, 0.5850416706581091, 0.5772583580802758, 0.6289555193664783, 0.5740332726634096, 0.5449436408340518, 0.5569259507615671, 0.533936178763765, 0.5465798569246845, 0.579634276945701]\n",
      "0.5875562793371013\n"
     ]
    }
   ],
   "source": [
    "cv=10\n",
    "add_fes_str,pipelines_str = fast_build_model_FE_ensemble(X_train,y_train,cv,\n",
    "                    Feature_Engineering,parameters,list_models=list_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T07:50:33.466440Z",
     "start_time": "2021-02-14T07:50:31.734442Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5762417796008895"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = fast_predict_FE_ensemble(X_val,add_fes_str,pipelines_str)\n",
    "roc_auc_score(y_val.values, pred_proba,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:38:30.877850Z",
     "start_time": "2021-02-14T06:38:28.957853Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_proba = fast_predict_FE_ensemble(data_test,add_fes_str,pipelines_str)\n",
    "\n",
    "# df_submission = pd.DataFrame({'index':data_test.index,'Best Performance':pred_proba})\n",
    "# df_submission\n",
    "\n",
    "# df_submission.to_csv('df_submission_13feb_ENSEMBLESTR5CV_FE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:38:53.006711Z",
     "start_time": "2021-02-14T06:38:53.000741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_proba_ENSE==pred_proba_XGB).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:40:27.089168Z",
     "start_time": "2021-02-14T06:40:27.078141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_proba_ENSE.round(4)==pred_proba_XGB.round(4)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:39:49.956124Z",
     "start_time": "2021-02-14T06:39:49.950127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17933059739880264"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_XGB[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T06:39:54.566898Z",
     "start_time": "2021-02-14T06:39:54.550931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17933059819042685"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_ENSE[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T15:11:52.870825Z",
     "start_time": "2021-02-13T15:11:35.784848Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "<ipython-input-19-3e64f3dfca2c>:131: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{col}_bin_target_encoding_cut'] = pd.cut(data[col],bins=bin_dummy)\n",
      "<ipython-input-19-3e64f3dfca2c>:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{col}_bin_target_encoding_cut'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_bin_target_encoding_cut'])[f'{target_encode}'].values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8922, 22) (11153, 22)\n",
      "(2231, 22) (11153, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 0 done in : 3.1989974975585938\n",
      "(8922, 22) (11153, 22)\n",
      "(2231, 22) (11153, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-3e64f3dfca2c>:131: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{col}_bin_target_encoding_cut'] = pd.cut(data[col],bins=bin_dummy)\n",
      "<ipython-input-19-3e64f3dfca2c>:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{col}_bin_target_encoding_cut'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_bin_target_encoding_cut'])[f'{target_encode}'].values\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 1 done in : 3.2701711654663086\n",
      "(8922, 22) (11153, 22)\n",
      "(2231, 22) (11153, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-3e64f3dfca2c>:131: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{col}_bin_target_encoding_cut'] = pd.cut(data[col],bins=bin_dummy)\n",
      "<ipython-input-19-3e64f3dfca2c>:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{col}_bin_target_encoding_cut'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_bin_target_encoding_cut'])[f'{target_encode}'].values\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 2 done in : 3.7990024089813232\n",
      "(8923, 22) (11153, 22)\n",
      "(2230, 22) (11153, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-3e64f3dfca2c>:131: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{col}_bin_target_encoding_cut'] = pd.cut(data[col],bins=bin_dummy)\n",
      "<ipython-input-19-3e64f3dfca2c>:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{col}_bin_target_encoding_cut'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_bin_target_encoding_cut'])[f'{target_encode}'].values\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 3 done in : 3.40883731842041\n",
      "(8923, 22) (11153, 22)\n",
      "(2230, 22) (11153, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-3e64f3dfca2c>:131: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{col}_bin_target_encoding_cut'] = pd.cut(data[col],bins=bin_dummy)\n",
      "<ipython-input-19-3e64f3dfca2c>:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{col}_bin_target_encoding_cut'] = pd.merge(data,data_dummy,how='left',on=[f'{col}_bin_target_encoding_cut'])[f'{target_encode}'].values\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Anaconda3\\envs\\andre\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fit iteration 4 done in : 3.3530004024505615\n",
      "PRec Rec AUC average : [0.85363661 0.3       ] [0.99779319 0.00549786] <==> 0.5593385721068307\n",
      "[0.5534365122195667, 0.574695922997065, 0.5622765082091179, 0.5345414692076409, 0.5722752261438161]\n",
      "0.5640662176083158\n"
     ]
    }
   ],
   "source": [
    "cv=5\n",
    "add_fes,pipelines = fast_build_model_FE_ensemble(X_train,y_train,cv,\n",
    "                    Feature_Engineering,parameters,list_models=list_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:26:46.555215Z",
     "start_time": "2021-02-13T14:26:46.542215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5548748462799754"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:45:15.239331Z",
     "start_time": "2021-02-13T14:45:15.234298Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"pipelines_0567_ensembleFE.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(pipelines, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:45:46.581808Z",
     "start_time": "2021-02-13T14:45:46.576807Z"
    }
   },
   "outputs": [],
   "source": [
    "# pipelines[0].pipelines[0]['transformer'].transform(data2_fe.drop(columns=['Best Performance']).copy()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:45:48.705176Z",
     "start_time": "2021-02-13T14:45:48.679144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', RobustScaler())]),\n",
       "                                 ['job_duration_in_current_job_level',\n",
       "                                  'job_duration_in_current_person_level',\n",
       "                                  'job_duration_in_current_branch', 'age',\n",
       "                                  'number_of_dependences', 'GPA',\n",
       "                                  'year_graduated',\n",
       "                                  'job_duration_from_training',\n",
       "                                  'branch_rotation', 'job_rotation',\n",
       "                                  'assign_of_otherposition', 'annual_leave',\n",
       "                                  'sick_leaves', 'Last_achievement',\n",
       "                                  'Achievement_above_100%_during3quartal',\n",
       "                                  'GPA_bin_target_encoding_cut']),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 ['job_level', 'person_level', 'Employee_type',\n",
       "                                  'gender', 'marital_status_maried(Y/N)',\n",
       "                                  'Education_level'])])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines[0].pipelines[0]['transformer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:45:58.396828Z",
     "start_time": "2021-02-13T14:45:58.377830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11153, 36)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2_fe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:46:09.916824Z",
     "start_time": "2021-02-13T14:46:09.904826Z"
    }
   },
   "outputs": [],
   "source": [
    "# cv=10\n",
    "# add_fes,pipelines = fast_build_model_FE_ensemble(X_train,y_train,cv,\n",
    "#                     Feature_Engineering,parameters,list_models=list_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:46:11.785869Z",
     "start_time": "2021-02-13T14:46:11.773837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(add_fes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:46:18.559830Z",
     "start_time": "2021-02-13T14:46:17.344854Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_proba = fast_predict_FE_ensemble(data_test,add_fes,pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-13T14:46:20.241846Z",
     "start_time": "2021-02-13T14:46:20.222816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Best Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.230511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.273958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.386696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.220155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.253016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>5995</td>\n",
       "      <td>0.240473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>5996</td>\n",
       "      <td>0.168555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>5997</td>\n",
       "      <td>0.247632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>5998</td>\n",
       "      <td>0.196402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>5999</td>\n",
       "      <td>0.263921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Best Performance\n",
       "0         0          0.230511\n",
       "1         1          0.273958\n",
       "2         2          0.386696\n",
       "3         3          0.220155\n",
       "4         4          0.253016\n",
       "...     ...               ...\n",
       "5995   5995          0.240473\n",
       "5996   5996          0.168555\n",
       "5997   5997          0.247632\n",
       "5998   5998          0.196402\n",
       "5999   5999          0.263921\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = pd.DataFrame({'index':data_test.index,'Best Performance':pred_proba})\n",
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T14:15:34.143109Z",
     "start_time": "2021-02-12T14:15:34.117097Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_submission.to_csv('df_submission_12feb_Ensemble_FE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T14:53:33.263256Z",
     "start_time": "2021-02-12T14:53:33.247258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15+22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T14:53:27.961349Z",
     "start_time": "2021-02-12T14:53:27.953353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add str to some numeric\n",
    "    - Try XGB with str achiv how is the score\n",
    "    \n",
    "- yeo johnson transformation\n",
    "- Kmeans / DBSCAn\n",
    "- Remove Outlier\n",
    "- Embedding\n",
    "- Tuning\n",
    "- Rule based for more specialized model\n",
    "- Using no Add fe and ensemble of add _fe etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
